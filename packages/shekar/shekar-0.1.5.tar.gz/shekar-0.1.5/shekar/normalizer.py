import regex as re


class Normalizer:
    def __init__(
        self,
        space_correction: bool = True,
        unify_numbers: bool = True,
        unify_punctuations: bool = True,
        unify_arabic_unicode: bool = True,
        remove_emojis: bool = True,
        remove_diactrics: bool = True,
        remove_punctuations: bool = False,
    ):
        self._unify_numbers = unify_numbers
        self._unify_punctuations = unify_punctuations
        self._unify_arabic_unicode = unify_arabic_unicode
        self._remove_emojis = remove_emojis
        self._remove_diactrics = remove_diactrics
        self._remove_punctuations = remove_punctuations

        self._diacritics_mappings = [
            (r"[Ù°Ù‹ÙŒÙÙŽÙÙÙ‘Ù’Ù“Ù”Ù–Ø•Ù•Ù™Ù´Ì’Ì]", ""),
        ]

        self._character_mappings = [
            (r"[Ù€]", ""),
            (r"[ïºïº‚]", "Ø¢"),
            (r"[Ù²Ùµï­ï­‘Ù³ïº‡ïºˆØ¥Ø£Ù±]", "Ø§"),
            (r"[Ù®Ù»Ú€ÝÝ’Ý”Ý•Ý–ï­’ï­•ïºïº’]", "Ø¨"),
            (r"[ï­–ï­—ï­˜ï­™ï­šï­›ï­œï­]", "Ù¾"),
            (r"[Ù¹ÙºÙ¼Ù¿Ý“ï­žï­Ÿï­ ï­¡ï­¦ï­¨ïº•ïº˜]", "Øª"),
            (r"[Ù½Ý‘ïº™ïºšïº›ïºœï­¢ï­¤]", "Ø«"),
            (r"[ÚƒÚ„ï­²ï­´ï­µï­·ïºïºŸïº ]", "Ø¬"),
            (r"[Ú‡Ú¿ï­ºÝ˜ï­¼ï®€ï®Ý¯]", "Ú†"),
            (r"[ÚÚ‚Ú…Ý—Ý®ïº¡ïº¤]", "Ø­"),
            (r"[ïº¥ïº¦ïº§]", "Ø®"),
            (r"[ÚˆÚ‰ÚŠÚ‹ÚÛ®Ý™Ýšï®‚ï®ˆïº©]", "Ø¯"),
            (r"[ÚŒï±›ïº«ïº¬ÚŽÚÚï®…ï®‡]", "Ø°"),
            (r"[Ú‘Ú’Ú“Ú”Ú•Ú–Û¯Ý›ï®Œïº­]", "Ø±"),
            (r"[Ú—Ý«ïº¯ïº°]", "Ø²"),
            (r"[Ú™ï®Šï®‹]", "Ú˜"),
            (r"[ÚšÚ›ïº±ïº´]", "Ø³"),
            (r"[ÚœÛºïºµïº¸ÝœÝ­]", "Ø´"),
            (r"[ÚÚžïº¹ïº¼]", "Øµ"),
            (r"[Û»ïº½ï»€]", "Ø¶"),
            (r"[ï»ï»ƒï»„]", "Ø·"),
            (r"[ï»…ï»†ï»ˆÚŸ]", "Ø¸"),
            (r"[Ú ÝÝžÝŸï»‰ï»Šï»‹]", "Ø¹"),
            (r"[Û¼ï»ï»Žï»]", "Øº"),
            (r"[Ú¡Ú¢Ú£Ú¤Ú¥Ú¦Ý Ý¡ï­ªï­«ï­¬ï»‘ï»’ï»“]", "Ù"),
            (r"[Ù¯Ú§Ú¨ï»•ï»—]", "Ù‚"),
            (r"[ÙƒØ»Ø¼ÚªÚ«Ú¬Ú­Ú®Ý¢Ý£ï®Žï®ï¯“ï»™ï»›]", "Ú©"),
            (r"[Ú°Ú±Ú²Ú³Ú´ï®’ï®”ï®–]", "Ú¯"),
            (r"[ÚµÚ¶Ú·Ú¸Ýªï»ï» ]", "Ù„"),
            (r"[Û¾Ý¥Ý¦ï»¡ï»¢ï»£]", "Ù…"),
            (r"[Ú¹ÚºÚ»Ú¼Ú½Ý§Ý¨Ý©ï®žï»¥ï»§]", "Ù†"),
            (r"[Ù¶Ù·ï¯—ï¯˜ï¯™ï¯šï¯œï¯ï¯žï¯Ÿïº…Û„Û…Û‰ÛŠÛ‹Ûï¯ ï»­Ø¤×¤]", "Ùˆ"),
            (r"[Ú¾Û¿Û€ÛÛ‚ÛƒÛ•ï®¤ï®¦ï®§ï®¨ï®©ï»©ï»«Ø©]", "Ù‡"),
            (
                r"[Ø Ø½Ø¾Ø¿Ù‰ÙŠÙ¸ÛÛŽÛÛ‘Û’Û“ï®®ï®¯ï®°ï®±ï¯¤ï¯¥ï¯¦ï¯§ï¯¼ï¯½ï¯¾ï¯¿ï»¯ï»±ï»³ï¯¨ï¯©ï¯«ï¯­ï¯°ï¯³ï¯µï¯·ï¯¹ï¯»ï±]",
                "ÛŒ",
            ),
        ]

        self._number_mappings = [
            (r"[0Ù ðŸ¢ðŸ¬]", "Û°"),
            (r"[1Ù¡ðŸ£ðŸ­â‘´â’ˆâ“µâ‘ â¶ðŸ™ðŸ·Ä±]", "Û±"),
            (r"[2Ù¢ðŸ¤ðŸ®â‘µâ’‰â“¶â‘¡â·Â²ðŸðŸ¸ðŸšá’¿Õ·]", "Û²"),
            (r"[3Ù£ðŸ¥ðŸ¯â‘¶â’Šâ“·â‘¢â¸Â³áƒ•]", "Û³"),
            (r"[4Ù¤ðŸ¦ðŸ°â‘·â’‹â“¸â‘£â¹â´]", "Û´"),
            (r"[5Ù¥ðŸ§ðŸ±â‘¸â’Œâ“¹â‘¤âºâµ]", "Ûµ"),
            (r"[6Ù¦ðŸ¨ðŸ²â‘¹â’â“ºâ‘¥â»â¶]", "Û¶"),
            (r"[7Ù§ðŸ©ðŸ³â‘ºâ’Žâ“»â‘¦â¼â·]", "Û·"),
            (r"[8Ù¨ðŸªðŸ´â‘»â’â“¼â‘§â½â¸Û¸]", "Û¸"),
            (r"[9Ù©ðŸ«ðŸµâ‘¼â’â“½â‘¨â¾â¹]", "Û¹"),
            (r"[â‘½â’‘â“¾â‘©]", "Û±Û°"),
            (r"[â‘¾â’’â‘ª]", "Û±Û±"),
            (r"[â‘¿â’“â‘«]", "Û±Û²"),
            (r"[â’€â’”â‘¬]", "Û±Û³"),
            (r"[â’â’•â‘­]", "Û±Û´"),
            (r"[â’‚â’–â‘®]", "Û±Ûµ"),
            (r"[â’ƒâ’—â‘¯]", "Û±Û¶"),
            (r"[â’„â’˜â‘°]", "Û±Û·"),
            (r"[â’…â’™â‘±]", "Û±Û¸"),
            (r"[â’†â’šâ‘²]", "Û±Û¹"),
            (r"[â’‡â’›â‘³]", "Û²Û°"),
        ]

        self._punctuation_unifiying_mappings = [
            (r"[â–•â˜â™âšâ–â”‚]", "|"),
            (r"[ã…¡ä¸€â€”â€“ãƒ¼Ì¶Ù€]", "-"),
            (r"[â–_Ì²]", "_"),
            (r"[â”?ï¿½ØŸÊ•Ê”ðŸ»\x08\x97\x9d]", "ØŸ"),
            (r"[â•ï¼]", "!"),
            (r"[â‰]", "!ØŸ"),
            (r"[â€¼]", "!!"),
            (r"[â„…%]", "Ùª"),
            (r"[Ã·]", "/"),
            (r"[Ã—]", "*"),
            (r"[ï¼š]", ":"),
            (r"[â€º]", ">"),
            (r"[â€¹ï¼œ]", "<"),
            (r"[ã€Š]", "Â«"),
            (r"[ã€‹]", "Â»"),
            (r"[â€¢]", "."),
            (r"[Ù¬,]", "ØŒ"),
            (r"[;ï¼›]", "Ø›"),
        ]

        self._no_punctuation_mappings = [
            (r"[^\w\s\d\p{Emoji}]", ""),
        ]

        self._extra_space_mappings = [
            (r" {2,}", " "),  # remove extra spaces
            (r"\n{3,}", "\n\n"),  # remove extra newlines
            (r"\u200c{2,}", "\u200c"),  # remove extra ZWNJs
            (r"\u200c{1,} ", " "),  # remove unneded ZWNJs before space
            (r" \u200c{1,}", " "),  # remove unneded ZWNJs after space
            (r"\b\u200c*\B", ""),  # remove unneded ZWNJs at the beginning of words
            (r"\B\u200c*\b", ""),  # remove unneded ZWNJs at the end of words
            (r"[\u200b\u200d\u200e\u200f\u2066\u2067\u202a\u202b\u202d]", ""),
        ]

        self._emoji_mappings = [
            (r"[ðŸ˜€-ðŸ˜¯]", ""),
            (r"[ðŸŒ-ðŸ–¿]", ""),
            (r"[ðŸš€-ðŸ›¿]", ""),
            (r"[ðŸ‡ -ðŸ‡¿]", ""),
            (r"[ã  -ð¯¿¿]", ""),
            (r"[â°]", ""),
            (r"[â™€-â™‚]", ""),
            (r"[â˜€-ðŸ”¿]", ""),
            (r"[â€]", ""),
            (r"[â]", ""),
            (r"[â©]", ""),
            (r"[âŒš]", ""),
            (r"[ï¸]", ""),
            (r"[ðŸ’¯]", ""),
            (r"[ã€°]", ""),
            (r"[â±]", ""),
            (r"[âª]", ""),
        ]

        self._unicode_mappings = [
            ("ï·½", "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÛŒÙ…"),
            ("ï·¼", "Ø±ÛŒØ§Ù„"),
            ("(ï·°|ï·¹)", "ØµÙ„ÛŒ"),
            ("ï·²", "Ø§Ù„Ù„Ù‡"),
            ("ï·³", "Ø§Ú©Ø¨Ø±"),
            ("ï·´", "Ù…Ø­Ù…Ø¯"),
            ("ï·µ", "ØµÙ„Ø¹Ù…"),
            ("ï·¶", "Ø±Ø³ÙˆÙ„"),
            ("ï··", "Ø¹Ù„ÛŒÙ‡"),
            ("ï·¸", "ÙˆØ³Ù„Ù…"),
            ("ï»µ|ï»¶|ï»·|ï»¸|ï»¹|ï»º|ï»»|ï»¼", "Ù„Ø§"),
        ]

        self._all_mappings = []
        self._all_mappings.extend(self._character_mappings)

        if unify_punctuations and not remove_punctuations:
            self._all_mappings.extend(self._punctuation_unifiying_mappings)

        if remove_punctuations:
            self._all_mappings.extend(self._no_punctuation_mappings)

        if unify_numbers:
            self._all_mappings.extend(self._number_mappings)
        if unify_arabic_unicode:
            self._all_mappings.extend(self._unicode_mappings)
        if remove_emojis:
            self._all_mappings.extend(self._emoji_mappings)
        if remove_diactrics:
            self._all_mappings.extend(self._diacritics_mappings)
        if space_correction:
            self._all_mappings.extend(self._extra_space_mappings)

    def normalize(self, text):
        # unification
        for pattern, replacement in self._all_mappings:
            text = re.sub(pattern, replacement, text)

        # space correction
        text = self.space_correction(text)

        return text

    def unify_numbers(self, text):
        for pattern, replacement in self._number_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def unify_punctuations(self, text):
        for pattern, replacement in self._punctuation_unifiying_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def unify_characters(self, text):
        for pattern, replacement in self._character_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def unify_arabic_unicode(self, text):
        for pattern, replacement in self._unicode_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def remove_emojis(self, text):
        for pattern, replacement in self._emoji_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def remove_diactrics(self, text):
        for pattern, replacement in self._diacritics_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def remove_punctuations(self, text):
        for pattern, replacement in self._no_punctuation_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def remove_diacritics(self, text):
        for pattern, replacement in self._diacritics_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def remove_extra_spaces(self, text):
        for pattern, replacement in self._extra_space_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    def space_correction(self, sentence):
        # copied from ParsiNorm with
        # This Function is a mixture of HAZM and ParsiVar Features

        sentence = re.sub(r"^(Ø¨ÛŒ|Ù…ÛŒ|Ù†Ù…ÛŒ)( )", r"\1â€Œ", sentence)  # verb_prefix
        sentence = re.sub(r"( )(Ù…ÛŒ|Ù†Ù…ÛŒ)( )", r"\1\2â€Œ ", sentence)  # verb_prefix
        sentence = re.sub(
            r"([^ ]Ù‡) ÛŒ ", r"\1â€ŒÛŒ ", sentence
        )  # nouns ends with Ù‡ when having ÛŒ
        sentence = re.sub(
            r"( )(Ù‡Ø§ÛŒÛŒ|Ù‡Ø§|Ù‡Ø§ÛŒ|Ø§ÛŒÛŒ|Ù‡Ø§ÛŒÙ…|Ù‡Ø§ÛŒØª|Ù‡Ø§ÛŒØ´|Ù‡Ø§ÛŒÙ…Ø§Ù†|Ù‡Ø§ÛŒØªØ§Ù†|Ù‡Ø§ÛŒØ´Ø§Ù†|Ø§Øª|Ø§Ù†|ÛŒÙ†"
            r"|Ø§Ù†ÛŒ|Ø¨Ø§Ù†|Ø§Ù…|Ø§ÛŒ|ÛŒÙ…|ÛŒØ¯|Ø§ÛŒØ¯|Ø§Ù†Ø¯|Ø¨ÙˆØ¯Ù…|Ø¨ÙˆØ¯ÛŒ|Ø¨ÙˆØ¯|Ø¨ÙˆØ¯ÛŒÙ…|Ø¨ÙˆØ¯ÛŒØ¯|Ø¨ÙˆØ¯Ù†Ø¯|Ø³Øª|ØªØ±|ØªØ±ÛŒ|ØªØ±ÛŒÙ†|Ú¯Ø±ÛŒ|Ú¯Ø±)( )",
            r"â€Œ\2\3",
            sentence,
        )
        # Issue: some suffixes may introduce incorrect spacing!
        # A more complex solution is needed to fix this issue.
        # Example: "Ø¨Ø§ Ú©ÛŒâ€ŒØ¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ù†ÛŒØŸ" <- "Ø¨Ø§ Ú©ÛŒ Ø¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ù†ÛŒØŸ"
        # Example: "Ø¨Ù‡ Ù†Ú©ØªÙ‡ Ø±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!" -> "Ø¨Ù‡ Ù†Ú©ØªÙ‡â€ŒØ±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!"

        # complex_word_suffix_pattern = (
        #     r"( )(Ø·Ù„Ø¨Ø§Ù†|Ø·Ù„Ø¨|Ú¯Ø±Ø§ÛŒÛŒ|Ú¯Ø±Ø§ÛŒØ§Ù†|Ø´Ù†Ø§Ø³|Ø´Ù†Ø§Ø³ÛŒ|Ú¯Ø°Ø§Ø±ÛŒ|Ú¯Ø°Ø§Ø±|Ú¯Ø°Ø§Ø±Ø§Ù†|Ø´Ù†Ø§Ø³Ø§Ù†|Ú¯ÛŒØ±ÛŒ|Ù¾Ø°ÛŒØ±ÛŒ|Ø¨Ù†Ø¯ÛŒ|Ø¢ÙˆØ±ÛŒ|Ø³Ø§Ø²ÛŒ|"
        #     r"Ø¨Ù†Ø¯ÛŒ|Ú©Ù†Ù†Ø¯Ù‡|Ú©Ù†Ù†Ø¯Ú¯Ø§Ù†|Ú¯ÛŒØ±ÛŒ|Ù¾Ø±Ø¯Ø§Ø²|Ù¾Ø±Ø¯Ø§Ø²ÛŒ|Ù¾Ø±Ø¯Ø§Ø²Ø§Ù†|Ø¢Ù…ÛŒØ²|Ø³Ù†Ø¬ÛŒ|Ø±ÛŒØ²ÛŒ|Ø¯Ø§Ø±ÛŒ|Ø¯Ù‡Ù†Ø¯Ù‡|Ø¢Ù…ÛŒØ²|Ù¾Ø°ÛŒØ±ÛŒ"
        #     r"|Ù¾Ø°ÛŒØ±|Ù¾Ø°ÛŒØ±Ø§Ù†|Ú¯Ø±|Ø±ÛŒØ²|Ø±ÛŒØ²ÛŒ|Ø±Ø³Ø§Ù†ÛŒ|ÛŒØ§Ø¨|ÛŒØ§Ø¨ÛŒ|Ú¯Ø§Ù†Ù‡|Ú¯Ø§Ù†Ù‡â€ŒØ§ÛŒ|Ø§Ù†Ú¯Ø§Ø±ÛŒ|Ú¯Ø§|Ø¨Ù†Ø¯|Ø±Ø³Ø§Ù†ÛŒ|Ø¯Ù‡Ù†Ø¯Ú¯Ø§Ù†|Ø¯Ø§Ø±)( )"
        # )
        # sentence = re.sub(complex_word_suffix_pattern, r"â€Œ\2\3", sentence)
        sentence = re.sub(r' "([^\n"]+)" ', r'"\1"', sentence)

        punc_after = r".\.:!ØŒØ›ØŸÂ»\]\)\}"
        punc_before = r"Â«\[\(\{"

        sentence = re.sub(
            r" ([" + punc_after + "])|([" + punc_before + "]) ", r"\1\2", sentence
        )  # Remove/add spaces around punctuation
        sentence = re.sub(
            r"([.ØŒ:ØŸ!])([^ {} \dÛ°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹])".format(punc_after), r"\1 \2", sentence
        )  # Add space after ., :
        sentence = re.sub(
            r"([^ " + punc_before + "])([" + punc_before + "])", r"\1 \2", sentence
        )  # Add space before punctuation

        sentence = self.remove_extra_spaces(sentence)
        return sentence
