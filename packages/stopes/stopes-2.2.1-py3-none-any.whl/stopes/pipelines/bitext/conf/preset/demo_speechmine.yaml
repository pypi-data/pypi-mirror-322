# @package _global_

# configure the launcher, this one will
# decide how each step of the pipeline gets executed
launcher:
  # `local` means that you will run all the steps sequentially on
  # your local computer. You can also use `slurm` if you have a slurm cluster
  # setup, in which case paralell jobs will be submitted when possible.
  cluster: local
  # we don't need to set this if we aren't using slurm
  partition: null
  # To improve resilience and make iteration faster, stopes caches the results of
  # each steps of the pipeline. Set a fixed directory here if you want to
  # leverage caching.
  cache:
    caching_dir: /tmp/global_mining_cache

# you will need to set this on the CLI to point to where
# the demo dir is (after running demo/mining/prepare.sh)
demo_text_dir: ???

# Put the path to your audio data here
demo_audio_dir: ???

# where will the data go, `.` is the current run directory (auto generated by
# hydra to be unique for each run)
output_dir: .
# where to find models and vocab, this is what `prepare.sh` downloaded
model_dir: ${demo_dir}/models/wmt22
vocab_dir: ${demo_dir}/models/wmt22

# Setup some of the steps, using GPU for populate_index makes
# it a lot faster, but if you don't have one, it's ok.
populate_index:
  config:
    use_gpu: False

embedding_sample:
  sample_shards: False

train_index:
  config:
    use_gpu: False

calculate_distances:
  config:
    gpu_memory_gb: 32
    gpu_type: "" # don't use gpu

# Provides info about the data. A lot of this is used to generate nice output
# file names.
data:
  data_version: V32m
  iteration: 1
  data_shard_dir: ${demo_dir}
  shard_type: text
  bname: demo_wmt22
  # shard_glob tells us where to find the language files. `{lang}` will be
  # replaced by the language code from src and tgt
  shard_glob: ${.data_shard_dir}/{lang}.gz
  # we need to know the number of lines in each file, this is computed in
  # prepare.sh and this tells the pipeline where to find the files with this
  # info
  nl_file_template: "{lang}.nl"

lang_configs:
  frA:
    data:
      data_version: 23H1RCLSP
      iteration: 1
      data_shard_dir: ${demo_audio_dir}
      shard_type: speech
      bname: speech
      shard_list: null
      # shard_glob tells us where to find the language files `{lang}` will be
      # replaced by the language code from src and tgt
      shard_glob: ${.data_shard_dir}/speech/*.ogg
      # we need to know the number of lines in each file, this is computed in
      # prepare.sh and this tells the pipeline where to find the files with this
      # info
      nl_file_template: "{lang}.nl"

    embed_speech:
      preprocess: null
      encoder:
        _target_: stopes.modules.preprocess.mining_speech_encoder.Sonar2MiningSpeechEncoder
        encoder_model: ???
        _name: sonar2_speech_encoder
        spm_model: null # unused
        spm_vocab: null # unused
        mini_batch_size: null
        fp16: true
        gpu: true
        num_processes: 4

  fr:
    data:
      data_version: 23H1RCL
      iteration: 1
      data_shard_dir: ${demo_text_dir}
      shard_type: text
      bname: text
      shard_list: null
      # shard_glob tells us where to find the language files. `{lang}` will be
      # replaced by the language code from src and tgt
      shard_glob: ${.data_shard_dir}/{lang}.gz
      # we need to know the number of lines in each file, this is computed in
      # prepare.sh and this tells the pipeline where to find the files with this
      # info
      nl_file_template: "{lang}.nl"

    embed_text:
      encoder:
        _target_: stopes.modules.preprocess.sonar_sentence_encoder.SonarTextEncoder
        _name: NAME_OF_SONAR_ENCODER_MODEL
        spm_model: null # unused
        spm_vocab: null # unused
