PydanticAI: A Comprehensive Guide to its API and Usage with Coding LLMs
Developing production-ready applications with generative AI can be a complex endeavor, often involving intricate integrations and meticulous error handling. PydanticAI emerges as a powerful Python framework designed to streamline this process, offering a robust and user-friendly approach to building AI-driven applications. This article provides a comprehensive exploration of PydanticAI's API, its key features, and how to leverage it effectively with coding LLMs. We'll delve into various code examples, illustrating how PydanticAI can simplify and enhance your AI application development journey. To gather the information for this article, extensive research was conducted, including examining the official PydanticAI documentation 1, exploring tutorials and guides 2, and analyzing diverse code examples to showcase the versatility of this framework.
Introduction to PydanticAI
Developed by the Pydantic team, PydanticAI serves as an agent framework, seamlessly bridging the gap between Pydantic and Large Language Models (LLMs). It draws inspiration from FastAPI, renowned for its innovative and ergonomic design built upon Pydantic. PydanticAI aims to replicate this user-friendly approach in the realm of generative AI application development.
Key Features and Functionalities
PydanticAI offers a compelling array of features that make it a standout choice for AI development:
Model-Agnostic: PydanticAI supports a wide spectrum of LLMs, including prominent options like OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral. Furthermore, it provides a straightforward interface for incorporating support for other models3.
Type-Safe: Ensuring type safety is paramount in software development, and PydanticAI excels in this aspect. It seamlessly integrates with static type checkers such as MyPy and Pyright, enabling robust type validation and minimizing potential errors3.
Python-Centric Design: PydanticAI embraces a Python-centric design philosophy, leveraging familiar Python control flow and agent composition principles. This allows developers to readily apply standard Python best practices, ensuring a smooth and intuitive development experience3.
Structured Responses: One of PydanticAI's core strengths lies in its ability to harness Pydantic's capabilities for structuring and validating model outputs. This ensures consistency, reliability, and predictability in the responses generated by LLMs1.
Dependency Injection System: PydanticAI incorporates an optional dependency injection system, providing a mechanism to supply data and services to your agent's prompts, tools, and validators. This feature proves particularly valuable for testing, facilitating iterative development, and promoting modularity in your AI applications3.
Streamed Responses: For applications requiring real-time interactions, PydanticAI offers the capability to stream LLM outputs continuously. This feature, coupled with immediate validation, ensures rapid and accurate results, enhancing the responsiveness of your AI applications3.
Pydantic Logfire Integration: Seamless integration with Pydantic Logfire empowers developers with real-time debugging capabilities, performance monitoring, and comprehensive behavior tracking of their LLM-powered applications. This facilitates in-depth analysis and optimization of AI systems3.
API Description
PydanticAI provides a well-defined API encompassing various methods, parameters, and return types for seamless interaction with LLMs and the construction of robust AI applications. Here's a breakdown of the core API references:




pydantic\_ai.Agent
The pydantic\_ai.Agent class serves as the cornerstone of PydanticAI, enabling the creation and management of agents that interact with LLMs. It provides methods for configuring agents, defining prompts, incorporating tools, and executing LLM interactions.
Here's a basic example demonstrating the usage of pydantic\_ai.Agent:

Python


from pydantic\_ai import Agent

agent = Agent(
 'gemini-1.5-flash', # Specify the LLM model to use
 system\_prompt='Be concise, reply with one sentence.', # Set a system prompt
)

result = agent.run\_sync('Where does "hello world" come from?') # Run the agent synchronously

print(result.data) # Print the LLM's response

This code snippet demonstrates a simple "Hello World" example using PydanticAI. It initializes an agent with the Gemini 1.5 Flash model and sets a system prompt to guide the LLM's response. The agent.run\_sync() method executes the agent synchronously with the provided user query, and the result is printed to the console1.
pydantic\_ai.tools
The pydantic\_ai.tools module provides a collection of tools and utilities that empower developers to extend the functionalities of their agents. These tools can be used to integrate external services, access data sources, and perform various actions within the context of an LLM interaction.
pydantic\_ai.result
The pydantic\_ai.result module defines classes and structures for handling and validating the outputs generated by LLMs. This ensures that the responses adhere to predefined schemas and data types, enhancing the reliability and consistency of AI applications.
pydantic\_ai.messages
The pydantic\_ai.messages module encapsulates message formats and structures for facilitating communication between agents and LLMs. It defines standardized message types and provides utilities for constructing and processing messages.
pydantic\_ai.exceptions
The pydantic\_ai.exceptions module defines exceptions and error handling mechanisms specific to PydanticAI. This allows developers to gracefully handle errors that may arise during LLM interactions and implement robust error recovery strategies.
pydantic\_ai.settings
The pydantic\_ai.settings module provides configuration options and settings for customizing the behavior of PydanticAI. Developers can fine-tune various aspects of the framework, such as logging levels, API keys, and model parameters.
pydantic\_ai.models
The pydantic\_ai.models module offers a collection of pre-built models and integrations with various LLM providers. This simplifies the process of incorporating different LLMs into your AI applications, providing a standardized interface for interacting with diverse models.
pydantic\_ai.models.openai
The pydantic\_ai.models.openai module specifically handles interactions with OpenAI's models and API. It provides convenient methods for accessing and utilizing OpenAI's LLMs within PydanticAI agents.
pydantic\_ai.models.anthropic
The pydantic\_ai.models.anthropic module specifically handles interactions with Anthropic's models and API. It provides convenient methods for accessing and utilizing Anthropic's LLMs within PydanticAI agents.
pydantic\_ai.models.gemini
The pydantic\_ai.models.gemini module specifically handles interactions with Google Gemini's models and API. It provides convenient methods for accessing and utilizing Google Gemini's LLMs within PydanticAI agents.
pydantic\_ai.models.vertexai
The pydantic\_ai.models.vertexai module specifically handles interactions with Google Vertex AI's models and API. It provides convenient methods for accessing and utilizing Google Vertex AI's LLMs within PydanticAI agents.
pydantic\_ai.models.groq
The pydantic\_ai.models.groq module specifically handles interactions with Groq's models and API. It provides convenient methods for accessing and utilizing Groq's LLMs within PydanticAI agents.
pydantic\_ai.models.mistral
The pydantic\_ai.models.mistral module specifically handles interactions with Mistral's models and API. It provides convenient methods for accessing and utilizing Mistral's LLMs within PydanticAI agents.
pydantic\_ai.models.ollama
The pydantic\_ai.models.ollama module specifically handles interactions with Ollama's models and API. It provides convenient methods for accessing and utilizing Ollama's LLMs within PydanticAI agents.
pydantic\_ai.models.test
The pydantic\_ai.models.test module provides utilities for testing and mocking LLM interactions. This allows developers to isolate and test their agent logic without relying on actual LLM calls, facilitating efficient unit testing and debugging.
pydantic\_ai.models.function
The pydantic\_ai.models.function module facilitates the definition and integration of custom functions within PydanticAI agents. This enables developers to extend the capabilities of their agents by incorporating specialized logic and functionalities.
Tools & Dependency Injection Example
PydanticAI's dependency injection system provides a powerful mechanism for incorporating external data and services into your agent's interactions with LLMs. This example demonstrates how to build a support agent for a bank, leveraging dependency injection to access customer information and provide tailored assistance.

Python


from dataclasses import dataclass
from pydantic import BaseModel, Field
from pydantic\_ai import Agent, RunContext

# This is a simple sketch of a database connection, used to keep the example short and readable.
# In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.
from bank\_database import DatabaseConn 

@dataclass
class SupportDependencies:
 customer\_id: int
 db: DatabaseConn

# This Pydantic model is used to constrain the structured data returned by the agent.
# From this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data,
# and performs validation to guarantee the data is correct at the end of the run.
class SupportResult(BaseModel):
 support\_advice: str = Field(description='Advice returned to the customer')
 block\_card: bool = Field(description="Whether to block the customer's card")
 risk: int = Field(description='Risk level of query', ge=0, le=10)

support\_agent = Agent(
 'openai:gpt-4o', # Specify the LLM model to use
 deps\_type=SupportDependencies, # Define the dependency type
 result\_type=SupportResult, # Define the result type
 system\_prompt=(
 'You are a support agent in our bank, give the '
 'customer support and judge the risk level of their query.'
 ),
)

@support\_agent.system\_prompt
async def add\_customer\_name(ctx: RunContext) -> str:
 customer\_name = await ctx.deps.db.customer\_name(id=ctx.deps.customer\_id)
 return f"The customer's name is {customer\_name!r}"

@support\_agent.tool
async def customer\_balance(
 ctx: RunContext, include\_pending: bool
) -> float:
 """Returns the customer's current account balance."""
 return await ctx.deps.db.customer\_balance(
 id=ctx.deps.customer\_id, include\_pending=include\_pending
 )

# ... (rest of the code)

async def main():
 deps = SupportDependencies(customer\_id=123, db=DatabaseConn())
 result = await support\_agent.run('What is my balance?', deps=deps)
 print(result.data)

In this example, the SupportDependencies dataclass encapsulates the necessary dependencies, including the customer ID and a database connection. The SupportResult model defines the structure of the agent's response. The @support\_agent.system\_prompt decorator allows for dynamic system prompt generation based on the provided dependencies. Similarly, the @support\_agent.tool decorator registers a tool that can be utilized by the LLM during its interaction. This example showcases how PydanticAI's dependency injection system facilitates the integration of external data and services, enabling the creation of more context-aware and powerful AI agents1.
Contracts Domain Example
This example demonstrates how to use PydanticAI to extract entities from a business contract. It utilizes PyMuPDF4LLM to extract data from a PDF file as Markdown and then employs an agent to identify key entities within the contract.

Python


from dotenv import load\_dotenv
from pprint import pprint
import pymupdf4llm
load\_dotenv()

# Extract Markdown from PDF
md\_text = pymupdf4llm.to\_markdown("sample.pdf")
pprint(md\_text)

import nest\_asyncio
nest\_asyncio.apply()
from pydantic\_ai import Agent
from pydantic\_ai.models.openai import OpenAIModel
model = OpenAIModel('gpt-4o-mini')
from pydantic import BaseModel
from pydantic import Field
from typing import Optional, List

# Define Agent and Types
class ContractAnalysis(BaseModel):
 parties : Optional[List] = Field(description="parties in a contract")
 agreement\_date: str = Field(description="agreement date")

agent = Agent(model, result\_type=ContractAnalysis, system\_prompt=("You are a Business Lawyer"))

# Run Agent
result = agent.run\_sync(md\_text)
pprint(result.data)
# >>> ContractAnalysis(parties=['Indian Institute of Technology Kanpur', 'M/s \_\_\_\_\_\_'], agreement\_date='October 1, 2012')

This example highlights the use of PydanticAI in a specific domain, showcasing its ability to extract structured information from unstructured text. It demonstrates the integration of external libraries and the definition of custom Pydantic models to represent the extracted entities4.
Pydantic Model Example
This example illustrates how to use PydanticAI to construct a Pydantic model from a text input. It demonstrates the use of structured result\_type to define the expected output format.

Python


import os
from typing import cast
import logfire
from pydantic import BaseModel
from pydantic\_ai import Agent
from pydantic\_ai.models import KnownModelName

# 'if-token-present' means nothing will be sent (and the example will work)
# without needing to set any environment variables
os.environ['OPENAI\_API\_KEY'] = os.environ.get('OPENAI\_API\_KEY') or 'if-token-present'

class User(BaseModel):
 name: str
 age: int
 # ... other fields

agent = Agent(
 cast(KnownModelName, 'openai'),
 system\_prompt="You are a world class programmer, expert in all programming languages and tools.",
 result\_type=User,
)

result = agent.run\_sync(
 """
 Create a Pydantic model for a user with a name and age.
 """
)

print(result.data)
# name='string' age=0

This example showcases PydanticAI's capability to generate code and data structures based on natural language instructions. It demonstrates the use of result\_type to enforce a specific output structure, ensuring that the LLM's response conforms to the desired Pydantic model5.
Limitations and Potential Drawbacks
While PydanticAI offers numerous advantages for AI development, it's essential to acknowledge its limitations, particularly since it is currently in early beta. The API is still subject to change, which may require adjustments to your code as the framework evolves1.
Conclusion
PydanticAI emerges as a valuable tool for simplifying and enhancing the development of AI-driven applications. Its model-agnostic nature, type safety features, Python-centric design, and support for structured outputs make it a compelling choice for developers seeking to integrate LLMs into their projects. The framework's dependency injection system promotes modularity and testability, while streamed responses enable real-time interactions. By leveraging PydanticAI's capabilities, developers can streamline their AI development workflows, improve code quality, and unlock the full potential of generative AI.
Works cited
1. PydanticAI, accessed December 23, 2024, 
2. PydanticAI - Agent Framework / shim to use Pydantic with LLMs - Install Locally - YouTube, accessed December 23, 2024, 
3. pydantic/pydantic-ai: Agent Framework / shim to use Pydantic with LLMs - GitHub, accessed December 23, 2024, 
4. PydanticAI Example from Contracts Domain | by Yogendra Sisodia | Dec, 2024 - Medium, accessed December 23, 2024, 
5. Pydantic Model - PydanticAI, accessed December 23, 2024, 
