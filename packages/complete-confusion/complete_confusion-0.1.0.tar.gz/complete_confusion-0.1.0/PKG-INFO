Metadata-Version: 2.1
Name: complete-confusion
Version: 0.1.0
Summary: Performance evaluation and visualization with one function call
License: Apache 2.0
Author: Peter Kok
Author-email: p.kok@esciencecenter.nl
Requires-Python: >=3.10,<4.0
Classifier: License :: Other/Proprietary License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: numpy (>=2.2.2,<3.0.0)
Requires-Dist: plotly (>=5.24.1,<6.0.0)
Requires-Dist: scikit-learn (>=1.6.1,<2.0.0)
Description-Content-Type: text/markdown

# Complete Confusion

A simple call to visualize performance metrics for classification and regression models.


## Installation

```bash
pip install complete-confusion
```

## Usage

```python
import complete_confusion as cc

# Example data
predictions = [0, 1, 0, 2, 1, 2, 0]
trues = [0, 1, 0, 2, 0, 2, 2]
classes = ["Class 0", "Class 1", "Class 2"]
output_path = "confusion_matrix.html"

cc.export_confusion_matrix_to_html(predictions, trues, classes, output_path)
```


## Development

```bash
poetry install
poetry shell
python evaluate.py
```

