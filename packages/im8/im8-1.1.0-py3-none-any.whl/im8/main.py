import pyperclip

questions = {
    "Удобная реализация MLP": {
        "code": "from torch import nn\n\n\nclass Model(nn.Module):\n    def __init__(self, hidden_sizes: list, activation: nn.Module = nn.ReLU):\n        super().__init__()\n        self.layers = nn.Sequential()\n\n        for in_size, out_size in zip(hidden_sizes, hidden_sizes[1:-1]):\n            layer = nn.Sequential(\n                nn.Linear(in_size, out_size), nn.BatchNorm1d(out_size), activation()\n            )\n            self.layers.append(layer)\n\n        self.layers.append(nn.Linear(hidden_sizes[-2], hidden_sizes[-1]))\n\n    def forward(self, x):\n        return self.layers(x)"
    },
    "Сравнение оптимизаторов чегоугодно и train loop": {
        "code": "import pandas as pd\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torchmetrics as M\n\n\ndef train_model(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    test_loader,\n    epochs,\n    device,\n    metric,\n    print_every,\n):\n    metric_name = metric.__class__.__name__\n\n    metrics_df = pd.DataFrame(\n        [],\n        columns=[\n            \"Train Loss\",\n            \"Test Loss\",\n            f\"Train {metric_name}\",\n            f\"Test {metric_name}\",\n        ],\n    )\n\n    for epoch in tqdm(range(epochs), total=epochs):\n        epoch_loss = 0\n\n        metric.reset()\n\n        for batch_X, batch_y in train_loader:\n            batch_X = batch_X.to(device)\n            batch_y = batch_y.to(device)\n\n            y_pred = model(batch_X)\n            loss = criterion(y_pred, batch_y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            metric.update(y_pred, batch_y)\n\n        train_f1 = metric.compute().item()\n        metric.reset()\n\n        test_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                y_pred = model(batch_X)\n                loss = criterion(y_pred, batch_y)\n                test_loss += loss.item()\n                metric.update(y_pred, batch_y)\n\n        test_f1 = metric.compute().item()\n\n        metrics_df.loc[epoch] = {\n            \"Train Loss\": epoch_loss / len(train_loader),\n            f\"Train {metric_name}\": train_f1,\n            \"Test Loss\": test_loss / len(test_loader),\n            f\"Test {metric_name}\": test_f1,\n        }\n\n        if (epoch + 1) % print_every == 0:\n            print(\n                f\"Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Train {metric_name}: {train_f1:.4f}, Test Loss: {test_loss / len(test_loader):.4f}, Test {metric_name}: {test_f1:.4f}\"\n            )\n\n    return metrics_df\n\nbatch_size = 64\nepochs = 100\nprint_every = 10\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice = \"cpu\"\n\nmodel = Model([X.shape[1], 128, y.shape[1]]).to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.97))\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nmetric = M.MeanAbsolutePercentageError()\nmetric_name = metric.__class__.__name__\n\n# pip install lion-pytorch\n# from lion_pytorch import Lion\n\ntotal_metrics = pd.DataFrame()\n\noptimizers = [\n    (torch.optim.SGD, {}),\n    (torch.optim.RMSprop, {}),\n    (torch.optim.AdamW, dict(betas=(0.9, 0.97))),\n    # (Lion, dict(lr=1e-4, weight_decay=1e-2))\n]\n\nepochs = 200\nfor i in range(len(optimizers)):\n    model = Model([X.shape[1], 128, y.shape[1]]).to(device)\n\n    optimizer = optimizers[i][0](model.parameters(), **optimizers[i][1])\n\n    metrics_df = train_model(\n        model,\n        criterion,\n        optimizer,\n        train_loader,\n        test_loader,\n        epochs,\n        device,\n        metric,\n        print_every=epochs + 1,\n    )\n\n    optim_metrics = metrics_df[[\"Train Loss\", \"Test Loss\"]].rename(\n        columns={\n            \"Train Loss\": f\"{optimizer.__class__.__name__}/Train Loss\",\n            \"Test Loss\": f\"{optimizer.__class__.__name__}/Test Loss\",\n        }\n    )\n\n    total_metrics = pd.concat([total_metrics, optim_metrics], axis=1)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\n\ntotal_metrics.rolling(4).mean().plot(ax=ax)  # .rolling(10).mean()\nplt.grid(alpha=0.5, linestyle=\":\")\n\nplt.show()\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\n\ntotal_metrics.rolling(4).mean().plot(ax=ax)  # .rolling(10).mean()\nplt.ylim(0, 0.003)\nplt.grid(alpha=0.5, linestyle=\":\")\n\nplt.show()"
    },
    "Разбиение датасета на метки для множественной классификации": {
        "code": "from torchvision import transforms as T\nfrom torchvision.datasets import ImageFolder\n\ndata_dir = \"datasets/images/clothes_multi\"\n\n# Предобработка изображений\ntransform = T.Compose(\n    [\n        T.CenterCrop((256, 256)),\n        T.Resize((32, 32)),\n        T.ToTensor(),\n    ]\n)\n\n# Загрузка данных\nfull_dataset = ImageFolder(data_dir, transform=transform)\n\nind2class = dict(enumerate(full_dataset.classes))\n\ncolors = list(\n    set([class_.split(\"_\", maxsplit=1)[0] for class_ in full_dataset.classes])\n)\ncolor2ind = {color: idx for idx, color in dict(enumerate(colors)).items()}\n\ngarments = list(\n    set([class_.split(\"_\", maxsplit=1)[1] for class_ in full_dataset.classes])\n)\ngarment2ind = {color: idx for idx, color in dict(enumerate(garments)).items()}\n\nfor k, v in ind2class.items():\n    color, garment = v.split(\"_\", maxsplit=1)\n    ind2class[k] = (color2ind[color], garment2ind[garment])\n\ntrain_size = int(0.7 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    full_dataset, [train_size, test_size]\n)"
    },
    "CNN для множественной классификации": {
        "code": "import torch.nn as nn\n\n\nclass CNN(nn.Module):\n    def __init__(self, inp, num_classes_1, num_classes_2):\n        super().__init__()\n        self.shared_model = nn.Sequential(\n            nn.Conv2d(inp, 8, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten(start_dim=1),\n        )\n\n        self.fc1 = nn.Linear(1024, num_classes_1)\n        self.fc2 = nn.Linear(1024, num_classes_2)\n\n    def forward(self, x):\n        x = self.shared_model(x)\n        out1 = self.fc1(x)\n        out2 = self.fc2(x)\n        return out1, out2"
    },
    "train loop для множественной классификации": {
        "code": "import torchmetrics as M\n\nnum_classes_1 = ...\nnum_classes_2 = ...\ncriterion1 = ...\ncriterion2 = ...\n\nmetric_1 = M.F1Score(task=\"multilabel\", average=\"macro\", num_labels=num_classes_1)\nmetric_2 = M.F1Score(task=\"multilabel\", average=\"macro\", num_labels=num_classes_2)\n\ndata = pd.DataFrame(\n    [],\n    columns=[\n        \"Train Loss\",\n        \"Test Loss\",\n        \"Train F1 (1)\",\n        \"Test F1 (1)\",\n        \"Train F1 (2)\",\n        \"Test F1 (2)\",\n    ],\n)\n\nfor epoch in tqdm(range(epochs), total=epochs):\n    epoch_loss = 0\n    metric_1.reset()\n    metric_2.reset()\n\n    for batch_X, batch_y in train_loader:\n        batch_y1 = batch_y[:, 0]\n        batch_y2 = batch_y[:, 1]\n        pred1, pred2 = model(batch_X)\n        loss1 = criterion1(pred1, batch_y1)\n        loss2 = criterion2(pred2, batch_y2)\n        loss = loss1 + loss2\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        y_ohe_1 = torch.nn.functional.one_hot(\n            batch_y1, num_classes=num_classes_1\n        ).float()\n        metric_1.update((pred1 > 0.5).int(), y_ohe_1)\n\n        y_ohe_2 = torch.nn.functional.one_hot(\n            batch_y2, num_classes=num_classes_2\n        ).float()\n        metric_2.update((pred2 > 0.5).int(), y_ohe_2)\n\n    train_f1_1 = metric_1.compute().item()\n    train_f1_2 = metric_2.compute().item()\n    metric_1.reset()\n    metric_2.reset()\n\n    test_loss = 0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            batch_y1 = batch_y[:, 0]\n            batch_y2 = batch_y[:, 1]\n            pred1, pred2 = model(batch_X)\n            loss1 = criterion1(pred1, batch_y1)\n            loss2 = criterion2(pred2, batch_y2)\n            loss = loss1 + loss2\n            test_loss += loss.item()\n\n            y_ohe_1 = torch.nn.functional.one_hot(\n                batch_y1, num_classes=num_classes_1\n            ).float()\n            metric_1.update((pred1 > 0.5).int(), y_ohe_1)\n\n            y_ohe_2 = torch.nn.functional.one_hot(\n                batch_y2, num_classes=num_classes_2\n            ).float()\n            metric_2.update((pred2 > 0.5).int(), y_ohe_2)\n\n    test_f1_1 = metric_1.compute().item()\n    test_f1_2 = metric_2.compute().item()\n\n    data.loc[epoch] = {\n        \"Train Loss\": epoch_loss / len(train_loader),\n        \"Train F1 (1)\": train_f1_1,\n        \"Test Loss\": test_loss / len(test_loader),\n        \"Test F1 (1)\": test_f1_1,\n        \"Train F1 (2)\": train_f1_2,\n        \"Test F1 (2)\": test_f1_2,\n    }\n\n    if (epoch + 1) % print_every == 0:\n        print(\n            f\"Epoch {epoch+1}/{epochs}, \"\n            f\"Train Loss: {epoch_loss / len(train_loader):.4f}, \"\n            f\"Train F1 (1): {train_f1_1:.4f}, Test Loss: {test_loss / len(test_loader):.4f}, \"\n            f\"Test F1 (1): {test_f1_1:.4f}, Train F1 (2): {train_f1_2:.4f}, Test F1 (2): {test_f1_2:.4f}\"\n        )"
    },
    "Расчёт статистики для нормализации": {
        "code": "import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\n\nraw_dataset = ImageFolder(\n    \"datasets/images/chars\",\n    transform=T.Compose(\n        [\n            T.Resize((256, 256)),\n            T.ToTensor(),\n        ]\n    ),\n)\n\ndataloader = DataLoader(raw_dataset, 64, shuffle=False)\n\nN = 0\n\nsumm = torch.zeros(3)\nsumm2 = torch.zeros(3)\n\nfor imgs, target in dataloader:\n    summ += imgs.sum(axis=[0, 2, 3])\n    summ2 += (imgs**2).sum(axis=[0, 2, 3])\n    N += imgs.numel() // 3\n\nmean = summ / N\n\nstd = torch.sqrt(summ2 / N - mean**2)"
    },
    "Поиск по латентному представлению": {
        "code": "latents = []\n\npicture = test_dataset[0][0]\nget_hidden_state = model.model\n\nwith torch.no_grad():\n    latent = get_hidden_state(picture.unsqueeze(0))\n\n    for pic, label in test_dataset:\n        latent_new = get_hidden_state(pic.unsqueeze(0))\n        distance = torch.nn.functional.pairwise_distance(latent, latent_new, p=2)\n        latents.append((pic, distance))\n\n    latents.sort(key=lambda x: x[1])\n\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(latents[i][0].permute(1, 2, 0))\n    if i == 0:\n        ax.set_title(\"Original\")\n    else:\n        ax.set_title(f\"Distance: {latents[i][1].item():.2f}\")"
    },
    "я Базовая модель": {
        "code": "# mod\n\n\n\nclass Model(nn.Module):\n\n    def __init__(self, input_size, output_size):\n\n        super(Model, self).__init__()\n\n        self.network = nn.Sequential(\n\n            nn.Linear(input_size, 128),\n            nn.ReLU(),\n            #             nn.Dropout(),\n\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            #             nn.Dropout(),\n\n            nn.Linear(64, output_size),\n        )\n\n\n    def forward(self, x):\n\n        return self.network(x)\n\n\n\ninput_dim = X_train.shape[1]\n\n\n\noutput_dim = y_train.shape[1]  # 2\n\n\n\nmodel = Model(input_dim, output_dim)"
    },
    "я bank оптимизатор": {
        "code": "# bo1\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom torchmetrics.classification import MulticlassAccuracy\n\n\ndef train_model(\n    optimizer_name, model, train_loader, test_loader, epochs=50, print_every=10\n):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optimizer_name(model.parameters(), lr=0.01)\n\n    train_losses = []\n    test_accuracies = []\n\n    accuracy_metric = MulticlassAccuracy(num_classes=2, average=\"macro\")\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n\n        train_losses.append(epoch_loss / len(train_loader))\n        if (epoch + 1) % print_every == 0:\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.4f}\")\n\n        model.eval()\n        all_preds = []\n        all_labels = []\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                preds = torch.argmax(predictions, dim=1)\n                all_preds.append(preds)\n                all_labels.append(batch_y)\n\n        all_preds = torch.cat(all_preds)\n        all_labels = torch.cat(all_labels)\n\n        test_accuracy = accuracy_metric(all_preds, all_labels).item()\n        test_accuracies.append(test_accuracy)\n\n    return train_losses, test_accuracies, all_preds, all_labels\n\n# bo2\n\n\n# Оптимизаторы\noptimizers = {\n    \"SGD\": torch.optim.SGD,\n    \"Adam\": torch.optim.Adam,\n    \"RMSprop\": torch.optim.RMSprop,\n}\n\nresults = {}\n\n# Обучение и сбор результатов\nfor opt_name, opt_func in optimizers.items():\n    print(f\"\\nTraining with {opt_name} optimizer...\")\n    model = Model(input_dim, output_dim)\n    train_losses, test_accuracies, all_preds, all_labels = train_model(\n        opt_func, model, train_loader, test_loader\n    )\n    results[opt_name] = {\n        \"train_losses\": train_losses,\n        \"test_accuracies\": test_accuracies,\n        \"all_preds\": all_preds,\n        \"all_labels\": all_labels,\n    }\n\n# bo3\n\n\nplt.figure(figsize=(12, 6))\n\nfor opt_name, res in results.items():\n    plt.plot(res[\"train_losses\"], label=f\"{opt_name} Train Loss\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Сравнение оптимизаторов (Loss)\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(12, 6))\n\nfor opt_name, res in results.items():\n    plt.plot(res[\"test_accuracies\"], label=f\"{opt_name} Test Accuracy\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Сравнение оптимизаторов (Accuracy)\")\nplt.legend()\nplt.show()\n\n# Отображение confusion matrix и классификационного отчета для каждого оптимизатора\nfor opt_name, res in results.items():\n    print(f\"\\nConfusion Matrix and Classification Report for {opt_name}:\")\n\n    # Отображение confusion matrix\n    plt.figure(figsize=(6, 6))\n    sns.heatmap(\n        confusion_matrix(res[\"all_preds\"], res[\"all_labels\"]),\n        annot=True,\n        fmt=\"d\",\n        cmap=\"Blues\",\n    )\n    plt.title(f\"Confusion Matrix for {opt_name}\")\n    plt.show()\n\n    # Classification report\n    print(classification_report(res[\"all_preds\"], res[\"all_labels\"]))"
    },
    "я bank droupout и веса": {
        "code": "# b1\n\n\n\ndef train_model(model, train_loader, criterion, optimizer, epochs=100, print_every=10):\n\n    losses = []\n\n    for epoch in range(epochs):\n\n        epoch_loss = 0\n        model.train()\n\n\n        for batch_X, batch_y in train_loader:\n\n            optimizer.zero_grad()\n\n\n            outputs = model(batch_X)\n\n            loss = criterion(outputs, batch_y)\n\n            loss.backward()\n\n            optimizer.step()\n\n\n            epoch_loss += loss.item()\n\n\n        losses.append(epoch_loss / len(train_loader))\n\n\n        if (epoch + 1) % print_every == 0:\n\n            print(\n                f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader):.4f}\"\n            )\n\n    return losses\n\n\n\n# Функция для оценки модели\n\n\ndef evaluate_model(model, test_loader):\n\n    y_pred = []\n\n    y_true = []\n\n\n    model.eval()\n\n    with torch.no_grad():\n\n        for batch_X, batch_y in test_loader:\n\n            outputs = model(batch_X)\n\n            _, predicted = torch.max(outputs, 1)\n\n            y_pred.extend(predicted.numpy())\n\n            y_true.extend(batch_y.numpy())\n\n\n    # Вывод confusion matrix и classification report\n\n    print(\"Confusion Matrix:\")\n\n    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n\n    plt.show()\n\n    print(\"\\nClassification Report:\")\n\n\n    print(classification_report(y_true, y_pred))\n\n# b2\n\nmodel1 = Model1(input_size=input_size, output_size=output_size)\nmodel2 = Model2(input_size=input_size, output_size=output_size)\n\n# Определение функции потерь и оптимизатора\ncriterion1 = nn.CrossEntropyLoss(\n    weight=torch.tensor(class_weights, dtype=torch.float32)\n)\ncriterion2 = nn.CrossEntropyLoss(\n    weight=torch.tensor(class_weights, dtype=torch.float32)\n)\noptimizer1 = optim.Adam(model1.parameters(), lr=0.001)\noptimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n\n# Обучение моделей\nprint(\"\\nTraining Model 1...\")\nlosses1 = train_model(\n    model1, train_loader, criterion1, optimizer1, epochs=100, print_every=10\n)\nprint(\"Training Model 2...\")\nlosses2 = train_model(\n    model2, train_loader, criterion2, optimizer2, epochs=100, print_every=10\n)\n\n# Визуализация потерь\n\nplt.plot(range(len(losses1)), losses1, label=\"Model 1\")\nplt.plot(range(len(losses2)), losses2, label=\"Model 2\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss на Training\")\nplt.legend()\nplt.show()\n\n# Оценка моделей\nprint(\"\\nEvaluating Model 1:\")\nevaluate_model(model1, test_loader)\nprint(\"\\nEvaluating Model 2:\")\nevaluate_model(model2, test_loader)"
    },
    "я Gold": {
        "code": "# g1\n\nfrom torchmetrics import MeanAbsolutePercentageError\n\n\ndef train_model(optimizer_name, model, train_loader, test_loader, epochs=100):\n    criterion = nn.MSELoss()\n    optimizer = optimizer_name(model.parameters(), lr=0.01)\n\n    train_losses = []\n    test_losses = []\n    train_mapes = []\n    test_mapes = []\n    mape_metric = MeanAbsolutePercentageError()\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        epoch_mape = 0\n\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n\n            mape = mape_metric(predictions, batch_y)\n            epoch_mape += mape.item()\n\n        train_losses.append(epoch_loss / len(train_loader))\n        train_mapes.append(epoch_mape / len(train_loader))\n        if (epoch + 1) % print_every == 0:\n            print(\n                f\"Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.4f}, MAPE:  {train_mapes[-1]:.4f}\"\n            )\n\n        model.eval()\n        test_loss = 0\n        test_mape = 0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                predictions = model(batch_X)\n                loss = criterion(predictions, batch_y)\n                test_loss += loss.item()\n\n                mape = mape_metric(predictions, batch_y)\n                test_mape += mape.item()\n\n        test_losses.append(test_loss / len(test_loader))\n        test_mapes.append(test_mape / len(test_loader))\n\n    return train_losses, test_losses, train_mapes, test_mapes\n\n# g2\n\n# Оптимизаторы\noptimizers = {\n    \"SGD\": torch.optim.SGD,\n    \"Adam\": torch.optim.Adam,\n    \"RMSprop\": torch.optim.RMSprop,\n}\n\nresults = {}\n\n# Обучение и сбор результатов\nfor opt_name, opt_func in optimizers.items():\n    print(f\"\\nTraining with {opt_name} optimizer...\")\n    model = Model(input_dim, output_dim)\n    train_losses, test_losses, train_mapes, test_mapes = train_model(\n        opt_func, model, train_loader, test_loader\n    )\n    results[opt_name] = {\n        \"train_losses\": train_losses,\n        \"test_losses\": test_losses,\n        \"train_mapes\": train_mapes,\n        \"test_mapes\": test_mapes,\n    }\n\n# g3\nplt.figure(figsize=(12, 6))\n\nfor opt_name, res in results.items():\n    plt.plot(res[\"test_losses\"], label=f\"{opt_name} Test Loss\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"MSE Loss\")\nplt.title(\"Сравнение оптимизаторов на тесте (Loss)\")\nplt.legend()\nplt.show()\n\n\nplt.figure(figsize=(12, 6))\n\nfor opt_name, res in results.items():\n    plt.plot(res[\"test_mapes\"], label=f\"{opt_name} Test MAPE\")\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Mean Absolute Percentage Error на тесте(MAPE)\")\nplt.title(\"Сравнение оптимизаторов (MAPE)\")\nplt.legend()\nplt.show()\n\n# Финальное сообщение\nfor opt_name, res in results.items():\n    final_test_loss = res[\"test_losses\"][-1]\n    final_test_mape = res[\"test_mapes\"][-1]\n    print(\n        f\"{opt_name} - Final Test Loss: {final_test_loss:.4f}, Final Test MAPE: {final_test_mape:.2f}%\"\n    )"
    },
    "1. Модель перцептрона. Проблема линейно неразделимых множеств и ее решение. Логика построения многослойных ИНС. Линейные слои (Linear Layers) в PyTorch..md": {
        "markdown": "## Модель перцептрона \nОдин слой, выполняющий линейную комбинацию входных данных и применяющий активационную функцию $f$\n\n$$\n\\hat y = f(w_0 + w_1 x_1 +\\ ...\\ + w_n x_n) = f(w^T x)\n$$\n![[{AD517AB3-EEEF-493E-A771-80559180ADAA}.png]]\n\n## Проблема линейно неразделимых множеств\nПерцептрон не может решить задачу классификации, если классы не могут быть разделены гиперплоскостью (то есть линейно). Например, задача XOR.\n![[Pasted image 20250106104703.png]]\nДля решения проблемы линейной неразделимости используется **многослойный перцептрон (MLP)**, где несколько слоев позволяют моделировать нелинейные границы раздела, используя нелинейные активационные функции (например, ReLU).\n## Логика построения многослойных ИНС\nВ многослойных ИНС (искусственная нейронная сеть) входной слой передает данные через несколько скрытых слоев, каждый из которых применяет линейную трансформацию и активацию. На выходном слое производится итоговое предсказание.\n## Линейные слои (Linear Layers) в PyTorch\nЛинейный слой выполняет операцию y=x @ W.T+b, где W — матрица весов, b — смещение, x— входные данные, а y — выход. \nВ PyTorch линейный слой создается с помощью torch.nn.Linear(in_features, out_features), аналогичному операции torch.nn.functional.linear(input, weight, bias)\n\n```python\nimport torch\nfrom torch import nn\n  \nin_features = 10\nout_features = 2\n\nlinear_layer = nn.Linear(in_features=in_features, out_features=out_features)\n\nx = torch.randn(2, 10)\n  \n\ntorch.isclose(\n    torch.sum(linear_layer(x)),\n    torch.sum(x @ linear_layer.weight.T + linear_layer.bias)\n\n)\n```\n\n"
    },
    "2. Функции активации. Требования к функциям активации Популярные функции активации. Слои нелинейной активации (Non Linear Activations) в PyTorch..md": {
        "markdown": "## Функции активации\nФункции активации необходимы для того, чтобы нейронные сети могли моделировать нелинейные зависимости. Без них сеть будет эквивалентна линейной модели, что сильно ограничивает её возможности.\n## Требования к функциям активации\n1. **Нелинейность** — функция должна быть нелинейной, чтобы сеть могла решать сложные задачи.\n2. **Дифференцируемость** — функция должна быть **почти всюду** дифференцируемой, чтобы использовать градиентный спуск. (Например, чтобы ReLU была дифференцируема в точке 0 градиент устанавливают в 0)\n3. **Вычислительная эффективность** — функция должна быть вычислительно простой для быстрого обучения.\n## Популярные функции активации\n\n1. **Sigmoid**  \n   $$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$  \n   Функция sigmoid сжимает входные данные в диапазон от 0 до 1. Она используется для задач классификации, но может страдать от проблемы исчезающего градиента.\n\n2. **Tanh**  \n   $$ \\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$  \n   Функция tanh сжимает входные данные в диапазон от -1 до 1. Она решает проблему исчезающих градиентов лучше, чем sigmoid, но всё ещё может её испытывать при больших значениях.\n\n3. **ReLU**  \n   $$ \\text{ReLU}(x) = \\max(0, x) $$  \n   Это наиболее популярная функция активации. Она проста и вычислительно эффективна, но может страдать от проблемы \"мертвых нейронов\", когда выход становится всегда нулевым для отрицательных значений.\n\n4. **Leaky ReLU**  \n   $$ \\text{Leaky ReLU}(x) = \\begin{cases} \n   x & \\text{если } x > 0 \\\\\n   \\alpha x & \\text{если } x \\leq 0 \n   \\end{cases} $$  \n   Модификация ReLU, которая позволяет некоторый маленький наклон для отрицательных значений. Это помогает избежать проблемы мёртвых нейронов.\n\n5. **ELU**  \n   $$ \\text{ELU}(x) = \\begin{cases} \n   x & \\text{если } x > 0 \\\\\n   \\alpha(e^x - 1) & \\text{если } x \\leq 0 \n   \\end{cases} $$  \n   Эта функция активации, как и Leaky ReLU, имеет малый наклон для отрицательных значений, но в отличие от Leaky ReLU она использует экспоненциальную функцию для отрицательных входов, что помогает сети быстрее сходиться.\n\n## Слои нелинейной активации в PyTorch\nВ PyTorch слои активации можно использовать через `torch.nn`:\n1. **ReLU**: `torch.nn.ReLU()`\n2. **Sigmoid**: `torch.nn.Sigmoid()`\n3. **Tanh**: `torch.nn.Tanh()`\n4. **Leaky ReLU**: `torch.nn.LeakyReLU()`\n5. **ELU**: `torch.nn.ELU()`\n\n## Fun fact\nВ последнее время изобрели такую штуку, как линейный слой + активация в 1 и тот же момент.\nПример: **GEGLU** (Gated Linear Unit with GELU), которая показала прирост в архитектуре трансформера\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GEGLU(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(GEGLU, self).__init__()\n        self.linear1 = nn.Linear(input_dim, output_dim)\n        self.linear2 = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        return F.gelu(self.linear1(x)) * self.linear2(x)\n```\n"
    },
    "3. Глубокое обучение. «Вторая весна искусственного интеллекта» и ее причины..md": {
        "markdown": "## Глубокое обучение\nГлубокое обучение — это подмножество машинного обучения, которое использует нейронные сети с большим числом слоев для моделирования сложных зависимостей в данных.\n## «Вторая весна искусственного интеллекта»\n«Вторая весна искусственного интеллекта» (середина 2010-х годов) обозначает период возрождения интереса к искусственному интеллекту, когда достигнуты значительные успехи в применении глубоких нейронных сетей.\n## Причины возрождения\n- **Рост вычислительных мощностей**  \n    С появлением более мощных графических процессоров (GPUs), которые были адаптированы для ускорения вычислений матричных операций, стало возможным обучать глубокие нейронные сети быстрее и на больших объемах данных.\n- **Доступность больших данных**  \n    В 2012 году объемы данных значительно выросли благодаря развитию интернета, социальных сетей, смартфонов и других цифровых технологий. Это обеспечило необходимый масштаб тренировочных данных для глубоких нейронных сетей, что значительно улучшило их производительность.\n- **Прорывные алгоритмы и архитектуры**  \n    Исследователи, такие как Алекс Крижевский, Джеффри Хинтон и их коллеги, продемонстрировали, что глубокие сверточные нейронные сети (CNNs) могут значительно превосходить другие подходы в задачах компьютерного зрения. Их модель AlexNet стала важной вехой, так как впервые победила в ImageNet Challenge 2012 с большим отрывом от конкурентов.\n### Обратное распространение ошибки\n**Обратное распространение ошибки (Backpropagation)** — это алгоритм, используемый для обучения нейронных сетей. Основная идея заключается в том, чтобы вычислить градиенты ошибки сети относительно её параметров (весов и смещений), используя метод обратного прохода. Эти градиенты затем используются для обновления параметров с помощью оптимизационного алгоритма, такого как градиентный спуск.\n\nАлгоритм состоит из трёх этапов:\n1. **Прямой проход**  \n    Входные данные проходят через нейронную сеть, и на выходе вычисляется ошибка (например, с помощью функции потерь).\n2. **Обратный проход**  \n    Ошибка распространяется назад через сеть, слой за слоем, с помощью цепного правила (chain rule) дифференцирования, чтобы вычислить градиенты для каждого параметра сети.\n3. **Обновление параметров**  \n    Градиенты используются для обновления весов сети, уменьшая ошибку с каждым шагом итерации.\n### Что позволило создать модель AlexNet\n1. **Использование GPU**  \n    Алекс Крижевский адаптировал модель для работы с графическими процессорами, что ускорило процесс обучения глубоких сетей, состоящих из миллионов параметров.\n2. **ReLU-активация**  \n    AlexNet ввела в широкое использование функцию активации ReLU (Rectified Linear Unit), которая ускоряет сходимость обучения за счет устранения проблемы затухающих градиентов.\n3. **Регуляризация**  \n    Модель использовала метод Dropout для предотвращения переобучения, что позволило улучшить обобщающую способность сети.\n4. **Большие данные**  \n    AlexNet обучалась на массивном наборе данных ImageNet, который содержал миллионы размеченных изображений, обеспечив сеть большим объемом разнообразной информации для тренировки."
    },
    "4. Проблема поиска градиента в общей логике обучения нейронной сети. Градиент функции многих переменных. Методы вычисления..md": {
        "markdown": "## Проблема поиска градиента\nВ обучении нейронных сетей основная задача — вычисление градиента функции потерь по всем параметрам модели. \nПроблемы могут возникать из-за большого количества параметров, высокой сложности функций (а следовательно большого количества локальных минимумов/максимумов) и нестабильности (исчезающие или взрывающиеся градиенты).\n## Градиент функции многих переменных\nГрадиент функции многих переменных — это вектор частных производных. Для функции потерь L(w1, w2, ..., wn):\n\n$$\n\\nabla L = \\left( \\frac{\\partial L}{\\partial w_1}, \\frac{\\partial L}{\\partial w_2}, ..., \\frac{\\partial L}{\\partial w_n} \\right)\n$$\n\nГрадиент указывает направление наибольшего роста функции, а в обучении он используется в противоположном направлении для минимизации функции ошибки.\n## Методы вычисления\n1. **Обратное распространение ошибки (Backpropagation)**  \n   Использует правило цепочки для эффективного вычисления производных. Начинается с выходного слоя и идет обратно к входному, обновляя веса на каждом этапе.\n   [[Линейное отображение. Векторно-матричное дифференцирование.#^fafd8c|Подробный пример]]\n   \n   Одной из библиотек, предоставляющих инструменты для дифференцируемого программирования, делающих процесс обучения нейронных сетей удобным и гибким, является Torch (PyTorch на python). Она автоматически вычисляет градиенты благодаря механизму автоматического дифференцирования, упрощая реализацию и использование обратного распространения ошибки.\n2. **Численный метод конечных разностей (Finite Difference)**  \n   Вычисляет приближение градиента с помощью разностей:\n   $$\n   \\frac{\\partial L}{\\partial x_i} \\approx \\frac{L(x + h) - L(x-h)}{2h}\n   $$\n   Этот метод медленный и подвержен численной ошибке, но прост в реализации."
    },
    "5. Кросс-валидация. Выборки train, validation, test. Проблема переобучения. Ранняя остановка..md": {
        "markdown": "Кросс-валидация — это метод оценки модели, при котором данные разбиваются на несколько частей (**folds**). Модель обучается на одной части данных и тестируется на другой, чтобы получить устойчивую оценку качества. Этот метод помогает уменьшить влияние случайных факторов, связанных с конкретным разбиением данных.\n### Основные виды кросс-валидации\n#### 1. **k-fold кросс-валидация**\n- Данные делятся на $k$ равных частей (folds).\n- Обучение проводится $k$ раз:\n  - Каждый раз $k-1$ частей используются для обучения.\n  - Оставшаяся часть используется для тестирования.\n- Итоговая метрика — среднее значение метрики на всех $k$ итерациях.\n**Плюсы:**\n- Устойчивость оценки качества за счёт использования всех данных.\n- Универсальность для любых размеров данных.\n**Минусы:**\n- Требует $k$-кратного обучения, что увеличивает время расчёта.\n#### 2. **Leave-One-Out Cross-Validation (LOOCV)**\n- Специальный случай $k$-fold кросс-валидации, где $k = n$ (число примеров в выборке).\n- На каждой итерации:\n  - Один пример оставляется для тестирования.\n  - Остальные $n-1$ примеров используются для обучения.\n**Пример:**\nЕсли в наборе данных 100 наблюдений, то модель обучается 100 раз, каждый раз тестируя её на одном наблюдении.\n**Плюсы:**\n- Максимально эффективное использование данных, так как каждая точка используется для тестирования.\n- Подходит для небольших наборов данных.\n**Минусы:**\n- Очень затратен по времени для больших выборок, так как требует $n$-кратного обучения.\n#### 3. **Stratified k-fold**\n- Модификация $k$-fold, при которой разбиение данных производится с сохранением пропорций классов.\n- Используется для несбалансированных данных, где важно сохранять распределение классов в каждом fold.\n**Плюсы:**\n- Уменьшает риск переобучения на несбалансированных данных.\n#### 4. **Time Series Split**\n- Подходит для временных рядов, где порядок данных имеет значение.\n- Данные делятся на несколько итераций так, чтобы каждая следующая часть тестовых данных находилась позже обучающей.\n**Пример:**\n1. На первом шаге обучаем модель на первых 70% данных и тестируем на следующих 10%.\n2. На следующем шаге добавляем ещё 10% в обучающую выборку, а тестируем на следующих 10%.\n**Плюсы:**\n- Сохраняет временную последовательность.\n#### 5. **Shuffle-Split Cross-Validation**\n- Данные случайным образом разбиваются на обучающие и тестовые наборы заданное число раз.\n**Плюсы:**\n- Гибкость в отношении размера тестовой и обучающей выборки.\n- Полезен, если важен контроль над размерами подвыборок.\n**Минусы:**\n- Не подходит для временных рядов.\n### Сравнение методов\n| Метод                  | Итерации | Использование данных | Подходит для больших данных | Сложность |\n|-------------------------|----------|-----------------------|-----------------------------|-----------|\n| k-fold                 | k        | Все данные            | Да                          | Умеренная |\n| Leave-One-Out (LOOCV)  | n        | Все данные            | Нет                         | Высокая   |\n| Stratified k-fold      | k        | Все данные            | Да                          | Умеренная |\n| Time Series Split      | Зависит от набора | Частичное         | Да                          | Умеренная |\n| Shuffle-Split          | Настраиваемое     | Возможно частичное| Да                          | Низкая    |\n### Применение в Python\nБольшинство из видов кросс-валидации реализованы внутри пакета sklearn.model_selection\n## Выборки train, validation, test\n1. **Train**: используется для обучения модели.\n2. **Validation**: служит для подбора гиперпараметров и проверки качества модели в процессе обучения.\n3. **Test**: применяется для итоговой оценки модели на ранее невиданных данных.\nДанные должны быть разделены таким образом, чтобы тестовая выборка оставалась полностью изолированной во время обучения и настройки модели.\n## Проблема переобучения\nПереобучение возникает, когда модель слишком хорошо подстраивается под обучающую выборку, теряя способность обобщать на новых данных. Симптомы переобучения:\n- Высокая точность на обучающей выборке.\n- Низкая точность на валидационной или тестовой выборке.\n![[Pasted image 20250106113735.png]]\n## Ранняя остановка\nРанняя остановка — это метод предотвращения переобучения. \nВ процессе обучения, если ошибка (либо любая иная мера качества модели) на валидационной выборке перестает уменьшаться (или начинает расти) за какое-то количество (в формуле буква k) шагов, обучение прекращается. Это позволяет сохранить модель, которая лучше всего обобщает данные.\n\nФормально, если L — функция потерь на валидационной выборке, то обучение прекращается, когда:\n\n$$\nL_{\\text{val}}(t) < \\min \\{ L_{\\text{val}}(t-1), L_{\\text{val}}(t-2), \\dots, L_{\\text{val}}(t-k) \\}\n$$\n\nгде t — номер эпохи."
    },
    "6. Преобразование Softmax и функция потерь Cross Entropy loss..md": {
        "markdown": "## Преобразование Softmax\n\nSoftmax преобразует выходы модели в вероятности, распределенные по классам. Формула для класса i:\n\n$$\n\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n$$\n\nгде z_i — логит (выход сети) для класса i, n — общее количество классов. Сумма всех вероятностей равна 1.\n**Softmax** лучше просто **max**, потому что:\n1. Это мягкая версия max, которая сохраняет информацию о всех классах, а не только о максимальном.\n2. Его выводы интерпретируются как вероятности, поскольку значения находятся в диапазоне \\[0,1\\] и их сумма равна 1.\n3. Softmax дифференцируем, что делает его пригодным для обучения нейронных сетей с помощью градиентного спуска.\nРеализация на torch:\n```python\ndef softmax(x):\n    exp_x = torch.exp(x)\n    return exp_x / exp_x.sum(dim=-1, keepdim=True)\n```\n## Функция потерь Cross Entropy loss\nCross Entropy измеряет разницу между предсказанными вероятностями p и истинным распределением y. Формула:\n\n$$\nL = -\\sum_{i=1}^{n} y_i \\log(p_i)\n$$\n\nгде y_i — истинное значение (1 для правильного класса, 0 для остальных), p_i — вероятность, предсказанная для класса i.\nДля одного истинного класса y:\n\n$$\nL = -\\log(p_y)\n$$\n### Бинарный случай\nBinary Cross Entropy используется для задач бинарной классификации. Она измеряет разницу между предсказанным значением p и истинным значением y для каждой выборки. Формула: $$ L = - \\left( y \\log(p) + (1 - y) \\log(1 - p) \\right) $$\n## Связь между Softmax и Cross Entropy\nSoftmax используется для преобразования логитов в вероятности, а Cross Entropy применяет эти вероятности для оценки ошибки. \nЭто комбинация используется для обучения моделей для задачи классификации."
    },
    "7. Механизм обратного распространения ошибки. Принципиальная логика основного цикла обучения нейронной сети в PyTorch. Слои функций потерь (Loss Functions) в PyTorch..md": {
        "markdown": "## Механизм обратного распространения ошибки\nОбратное распространение ошибки (backpropagation) — это алгоритм вычисления градиентов для всех параметров нейронной сети. Он основан на применении правила цепочки для обновления весов. Основные шаги:\n1. Вычисление функции потерь L на основе предсказания модели y_pred и истинного значения y_true.\n2. Вычисление градиента функции потерь по параметрам модели с помощью правила цепочки (по значению для прохода дальше, по параметрам для обновления весов)\n3. Обновление параметров с использованием градиентного спуска:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде w — веса модели, η — скорость обучения.\nПодробный пример\n[[Линейное отображение. Векторно-матричное дифференцирование.#^fafd8c|Пример]]\n## Принципиальная логика основного цикла обучения нейронной сети в PyTorch\n1. **Прямой проход**: входные данные проходят через сеть, и вычисляется выход y_pred.\n2. **Вычисление потерь**: функция потерь оценивает разницу между y_pred и y_true.\n3. **Обратный проход**: выполняется backpropagation с вызовом loss.backward(), чтобы вычислить градиенты.\n4. **Обновление параметров**: оптимизатор обновляет веса, например, с помощью optimizer.step().\n5. **Очистка градиентов**: после обновления необходимо обнулить градиенты, используя optimizer.zero_grad().\nМогут быть добавлены любые иные дополнительные шаги, такие как scheduler для learning rate или подсчёт метрик\nПример цикла в PyTorch:\n\n```python\n...\nfor batch in data_loader:\n    optimizer.zero_grad()\n    y_pred = model(batch['input'])\n    loss = loss_fn(y_pred, batch['target'])\n    loss.backward()\n    optimizer.step()\n...\n```\n[[Основной цикл обучения|Схема]]\n### Макрушинская картинка\n![[Pasted image 20250121232023.png]]\n## Слои функций потерь в PyTorch\nФункции потерь используются для оптимизации модели, принимая предсказания и истинные значения. Их выбор зависит от типа задачи, например, классификация или регрессия.\nPyTorch предоставляет широкий набор функций потерь, которые используются для обучения моделей, оценивая разницу между предсказаниями и истинными значениями.\n## MSELoss\nИспользуется для регрессии. Формула:\n\n$$\nL = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred}_i} - y_{\\text{true}_i})^2\n$$\n\nПример в torch:\nloss_fn = torch.nn.MSELoss()\nloss = loss_fn(predictions, targets)\n\n## CrossEntropyLoss\nИспользуется для многоклассовой классификации, комбинируя softmax и cross entropy. Формула:\n\n$$\nL = -\\sum_{i=1}^{n} y_i \\log(p_i)\n$$\n\nПример в torch:\nloss_fn = torch.nn.CrossEntropyLoss()\nloss = loss_fn(predictions, targets)\n\n## BCELoss\nПрименяется для бинарной классификации. Формула:\n\n$$\nL = - \\left( y \\log(p) + (1 - y) \\log(1 - p) \\right)\n$$\n\nПример в torch:\nloss_fn = torch.nn.BCELoss()\nloss = loss_fn(predictions, targets)\n## SmoothL1Loss\nИспользуется для задач регрессии с шумными данными. Формула:\n\n$$\nL = \\begin{cases} \n0.5 (y_{\\text{pred}} - y_{\\text{true}})^2, & \\text{если } |y_{\\text{pred}} - y_{\\text{true}}| < 1 \\\\\n|y_{\\text{pred}} - y_{\\text{true}}| - 0.5, & \\text{иначе}\n\\end{cases}\n$$\n\nПример в torch:\nloss_fn = torch.nn.SmoothL1Loss()\nloss = loss_fn(predictions, targets)\n\n"
    },
    "8. Дифференцируемое программирование и реализация обратного распространения ошибки. Автоматическое дифференцирование в PyTorch. Пример и применение в обучении ИНС..md": {
        "markdown": "## Дифференцируемое программирование\nПодход, позволяющий интегрировать традиционное программирование с нейросетями, чтобы оптимизировать не только параметры модели, но и встроенные вычислительные операции. Основной механизм — автоматическое дифференцирование.\n## Реализация обратного распространения ошибки\nОбратное распространение ошибки использует градиенты функции потерь для обновления параметров:\n1. Вычисляется прямая проходка (forward pass) и значение функции потерь.\n2. Используются правила дифференцирования для вычисления градиентов параметров через цепное правило:\n$$\n\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial w}\n$$\nгде \\( L \\) — функция потерь, \\( w \\) — параметры.\n## Автоматическое дифференцирование в PyTorch\nPyTorch использует библиотеку `torch.autograd` для автоматического вычисления градиентов. При выполнении операций с тензорами создается вычислительный граф, позволяющий эффективно находить градиенты.\n\nВ общем случае все функции являются подклассом torch.autograd.Function и реализуют метод backward, который используется вычислительным графом для подсчёта градиентов\n```python\nimport torch\n\nclass MyFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input):\n        ctx.save_for_backward(input) # cохранение входа для последующего использования в backward\n        return input ** 2  # x^2\n\n    @staticmethod\n    def backward(ctx, grad_output):\n\t    # grad_output - градиенты более поздних функций\n\t    # grad_output * текущая_производная -> правило цепочки\n        input, = ctx.saved_tensors\n        grad_input = 2 * input * grad_output\n        return grad_input\n\n```\n## Конкретный пример\n# Инициализация переменных\n```python\nimport torch\n\nx = torch.tensor(2.0, requires_grad=True)\ny = x ** 2 + 3 * x + 5\n```\n# Обратное распространение\n```\ny.backward()\nprint(x.grad)  # Градиент dy/dx\n```\n## Пример и применение в обучении ИНС\nВ обучении нейронных сетей PyTorch использует автоматическое дифференцирование для оптимизации параметров.\n\nПример:\n```\nimport torch.nn as nn\nimport torch.optim as optim\n```\n\n# Пример модели\n```\nmodel = nn.Linear(1, 1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n```\n# Прямой проход\n```\ninput = torch.tensor([[1.0]])\ntarget = torch.tensor([[2.0]])\noutput = model(input)\nloss = criterion(output, target)\n```\n# Обратное распространение и обновление параметров\n```\nloss.backward()\noptimizer.step()\n```\n## Применение\n1. Оптимизация параметров в нейронных сетях.\n2. Использование нестандартных вычислений в графах (например, нестандартные функции потерь).\n3. Интеграция традиционных алгоритмов с градиентными методами.\n## Схема прямого распространения\n![[Pasted image 20250121232940.png]]\n## Схема обратного распространения\n![[Pasted image 20250122000646.png]]\n![[Pasted image 20250121232858.png]]"
    },
    "9. Стохастический градиентный спуск. Батчи обучающей выборки..md": {
        "markdown": "## Стохастический градиентный спуск\n\nСтохастический градиентный спуск (SGD) — это метод оптимизации, который обновляет параметры модели на основе градиента функции потерь, вычисленного для одной или нескольких случайно выбранных выборок. \nЭто ускоряет обучение и снижает вычислительные затраты по сравнению с классическим градиентным спуском (использующим в каждой итерации весь датасет).\nОбновление весов для параметра w:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\nгде:\n- w — параметр модели,\n- η — скорость обучения,\n- L — функция потерь.\n## Батчи обучающей выборки\n\n^1bc4f3\n\nБатчи — это небольшие подмножества обучающей выборки, используемые для вычисления градиента. Они позволяют балансировать между скоростью обучения и точностью градиента.\n1. **Полный градиентный спуск** (Batch Gradient Descent):\n   Использует всю обучающую выборку для одного обновления весов. Это медленно и вычислительно затратно.\n2. **Стохастический градиентный спуск** (Stochastic Gradient Descent):\n   Использует одну случайную выборку для обновления. Это быстро, но может быть нестабильным.\n3. **Мини-батч градиентный спуск** (Mini-Batch Gradient Descent):\n   Использует случайные батчи размера b, что стабилизирует обучение. Градиент рассчитывается как среднее:\n$$\n\\frac{1}{b} \\sum_{i=1}^{b} \\frac{\\partial L_i}{\\partial w}\n$$\n\nгде b — размер батча, L_i — функция потерь для i-го примера.\n![[Pasted image 20250106155400.png]]\n## Преимущества использования батчей\n1. Снижение вычислительных затрат по сравнению с полным градиентным спуском.\n2. Стабильность обучения по сравнению с использованием одной выборки.\n3. Возможность использовать аппаратное ускорение (GPU) для параллельной обработки батчей\n## Реализация на PyTorch\n```python\n...\n# Batch Gradient Descent (весь датасет за раз)\noutputs = X @ weights\nloss = torch.mean((outputs - y) ** 2)\nloss.backward()\nweights.data -= learning_rate * weights.grad\nweights.grad.zero_()\n...\n```\n```python\n...\n# Mini-Batch Gradient Descent (по batch_size примеров)\nbatch_size = 10 \nfor i in range(0, len(X), batch_size): \n\tX_batch = X[i:i+batch_size] \n\ty_batch = y[i:i+batch_size] \n\toutputs = X_batch @ weights \n\tloss = torch.mean((outputs - y_batch) ** 2) \n\tloss.backward() \n\tweights.data -= learning_rate * weights.grad \n\tweights.grad.zero_()\n...\n```\n```python\n# Stochastic Gradient Descent (по 1 примеру)\nfor i in range(len(X)):\n    X_sample = X[i:i+1]\n    y_sample = y[i:i+1]\n    outputs = X_sample @ weights\n    loss = torch.mean((outputs - y_sample) ** 2)\n    loss.backward()\n    weights.data -= learning_rate * weights.grad\n    weights.grad.zero_()\n```\n"
    },
    "10. Адаптивные методы градиентного спуска. Метод импульсов. Метод Нестерова..md": {
        "markdown": "## Адаптивные методы градиентного спуска\nАдаптивные методы изменяют скорость обучения для каждого параметра на основе прошлых градиентов. Это ускоряет сходимость и делает обучение более стабильным.\n### AdaGrad\nAdaGrad уменьшает шаг обучения для часто изменяющихся параметров и увеличивает для редко обновляемых:\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{G + \\epsilon}} \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде G — сумма квадратов прошлых градиентов, ε — небольшое значение для избегания деления на ноль. (Больше градиент -> меньше learning rate)\n### RMSProp\nRMSProp улучшает AdaGrad, используя экспоненциальное сглаживание для суммы квадратов градиентов:\n\n$$\nG_t = \\beta G_{t-1} + (1 - \\beta) \\left( \\frac{\\partial L}{\\partial w} \\right)^2\n$$\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\cdot \\frac{\\partial L}{\\partial w}\n$$\nгде β — коэффициент сглаживания, позволяет настраивать оптимизатор чтобы учитывать менее недавние изменения градиента, а не долгосрочные\n## Метод импульсов (Momentum)\nМетод импульсов ускоряет сходимость, добавляя накопление прошлых градиентов:\n\n$$\nv_t = \\gamma v_{t-1} + \\eta \\frac{\\partial L}{\\partial w}\n$$\n\n$$\nw = w - v_t\n$$\n\nгде γ — коэффициент импульса, v_t-1 добавляет \"инерцию\", помогая ускоряться вдоль направлений с постоянными градиентами. Это позволяет модели быстрее сходиться к минимуму, избегая колебаний. \n## Метод Нестерова\nМетод Нестерова, или ускоренный градиент Нестерова (Nesterov Accelerated Gradient, NAG), — это модификация градиентного спуска с моментом, направленная на ускорение сходимости и повышение стабильности обучения. За счёт дополнительного предсказательного шага вычислительно сложнее, так как содержит ещё одно предсказание\n**Основные формулы метода Нестерова:**\n1. **Предварительное обновление параметров:**\n   $$\n   \\tilde{\\theta}_t = \\theta_t + \\mu v_{t-1}\n   $$\n   где:\n   - $\\theta_t$ — параметры модели на итерации $t$,\n   - $\\mu$ — коэффициент моментума (обычно $0 \\leq \\mu < 1$),\n   - $v_{t-1}$ — скорость (накопленный градиент) на предыдущей итерации.\n2. **Вычисление градиента в предсказанной точке:**\n   $$\n   g_t = \\nabla f(\\tilde{\\theta}_t)\n   $$\n   где $f$ — функция потерь, $\\nabla f(\\tilde{\\theta}_t)$ — градиент функции потерь, вычисленный в точке $\\tilde{\\theta}_t$.\n3. **Обновление скорости:**\n   $$\n   v_t = \\mu v_{t-1} - \\eta g_t\n   $$\n   где:\n   - $\\eta$ — скорость обучения (learning rate),\n   - $g_t$ — градиент, вычисленный в предсказанной точке.\n4. **Обновление параметров модели:**\n   $$\n   \\theta_{t+1} = \\theta_t + v_t\n   $$\n \nТаким образом, метод Нестерова сначала предсказывает будущее положение параметров с учётом моментума, затем вычисляет градиент в этой предсказанной точке и обновляет параметры, что позволяет более эффективно двигаться в направлении минимума функции потерь.\n### Adam\nAdam объединяет идеи RMSProp и момента, учитывая как среднее значение градиентов (импульсы), так и их квадраты (частота обновления параметров):\n\n$$\nm_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\frac{\\partial L}{\\partial w}\n$$\n\n$$\nv_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\left( \\frac{\\partial L}{\\partial w} \\right)^2\n$$\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\cdot \\hat{m}_t\n$$\n\nгде $\\hat{m}_t$ и $\\hat{v}_t$ — скорректированные значения моментов, комбинирует описанные подходы. Метод более универсален, из-за чего имеет 2 дополнительных гиперпараметра $\\beta_1$ и $\\beta_2$ для корректировки длительности влияния предыдущих \n## Интерпретация\nВсе оптимизаторы рано или поздно сойдутся, разница лишь в том, что:\n - Сколько времени для этого понадобится\n - Застрянут ли они в локальном минимуме (метод моментов не застрянет, но может на импульсе улететь не туда)\n - Насколько сложно подобрать гиперпараметры (тот же Adam использует и штраф на веса и моменты, что добавляет два гиперпараметра, про которые нужно помнить)\n![[0_BebGrMQvpKgGOawq.gif]]\n![[0_-N56aP3ka9hTvCzJ.gif]]\n## Вывод\nОптимизатор по своей сути ещё один гиперпараметр, выбираемые для обучения сети. В каждой задаче могут быть качественные различия между ними. AdamW (W - weighted, позволяет добавлять регуляризацию на веса модели) является сильным baselin'ом в подавляющем большинстве ситуаций.\n![[Pasted image 20250106160741.png]]\nВ настоящее время также существует множество оптимизаторов, показывающих себя когда-то лучше, чем AdamW.\nНапример:\n[Lion - Evo**L**ved S**i**gn M**o**me**n**tum](https://github.com/lucidrains/lion-pytorch)"
    },
    "11. Проблема инициализации весов при обучении ИНС. Инициализация Ксавье..md": {
        "markdown": "## Проблема инициализации весов\nПри обучении нейронных сетей некорректная инициализация весов может привести к следующим проблемам:\n1. **Исчезающие градиенты**:\n   При слишком маленьких начальных значениях весов градиенты становятся малы, что замедляет обучение.\n2. **Взрывающиеся градиенты**:\n   При слишком больших начальных значениях весов градиенты становятся большими, что приводит к нестабильности и невозможности сходимости.\n3. **Несбалансированное обучение**:\n   Если веса инициализируются одинаково (например, с нуля), все нейроны одного слоя будут обучаться одинаково, что снижает эффективность сети.\n## Инициализация Ксавье\nИнициализация Ксавье (или Glorot инициализация) решает проблему стабильного распределения значений через сеть. Она контролирует дисперсию активаций и градиентов, чтобы оставаться примерно одинаковой на всех слоях.\n### Идея\nВес w инициализируется случайным образом с распределением, зависящим от числа входов $n_{in}$ и выходов  $n_{out}$) для слоя:\n\n1. Для равномерного распределения:\n   $$\n   w \\sim U\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{\\text{in}} + n_{\\text{out}}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{\\text{in}} + n_{\\text{out}}}}\\right]\n   $$\n\n2. Для нормального распределения:\n   $$\n   w \\sim N\\left(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\\right)\n   $$\n\n### Преимущества\n1. Сохраняет стабильные значения активаций и градиентов через слои, что позволяет избежать взрыв и затухание градиентов (стабильность через равенство Var(W⋅x)≈Var(x) которое выполняется с помощью учёта количества параметров в слое в знаменателе другой в формулах выше)\n2. Улучшает скорость сходимости модели из-за отсутствия симметрии (а значит сложнее застрять в локальном минимуме)\n3. Особенно эффективна для сети с функциями активации, такими как tanh или сигмоида (так как для них большие и малые значения активаций наиболее критичны).\n## Применение в PyTorch\nВ PyTorch инициализация Ксавье доступна через модуль `torch.nn.init`:\n\n```python\nimport torch\nimport torch.nn as nn\n\nlayer = nn.Linear(in_features, out_features)\ntorch.nn.init.xavier_uniform_(layer.weight)\n```\n\nИзначально nn.Linear инициализируется с помощью с использованием **Kaiming Uniform Initialization** с параметром a=$\\sqrt5$, что отлично подходит для таких функций активации, как ReLU\n```python\n...\n# один из методов nn.Linear, который используется при инициализации слоя\n def reset_parameters(self) -> None:\n        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n        # https://github.com/pytorch/pytorch/issues/57109\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n...​\n```\n"
    },
    "12. Переобучение модели и регуляризация. Принцип механизма Dropout. Слои регуляризации (Dropout Layers) в PyTorch..md": {
        "markdown": "## Переобучение модели\nПереобучение происходит, когда модель слишком хорошо запоминает обучающие данные, но плохо обобщает новые данные. Это приводит к огромной разнице в метриках на train и test наборах данных\nКлассическое переобучение с деревьями большой глубины изображено на картинках ниже\n## Train\n![[Pasted image 20250121235754.png]]\n## Test\n![[Pasted image 20250121235803.png]]\n## Регуляризация\nРегуляризация уменьшает переобучение, добавляя ограничения на параметры при обучении модели. Основные методы:\n1. L1/L2-регуляризация (штрафы на большие значения весов).\n2. Dropout (отключение нейронов во время обучения).\n## Принцип механизма Dropout\nDropout случайным образом отключает определенные нейроны с вероятностью p во время обучения, что уменьшает зависимость между нейронами. Это улучшает обобщающую способность модели, так как нейроны стараются более универсально подходить к задаче.\nМатематически, на каждом шаге:\n$$\nh_i = z_i \\cdot a_i\n$$\nгде $$z_i \\sim Bernoulli(1 - p)$$,  a_i — активация нейрона, h_i  — итоговый выход.\n![[Pasted image 20250106170114.png]]\nДропаут работает, потому что заставляет модель адаптироваться и не полагаться слишком сильно на отдельные признаки (которые могут в конкретном сэмпле быть None или не быть значимыми). Это создаёт эффект ансамбля моделей, улучшает обобщающую способность и снижает переобучение.\n## Слои регуляризации (Dropout Layers) в PyTorch\nDropout применяется как слой регуляризации в нейросетях. Во время тестирования он отключается автоматически.\n\nПример:\nimport torch.nn as nn\ndropout = nn.Dropout(p=0.5)\n\ninput_tensor = torch.randn(1, 10)\noutput_tensor = dropout(input_tensor)\n\n## Пример использования в модели\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(10, 50)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(50, 1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = nn.ReLU()(x)\n        x = self.dropout(x)\n        return self.fc2(x)\n\n## train и eval режимы модели\nВ связи с тем, что поведение некоторых слоёв (dropout или batchnorm слои) меняется про тренировке и инференсе, модели реализуют несколько состояний.\nmodel.train() переводит модель в режим обучения (например, включается dropout)\nmodel.eval() отключает dropout или накопление статистик для batchnorm, что позволяет правильно оценивать производительность модели"
    },
    "13. Минибатчи – причина использования. Нормализация по мини-батчам. Слои нормализации (Normalization Layers) в PyTorch..md": {
        "markdown": "## Минибатчи – причина использования\nМинибатчи разбивают данные на небольшие группы для обработки:\n1. Снижают затраты памяти, позволяя обучать модель на больших наборах данных.\n2. Ускоряют обучение за счет обновления весов чаще, чем при использовании всего набора данных.\n3. Сглаживают процесс оптимизации, уменьшая вероятность застревания в локальных минимумов.\n[[9. Стохастический градиентный спуск. Батчи обучающей выборки.#^1bc4f3|Более подробно]]\n## Основные слои нормализации (Normalization Layers) в PyTorch\n| Характеристика           | Batch Normalization                                                       | Layer Normalization                                 | RMS Normalization                                                                      |\n| ------------------------ | ------------------------------------------------------------------------- | --------------------------------------------------- | -------------------------------------------------------------------------------------- |\n| **Область нормализации** | Нормализация по батчу (по столбцам)                                       | Нормализация по всем признакам объекта (по строкам) | Нормализация по корню среднеквадратичного значения всех признаков объекта (по строкам) |\n| **Статистики**           | Зависит от минибатча                                                      | Независима от минибатча                             | Независима от минибатча                                                                |\n| **Области применения**   | CNN (пространственные данные)                                             | RNN, Transformer (последовательности)               | Transformer, упрощенные нормализации                                                   |\n| **Проблемы**             | Зависимость от размера батча (большой для адекватного подсчёта статистик) | Не учитывает пространственную структуру батча       | Простота, из-за чего менее универсален                                                 |\n| **Обучаемые параметры**  | $\\gamma$ (масштаб) и $\\beta$ (смещение)                                   | $\\gamma$ (масштаб) и $\\beta$ (смещение)             | $\\gamma$ (масштаб)                                                                     |\n## Устройство Batch Normalization (нормализация по мини-батчам)\n\nBatch Normalization нормализует значения для каждого признака в рамках текущего мини-батча. Это помогает стабилизировать обучение, ускорить сходимость и улучшить обобщающую способность модели.\n\nФормула:\n\n$\\hat{x}_i = \\frac{x_i - \\mu_{\\text{batch}}}{\\sqrt{\\sigma^2_{\\text{batch}} + \\epsilon}}$\n\nгде $\\mu_{\\text{batch}}$ и $\\sigma^2_{\\text{batch}}$ вычисляются для каждого признака внутри текущего батча:\n\n$\\mu_{\\text{batch}} = \\frac{1}{N} \\sum_{j=1}^N x_j, \\quad \\sigma^2_{\\text{batch}} = \\frac{1}{N} \\sum_{j=1}^N (x_j - \\mu_{\\text{batch}})^2$\n\nгде $N$ — количество объектов в батче.\n### Обучаемые параметры\n\nBatch Normalization включает два обучаемых параметра: $\\gamma$ (масштаб) и $\\beta$ (сдвиг). После нормализации по формуле выше, нормализованные значения масштабируются и сдвигаются:\n$y_i = \\gamma \\hat{x}_i + \\beta$\nЭти параметры обучаются вместе с остальными весами модели, позволяя адаптировать нормализацию для оптимальной производительности.\n### Накапливаемые статистики\nВо время обучения Batch Normalization отслеживает:\n- **Среднее значение ($\\mu_{\\text{running}}$)**: скользящее среднее по всем мини-батчам.\n- **Дисперсия ($\\sigma^2_{\\text{running}}$)**: скользящее среднее дисперсий всех мини-батчей.\nЭти статистики используются на этапе инференса (прогнозирования), чтобы нормализация была стабильной даже при подаче отдельных примеров или данных, отличающихся от обучающего набора.\n$\\mu_{global} \\leftarrow \\alpha \\cdot \\mu_{global} + (1 - \\alpha) \\cdot \\mu_{batch}$\n$\\sigma^2_{global} \\leftarrow \\alpha \\cdot \\sigma^2_{global} + (1 - \\alpha) \\cdot \\sigma^2_{batch}$\nгде $\\alpha$ — коэффициент сглаживания.\n## Пример реализации BatchNorm в PyTorch\n\n```python\nimport torch.nn as nn\n\nbatch_norm = nn.BatchNorm1d(num_features=10)\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = batch_norm(input_tensor)\n```\n## Устройство Layer Normalization\nLayer Normalization нормализует значения по всем признакам внутри одного объекта, вместо использования статистик батча. \n\nФормула:\n$$\n\\hat{x}_i = \\frac{x_i - \\mu_{layer}}{\\sqrt{\\sigma^2_{layer} + \\epsilon}}\n$$\nгде $\\mu_{layer}$ и $\\sigma^2_{layer}$ вычисляются для каждого объекта индивидуально:\n$$\n\\mu_{layer} = \\frac{1}{H} \\sum_{j=1}^H x_j, \\quad \\sigma^2_{layer} = \\frac{1}{H} \\sum_{j=1}^H (x_j - \\mu_{layer})^2\n$$\nгде H — количество признаков.\n\n### Обучаемые параметры\nLayer Normalization включает два обучаемых параметра: $\\gamma$ (масштаб) и $\\beta$ (сдвиг). После нормализации по формуле выше, нормализованные значения масштабируются и сдвигаются:\n$y_i = \\gamma \\hat{x}_i + \\beta$\nЭти параметры позволяют модели адаптировать нормализованные данные, чтобы восстановить необходимые масштабы и смещения (не обратное действие, а другое, удобное для обучения преобразование). Обучаемые параметры $\\gamma$ и $\\beta$ имеют ту же размерность, что и входные признаки, и оптимизируются вместе с остальными параметрами сети в процессе обучения.\n## Пример реализации LayerNorm в PyTorch\n```python\nimport torch.nn as nn\n\nlayer_norm = nn.LayerNorm(normalized_shape=10)\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = layer_norm(input_tensor)\n```\n## Устройство RMS Normalization\n\nRMS Normalization (Root Mean Square Normalization) нормализует значения внутри одного объекта, используя корень среднего квадрата (Root Mean Square) вместо среднего и дисперсии. Это упрощает вычисления, сохраняя основные преимущества нормализации.\n\nФормула:\n$\\hat{x}_i = \\frac{x_i}{\\sqrt{\\text{RMS}^2 + \\epsilon}}$\nгде $\\text{RMS}$ (корень среднего квадрата) вычисляется для каждого объекта индивидуально:\n$\\text{RMS} = \\sqrt{\\frac{1}{H} \\sum_{j=1}^H x_j^2}$\nгде $H$ — количество признаков.\n### Обучаемые параметры\nRMS Normalization включает один обучаемый параметр: $\\gamma$ (масштаб). После нормализации по формуле выше нормализованные значения масштабируются:\n$y_i = \\gamma \\hat{x}_i$\nПараметр $\\gamma$ позволяет модели адаптировать масштаб нормализованных данных для лучшей производительности. В отличие от Layer Normalization, RMSNorm обычно не включает параметр сдвига ($\\beta$). Обучаемый параметр $\\gamma$ имеет ту же размерность, что и входные признаки, и оптимизируется вместе с остальными параметрами сети в процессе обучения.\n## Пример реализации RMSNorm в PyTorch\n```python\nimport torch.nn as nn\n\n\nrms_norm = nn.RMSNorm([8, 10])\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = rms_norm(input_tensor)\n```"
    },
    "14. Многослойные сети. Граф потока вычислений. Класс nn.Module в PyTorch - назначение, основные поля и методы..md": {
        "markdown": "## Многослойные сети\nМногослойные нейронные сети состоят из нескольких слоев нейронов, где каждый слой передает результаты вычислений следующему. Основная идея — выучить сложные функции за счет композиции нелинейных преобразований.\n## Граф потока вычислений\nГраф потока вычислений описывает последовательность операций, выполняемых над входными данными. Узлы графа представляют операции, а рёбра — данные, передаваемые между ними. В PyTorch граф строится динамически во время выполнения программы, что позволяет использовать переменные, условия и циклы.\nПример:\n- Узлы: операции (свертка, ReLU, матричное умножение).\n- Рёбра: тензоры, передаваемые между узлами.\nПример:\nУзлы: a, b, c (промежуточный результат), f (конечный результат)\nРёбра: между узлами операция суммы и умножения\n![[Pasted image 20250122000721.png]]\n## Класс nn.Module в PyTorch\n### Назначение\nКласс nn.Module является базовым для всех нейронных сетей в PyTorch. Он позволяет:\n1. Определять архитектуру модели.\n2. Управлять параметрами модели.\n3. Удобно организовывать слои и операции.\n### Основные поля\n1. **parameters**: возвращает все обучаемые параметры модели.\n2. **buffers**: хранит тензоры тензоры, которые не являются параметрами (например, статистики BatchNorm).\n3. **children**: возвращает дочерние модули (например, отдельные слои).\n### Основные методы\n1. **forward(self, input)**: определяет, как данные проходят через модель. Его нужно переопределять.\n2. **train(self, mode=True)**: переключает модель в режим обучения или тестирования.\n3. **eval(self)**: включает режим тестирования (например, отключает Dropout).\n4. **state_dict()**: возвращает параметры и буферы модели для сохранения.\n5. **load_state_dict(state_dict)**: загружает сохранённые параметры и буферы.\n6. **to(device)**: переводит модель на указанный девайс (CPU/GPU).\n### Пример использования\nimport torch\nimport torch.nn as nn\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 20)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(20, 1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        return self.fc2(x)\n# Создание и использование модели\nmodel = SimpleNN()\ninput_data = torch.randn(5, 10)  # 5 объектов, 10 признаков\noutput = model(input_data)\n"
    },
    "15. Специфика задач машинного обучения на изображениях. Принцип работы сверточных сетей. Преимущества сверточных сетей при решении этих задач..md": {
        "markdown": "## Специфика задач машинного обучения на изображениях\n- Задачи включают классификацию, сегментацию, детекцию объектов, генерацию изображений.\n- Особенность: высокая размерность данных, пространственные зависимости, разнообразие форматов.\n## Сверточные слои (Convolution Layers)\n- Выполняют свертку входных данных с ядром для выделения признаков.\n- Параметры: число каналов, размер ядра, шаг (stride), паддинг (padding).\nФормула:\n\t $Y[i, j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} X[i+m, j+n] \\cdot K[m, n]$\nГде:\n- $Y[i, j]$ — значение выходного тензора (карты признаков) в позиции $(i, j)$.\n- $X$ — входной тензор (например, изображение).\n- $K$ — ядро свёртки (фильтр) размером $M \\times N$.\n- $M$ и $N$ — высота и ширина ядра свёртки соответственно.\nОперация:\n- Ядро $K$ перемещается по входному тензору $X$ с определённым шагом (stride).\n- В каждой позиции происходит поэлементное умножение ядра на соответствующую часть входного тензора.\n- Результаты умножений суммируются, формируя выходное значение $Y[i, j]$.\n- Формула размерности выхода:\n$$\nO = \\frac{(W - K + 2P)}{S} + 1\n$$\nгде W — размер входа, K — размер ядра, P — паддинг, S — шаг.\n![[Pasted image 20250106173723.png]]\nГлавным здесь является то, что при использовании свёрток мы даём нашей сети bias (изначальную установку) о пространственном взаимодействии пикселей внутри какого-либо квадрата (размера ядра свёртки)\n## Преимущества сверточных сетей при решении задач\n- Учитывают пространственную структуру изображения.\n- Сокращают количество параметров за счет использования фильтров.\n- Обеспечивают инвариантность к сдвигам, масштабам и другим трансформациям (за счёт последовательный комбинации свёрточных и пулинг слоёв).\n- Эффективны при обработке больших изображений.\n## Сравнение свёрточных и полносвязных слоёв\n\n| **Критерий**                 | **Свёрточные слои**                                                                        | **Полносвязные слои**                                        |\n| ---------------------------- | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------ |\n| **Количество параметров**    | Зависит от размера фильтра K×KK \\times K и числа фильтров FF: F×(K×K)F \\times (K \\times K) | Зависит от числа входов NN и выходов MM: N×MN \\times M       |\n| **Вычислительная сложность** | Меньше из-за локальных связей и меньшего числа параметров                                  | Больше из-за полного соединения всех нейронов                |\n| **Применение**               | Эффективно для обработки изображений и данных с локальными связями                         | Используется для табличных данных или в финальных слоях сети |\n"
    },
    "16. Архитектура многослойной ИНС распознавания изображений на основе сверточных сетей. Сверточные слои (Convolution Layers) и сжимающие слои (Pooling Layers) в PyTorch..md": {
        "markdown": "## Архитектура многослойной ИНС для распознавания изображений\nСостоит из сверточных, сжимающих и полносвязных слоев. Основные этапы:\n1. Извлечение признаков через сверточные слои.\n2. Уменьшение размерности данных с помощью сжимающих (pooling) слоев.\n3. Принятие решения в полносвязных слоях.\n## Сверточные слои (Convolution Layers)\n- Выполняют свертку входных данных с ядром для выделения признаков.\n- Параметры: число каналов, размер ядра, шаг (stride), паддинг (padding).\nФормула:\n\t $Y[i, j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} X[i+m, j+n] \\cdot K[m, n]$\nГде:\n- $Y[i, j]$ — значение выходного тензора (карты признаков) в позиции $(i, j)$.\n- $X$ — входной тензор (например, изображение).\n- $K$ — ядро свёртки (фильтр) размером $M \\times N$.\n- $M$ и $N$ — высота и ширина ядра свёртки соответственно.\nОперация:\n- Ядро $K$ перемещается по входному тензору $X$ с определённым шагом (stride).\n- В каждой позиции происходит поэлементное умножение ядра на соответствующую часть входного тензора.\n- Результаты умножений суммируются, формируя выходное значение $Y[i, j]$.\n- Формула размерности выхода:\n$$\nO = \\frac{(W - K + 2P)}{S} + 1\n$$\nгде W — размер входа, K — размер ядра, P — паддинг, S — шаг.\n\nГлавным здесь является то, что при использовании свёрток мы даём нашей сети bias (изначальную установку) о пространственном взаимодействии пикселей внутри какого-либо квадрата (размера ядра свёртки)\n\nПример использования:\n```python\nimport torch\nimport torch.nn as nn\n\nconv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\noutput = conv_layer(torch.randn(1, 3, 64, 64))  # Входной тензор: батч, каналы, высота, ширина\n```\n\n![[Pasted image 20250106174018.png]]\n## Сжимающие слои (Pooling Layers)\n- Уменьшают размерность данных, сохраняя ключевые признаки.\n- Виды: max pooling (максимальное значение) и average pooling (среднее значение).\nПример использования:\n\n```python\npool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\npooled_output = pool_layer(output)\n```\n![[Pasted image 20250106174039.png]]"
    },
    "17. Приемы для глубокого обучения на небольших наборах изображений..md": {
        "markdown": "## Увеличение данных (Data Augmentation)\nПрименение различных преобразований изображений для увеличения размера обучающего набора: повороты, отражения, обрезка, изменение яркости.\nЭто помогает модели увидеть больше вариаций данных, предотвращает переобучение и улучшает обобщающую способность.\n\nПример в PyTorch:\n```python\nfrom torchvision import transforms\n\naugmentation = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2)\n])\n```\n## Использование предобученных моделей\nИнициализация весов из моделей, обученных на больших наборах данных, с последующей настройкой (fine-tuning) или заморозкой начальных слоев.\nПредобученные модели обучены на больших наборах данных (например, ImageNet) и уже содержат полезные представления признаков.\n\nПример в PyTorch:\n```python\nfrom torchvision import models\n\nmodel = models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False  # Заморозить слои\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)  # Замена выходного слоя\n```\n## Регуляризация\nПрименение dropout, L1 или L2-регуляризации для предотвращения переобучения на малом датасете.\nМетоды регуляризации ограничивают сложность модели, предотвращая её чрезмерную подстройку под малый набор данных. Это улучшает способность модели обобщать на новые примеры.\n\nПример Dropout в PyTorch:\n```python\nimport torch.nn as nn\n\ndropout = nn.Dropout(p=0.5)\noutput = dropout(input_tensor)\n```\n## Ранняя остановка\nРанняя остановка — это метод предотвращения переобучения. \nВ процессе обучения, если ошибка (либо любая иная мера качества модели) на валидационной выборке перестает уменьшаться (или начинает расти) за какое-то количество (в формуле буква k) шагов, обучение прекращается. Это позволяет сохранить модель, которая лучше всего обобщает данные.\n\nФормально, если L — функция потерь на валидационной выборке, то обучение прекращается, когда:\n\n$$\nL_{\\text{val}}(t) < \\min \\{ L_{\\text{val}}(t-1), L_{\\text{val}}(t-2), \\dots, L_{\\text{val}}(t-k) \\}\n$$\n\nгде t — номер эпохи.\nТаким образом, модель не переоптимизируется на тренировочном наборе, что особенно важно при небольших данных."
    },
    "18. Схема работы сверточной сети. Операции свертки, пулинга, общий вид сверточной сети для решения задачи классификации изображения..md": {
        "markdown": "## Схема работы сверточной сети\nСостоит из сверточных, сжимающих и полносвязных слоев. Основные этапы:\n1. Извлечение признаков через сверточные слои.\n2. Уменьшение размерности данных с помощью сжимающих (pooling) слоев.\n3. Принятие решения в полносвязных слоях.\n\n## Сверточные слои (Convolution Layers)\n- Выполняют свертку входных данных с ядром для выделения признаков.\n- Параметры: число каналов, размер ядра, шаг (stride), паддинг (padding).\n- Формула размерности выхода:\n$$\nO = \\frac{(W - K + 2P)}{S} + 1\n$$\nгде W — размер входа, K — размер ядра, P — паддинг, S — шаг.\n\nПример использования:\n```python\nimport torch\nimport torch.nn as nn\n\nconv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\noutput = conv_layer(torch.randn(1, 3, 64, 64))  # Входной тензор: батч, каналы, высота, ширина\n```\n\n![[Pasted image 20250106174018.png]]\n## Сжимающие слои (Pooling Layers)\n- Уменьшают размерность данных, сохраняя ключевые признаки.\n- Виды: max pooling (максимальное значение) и average pooling (среднее значение).\nПример использования:\n\n```python\npool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\npooled_output = pool_layer(output)\n```\n![[Pasted image 20250106174039.png]]\n## Общий вид сверточной сети\nСостоит из чередующихся слоев свертки и пулинга для выделения признаков, завершающихся полносвязными слоями для классификации.\n\nПример структуры сети:\n```python\nimport torch.nn as nn\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CNN, self).__init__()\n        self.features = nn.Sequential(\n            # Свёртка: извлекает локальные признаки из входных изображений (например, края, текстуры).\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            # ReLU: добавляет нелинейность, чтобы модель могла аппроксимировать сложные зависимости.\n            nn.ReLU(),\n            # MaxPooling: уменьшает размерность (субдискретизация), выделяя важные признаки и ускоряя вычисления.\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Вторая свёртка: извлекает более высокоуровневые признаки (например, формы, объекты).\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            # Flatten: преобразует многомерный тензор в одномерный для входа в линейные слои.\n            nn.Flatten(),\n            # Linear слой: преобразует признаки в скрытое представление.\n            nn.Linear(32 * 8 * 8, 128),\n            nn.ReLU(),\n            # Финальный линейный слой: преобразует скрытое представление в выходное количество классов.\n            nn.Linear(128, num_classes)\n        )\n        \n    def forward(self, x):\n        # Последовательно применяем слои features для извлечения признаков.\n        x = self.features(x)\n        # Пропускаем извлечённые признаки через классификатор для предсказания.\n        x = self.classifier(x)\n        return x\n```\n## Схематично\n![[Pasted image 20250122002950.png]]"
    },
    "19. Виды задач машинного обучения и постановка задачи обучения с подкреплением..md": {
        "markdown": "## Виды задач машинного обучения\n### Обучение с учителем (Supervised Learning)\nМодель обучается на размеченных данных, где каждый входной пример имеет соответствующий целевой выход.\n- **Цель:** Научить модель предсказывать целевой выход для новых, ранее не виденных данных.\n- **Задачи:** Классификация и регрессия.\n### Обучение без учителя (Unsupervised Learning)\nМодель обучается на неразмеченных данных, где отсутствует целевой выход.\n- **Цель:** Найти внутренние структуры, закономерности или группировки в данных.\n- **Задачи:** Кластеризация, выявление аномалий, понижение размерности, поиск ассоциативных правил.\n### Обучение с частичным привлечением учителя (Semi-Supervised Learning)\nКомбинация обучения с учителем и обучения без учителя, где модель обучается на небольшом наборе размеченных данных и большом наборе неразмеченных данных.\n- **Цель и задачи:** Аналогичны обучению с учителем.\n- **Идея:** Использование неразмеченных данных для улучшения обучения модели и расширения её способности к обобщению.\n### Самообучение (Self-Supervised Learning)\nПодход к обучению, в котором модель обучается на неразмеченных данных, используя разнообразные задачи, создаваемые из самих данных, без необходимости внешних разметок. Вместо использования учителя для предоставления меток, самообучение извлекает информацию из данных для самостоятельного обучения модели.\n- **Цель и задачи:** Аналогичны обучению с учителем, вводные данные — аналогичны обучению без учителя.\n### Активное обучение (Active Learning)\nАктивное обучение — метод, применяемый в подходе **обучения с учителем**, обычно в случаях, когда получение меток дорого. В этом подходе метки получают динамически, определяя алгоритмическую **стратегию для максимизации полезности новых наблюдений**.\n- Активное обучение можно рассматривать как особый случай обучения с частичным привлечением учителя.\n- **Цель и задачи:** Аналогичны обучению с учителем. Входные данные — без разметки, с возможностью (обычно дорогостоящей) динамической разметки.\n\n### Обучение с подкреплением (Reinforcement Learning, RL)\nОбучение с подкреплением — это подход, при котором модель обучается как агент, взаимодействующий с окружающей средой и максимизирующий вознаграждение, получаемое от системы.\n- В RL агент самостоятельно исследует окружающую среду, принимая решения на основе своего опыта и обратной связи от среды.\n- В RL нет меток:\n    - Нельзя использовать обучение с учителем.\n    - Есть **вознаграждение**, которое указывает, насколько хорош текущий результат.\n    - \n**Модель RL учится стратегии максимизации вознаграждения**:\n- Стратегия должна учитывать баланс между исследованием (получением новой информации о среде) и использованием существующих знаний для максимизации вознаграждения.\n# Постановка задачи обучения с подкреплением\nОбучение с подкреплением (Reinforcement Learning) — это метод машинного обучения, в котором система обучается, взаимодействуя с окружающей средой.\nВ этом подходе есть:\n- **Агент (agent)**, который с помощью:\n- **Действий (actions)** взаимодействует с:\n- **Окружающей средой (environment)**, описываемой:\n    - Внутренним **состоянием (state)**.\n\n**Результат действий**:\n- Среда возвращает **вознаграждение (reward)** за действия агента.\n- Среда меняет своё состояние в ответ на эти действия.\n\n![[Pasted image 20250122003656.png]]\n### Основные элементы обучения с подкреплением\n1. $s_t$ — состояние среды (state) на шаге t.\n2. $a_t$ — действия агента (agent) на шаге t.\n3. $r_t$ — вознаграждение (reward) на шаге t.\n- $s \\in S$ — множество возможных состояний среды.\n- $a \\in A$ — множество возможных действий агента.\n- $p(s′∣a,s)$ — модель переходов между состояниями (в общем случае — вероятностная):\n    - Модель переходов может быть неизвестна агенту. В зависимости от подхода агент может пытаться или не пытаться узнать эту модель.\n- $\\pi(a | s)$ — стратегия (policy, политика) агента, определяющая его действия.\n- $r(s, a)$ — функция вознаграждения:\n    - Для многих задач построение функции вознаграждения является сложной задачей. Пример: шахматы."
    },
    "20. Подходы к определению стратегии. Определение вознаграждения и дисконтированного вознаграждения. Q-функция и V-функция. Уравнение Беллмана для функции значения состояния..md": {
        "markdown": "В обучении с подкреплением стратегия ($\\pi$) определяет поведение агента, то есть правила выбора действий в каждом состоянии.\n- Формально может быть записано как распределение: $\\pi(a|s)$\n## Подходы к определению стратегии\n1. **Детерминированная стратегия**: однозначно задает действие для каждого состояния.\n   $\\pi(s) = a$, точный выбор действия a в состоянии s. Примером такой стратегии будут стратегии, полученные с помощью Q-learning (всегда выбираем действие с максимальным Q значением)\n2. **Случайная стратегия**: определяет распределение вероятностей действий в каждом состоянии.\n   $\\pi(a | s)$, вероятность выбора действия a в состоянии s. Примером такой стратегии будут стратегии, полученные с помощью Policy Gradient (имеем распределение действий и семплируем из него)\n3. **Параметризованная стратегия** - например, стратегия может быть параметризованной с использованием нейронных сетей, где параметры модели настраиваются в процессе обучения. В записи $\\pi(a|s,\\mathbf{\\theta})$ $\\mathbf{\\theta}$ это вектор параметров модели, например веса нейронной сети.\n\n\n\n* __Цель обучения__ - __нахождение оптимальной стратегии__, которая максимизирует ожидаемое вознаграждение (reward) в долгосрочной перспективе.\n* __Агент обучается, итеративно взаимодействуя с средой и обновляя свою стратегию__.\n## Определение вознаграждения и дисконтированного вознаграждения\n- **Вознаграждение (R)**: значение, получаемое агентом за выполнение действия в определенном состоянии.\n- **Дисконтированное вознаграждение (G)**: сумма будущих вознаграждений с учетом коэффициента дисконтирования γ:\n  $$\n  G_t = \\sum_{k=0}^\\infty \\gamma^k R_{t+k}\n  $$\n  где γ ∈ [0, 1] регулирует вес будущих вознаграждений.\n\n![[Pasted image 20250122180047.png]]\n\n## Q-функция и V-функция\n\n^a0e423\n\n- **V-функция (функция ценности состояния)**:\n  $$\n  V^\\pi(s) = \\mathbb{E}_\\pi \\left[ G_t \\mid s_0 = s \\right]\n  $$\n  Ожидаемое дисконтированное вознаграждение, начиная из состояния s и следуя стратегии π.\n\n- **Q-функция (функция ценности состояния-действия)**:\n  $$\n  Q^\\pi(s, a) = \\mathbb{E}_\\pi \\left[ G_t \\mid s_0 = s, a_0 = a \\right]\n  $$\n  Ожидаемое дисконтированное вознаграждение, начиная из состояния s, выполняя действие a и далее следуя стратегии π.\n\nЕсли $Q^\\pi(s, a_1) > Q^\\pi(s, a_2)$, то выбор 1 действия приведёт к большему выигрышу. Это свойство позволяет агенту приоритизировать свои действия во время обучения.\n## Уравнение Беллмана для функции ценности состояния\nУравнение Беллмана связывает функцию ценности состояния с ожидаемыми вознаграждениями и следующими состояниями:\n$$\nV^\\pi(s) = \\mathbb{E}_\\pi \\left[ r_t + \\gamma V^\\pi(s_{t+1}) \\mid s_t = s \\right]\n$$\nИли, расписывая математическое ожидание:\n\n$$\nV^{\\pi}(s) = \\sum\\limits_{a} \\pi(a | s) \\sum\\limits_{s'} P(s'|s, a) \\left[R(s, a, s') + \\gamma V^{\\pi}(s')\\right]\n$$\nгде $s'$ - новое состояние\n\nДля вычисления оптимальной стратегии максимизируют по $a$:\n$$\nV^*(s) = \\max\\limits_{a} \\sum\\limits_{s'} P(s'|s, a) \\left[R(s, a, s') + \\gamma V^*(s')\\right]\n$$\nУравнение Беллмана позволяет рекурсивно вычислить оптимальные значения для всех состояний\n\n---\n\nДля Q-функции уравнение Беллмана выглядит так:\n$$\nQ^\\pi(s, a) = \\mathbb{E}_\\pi \\left[ r_t + \\gamma Q^\\pi(s_{t+1}, a_{t+1}) \\mid s_t = s, a_t = a \\right]\n$$\nгде $r_t$ - ожидаемое вознаграждение,\n$\\gamma V^\\pi(s_{t+1})$ или $\\gamma Q^\\pi(s_{t+1}, a_{t+1})$ - следующая дисконтированная ценность действия\nЭти уравнения используются для обучения и оценки стратегии."
    },
    "21. Метод Policy Gradient. Улучшения метода, общие принципы модели Actor-Critic..md": {
        "markdown": "### **Policy Gradient:**\nPolicy Gradient — это метод обучения с подкреплением, где стратегия ($\\pi_\\theta$) параметризуется нейронной сетью с параметрами $\\theta$, и обновление параметров осуществляется с помощью градиентного спуска для максимизации ожидаемого вознаграждения.\n#### **1. Целевая функция:**\nЦель Policy Gradient — максимизировать ожидаемое дисконтированное вознаграждение агента:\n$$\n\nJ(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right],\n\n$$\nгде:\n- $\\pi_\\theta(a \\mid s)$: вероятность выбрать действие $a$ в состоянии $s$,\n- $r_t$: вознаграждение в момент времени $t$,\n- $\\gamma$: коэффициент дисконтирования ($0 \\leq \\gamma \\leq 1$).\n#### **2. Теорема Policy Gradient:**\nДля обновления параметров $\\theta$ используется градиент целевой функции $J(\\theta)$:\n$$\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) G_t \\right],\n$$\nгде:\n- $\\log \\pi_\\theta(a_t \\mid s_t)$: логарифм вероятности выбранного действия $a_t$,\n- $G_t = \\sum_{k=0}^\\infty \\gamma^k r_{t+k}$: накопленное вознаграждение (return).\n#### **3. Обновление параметров:**\nПараметры $\\theta$ обновляются с помощью градиентного спуска:\n$$\n\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta),\n$$\n\nгде $\\alpha$ — скорость обучения.\n#### **4. Проблемы Policy Gradient и их решения:**\n1. **Высокая дисперсия градиентов:**\n   - Используются методы уменьшения дисперсии, например, центрирование $G_t$:\n     $$\n     \\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) (G_t - b) \\right],\n     $$\n     где $b$ — базовая линия (например, значение $V(s_t)$).\n2. **Стабильность обучения:**\n   - Для повышения стабильности используются продвинутые методы, такие как **Actor-Critic**.\n### **Actor-Critic:**\nActor-Critic — это усовершенствование Policy Gradient, где агент использует две модели:\n1. **Актёр (Actor):**\n   - Отвечает за стратегию ($\\pi_\\theta(a \\mid s)$).\n   - Используется для выбора действий.\n2. **Критик (Critic):**\n   - Оценивает действия с помощью функции ценности ($V(s)$) или $Q(s, a)$.\n   - Предоставляет обратную связь актёру.\n#### **1. Целевая функция:**\nActor-Critic также направлен на максимизацию ожидаемого вознаграждения:\n$$\nJ(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right].\n$$\n#### **2. Градиент для актёра:**\nГрадиент стратегии (Actor) вычисляется аналогично Policy Gradient:\n$$\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) A(s_t, a_t) \\right],\n$$\nгде:\n- $A(s_t, a_t)$: функция преимущества (Advantage Function), которая оценивает, насколько выбранное действие $a_t$ в состоянии $s_t$ лучше среднего уровня.\nФункция преимущества:\n$$\nA(s_t, a_t) = Q(s_t, a_t) - V(s_t),\n$$\nгде:\n- $Q(s_t, a_t)$: ожидаемая ценность пары (состояние-действие),\n- $V(s_t)$: ценность состояния.\n#### **3. Обучение критика:**\nКритик обучается аппроксимировать $V(s_t)$ (или $Q(s_t, a_t)$) ([[20. Подходы к определению стратегии. Определение вознаграждения и дисконтированного вознаграждения. Q-функция и V-функция. Уравнение Беллмана для функции значения состояния.#^a0e423|Q-функция и V-функция]]) с помощью MSE (Mean Squared Error):\n$$\nL(\\phi) = \\mathbb{E} \\left[ \\left( r_t + \\gamma V(s_{t+1}) - V(s_t) \\right)^2 \\right],\n$$\nгде:\n- $\\phi$: параметры модели критика.\n#### **4. Обновление параметров:**\n- **Актёр:** Параметры стратегии ($\\theta$) обновляются с использованием градиента:\n  $$\n  \\theta \\leftarrow \\theta + \\alpha_\\text{actor} \\nabla_\\theta J(\\theta).\n  $$\n\n- **Критик:** Параметры критика ($\\phi$) обновляются с использованием функции ошибки:\n  $$\n  \\phi \\leftarrow \\phi - \\alpha_\\text{critic} \\nabla_\\phi L(\\phi).\n  $$"
    },
    "22. Метод Q-Learning..md": {
        "markdown": "## Метод Q-Learning\nQ-Learning — это метод обучения с подкреплением, который используется для определения оптимальной стратегии путем приближения Q-функции.\n\n## Основное обновляющее правило\nQ-функция обновляется по следующему правилу:\n$$\nQ(s, a) \\leftarrow Q(s, a) + \\alpha \\left[ R(s, a) + \\gamma \\max_a Q(s', a) - Q(s, a) \\right]\n$$\nгде:\n- s, a — текущее состояние и действие,\n- R — вознаграждение за переход,\n- s' — новое состояние,\n- α — скорость обучения,\n- γ — коэффициент дисконтирования.\n\n## Алгоритм\n1. Инициализация Q-функции произвольными значениями.\n2. Для каждого эпизода:\n   - Выбор действия a в состоянии s (например, с использованием ε-жадной стратегии на первых шагах обучения для наилучшего исследования).\n   - Выполнение действия a и наблюдение нового состояния s' и вознаграждения r.\n   - Обновление Q(s, a) по правилу.\n   - Переход в новое состояние s'.\n3. Повторение до сходимости Q-функции.\n\n## Свойства\n- Метод не требует построению модели среды, агент напрямую взаимодействует с реальной средой\n- Гарантированно сходится к оптимальной Q-функции при достаточном исследовании состояния и действия.\n## Применение\nQ-Learning подходит для задач с дискретными пространствами состояний и действий. Для непрерывных пространств используется расширение, например Deep Q-Learning.\n"
    },
    "23. Типы задач машинного зрения, решаемые с помощью глубоких моделей. Архитектура VGG16, её преимущества и недостатки..md": {
        "markdown": "## Типы решаемых задач\n1. Классификация изображений\n2. Обнаружение объектов\n3. Сегментация изображений\n4. Распознавание лиц\n5. Детекция ключевых точек\n6. Генерация описаний изображений\n7. Стилизование изображений\n8. Улучшение качества изображений\n## VGG16\nАктуальность модели состоит в:\n- Применении маленьких свёрточных ядер (3 на 3) с большим количеством карт признаков\n- Большой глубине сети (16 слоёв, имеются более маленькие/большие версии сети)\nСама архитектура очень проста, содержит conv и pooling слои с dense(linear) на конце\nПлюсы:\n- Точность\n- Модульность (легко изменяется кол-во блоков)\n- Простота\nМинусы:\n- Большая размер (глубина) модели\n- Высокие вычислительные затраты и затраты по памяти\n![[Pasted image 20250106180900.png]]"
    },
    "24. Архитектура GoogLeNet, описание модуля Inception module, логика использования свертки 1x1 и использование DepthConcat в Inception module. Сравнение с другими архитектурами..md": {
        "markdown": "## Архитектура GoogLeNet\nGoogLeNet — это сверточная нейронная сеть, представленная для решения задачи классификации ImageNet. Она построена на основе модулей Inception и ориентирована на снижение вычислительной сложности при высокой производительности.\n\nОсновные характеристики:\n1. Глубокая сеть с 22 слоями.\n2. Использование модулей Inception для повышения эффективности.\n3. Дополнительные классификаторы для борьбы с проблемой затухающих градиентов.\n![[Pasted image 20250107143516.png]]\n## Описание Inception module\nInception module — это ключевая составляющая GoogLeNet, которая комбинирует сверточные и пуллинговые операции разного масштаба в одном модуле. \nСостав модуля:\n1. Свертки 1x1, 3x3 и 5x5 для извлечения признаков разного масштаба.\n2. MaxPooling 3x3 для обработки контекста.\n3. Объединение выходов всех операций с помощью DepthConcat (конкатенация результатов этих различных ядер, на картинке в красных овалах).\n## Логика использования свертки 1x1\n1. **Сокращение количества каналов**:\n   Свертка 1x1 используется перед большими фильтрами (3x3, 5x5) для уменьшения размерности по каналам, снижая итоговую вычислительную сложность.\n2. **Извлечение признаков**:\n   Обрабатывает каждый канал по отдельности, добавляя нелинейность через активацию. Например, чтобы из картинки 64 * 64 * 256 получить 64 * 64 * 5 нужно создать 5 свёрток 1 * 1 * 256 \n## Использование DepthConcat\nDepthConcat объединяет выходы всех операций Inception module по размерности каналов, создавая представление признаков, полученное из различных ядер. \nВ классическом примере объединяет параметры, полученные после свёрток: 1x1; 1x1 + 3x3; 1x1 + 5x5; maxpool + 1x1\n## Сравнение с другими архитектурами\n1. **ResNet**:\n   ResNet использует прямые соединения (skip connections), упрощая обучение глубоких сетей. GoogLeNet фокусируется на модулях Inception для снижения вычислительных затрат.\n2. **AlexNet**:\n   GoogLeNet глубже и эффективнее благодаря Inception module. AlexNet проще и требует больше вычислительных ресурсов на единицу параметров.\n3. **VGG**:\n   VGG имеет последовательную архитектуру с одинаковыми фильтрами, что делает ее более предсказуемой, но менее эффективной по вычислениям по сравнению с GoogLeNet.\n\nGoogLeNet балансирует глубину и эффективность, предлагая архитектуру с оптимизированным использованием вычислительных ресурсов."
    },
    "25. Архитектуры с residual connections, основные принципы residual connections. Нарушение симметрии глубоких ИНС с помощью residual connections. Сравнение с другими архитектурами..md": {
        "markdown": "## Архитектуры с residual connections\nResidual connections (остаточные связи) были представлены в ResNet. Они добавляют прямой путь между слоями через короткое соединение (skip connection), что помогает передавать информацию и градиенты на более глубокие слои.\n\nПример остаточной связи:\n$$\ny = F(x, W) + x\n$$\nгде F(x, W) — преобразование входа x с параметрами W, а x — входной сигнал, добавляемый напрямую.\n![[Pasted image 20250107143732.png]]\n![[Pasted image 20250107143940.png]]\n## Основные принципы residual connections\n1. **Обход нелинейностей**:\n   Прямое соединение добавляет **возможность** передавать входной сигнал напрямую, минуя сложные преобразования.\n2. **Улучшение обучения**:\n   Уменьшают проблему затухающих и взрывающихся градиентов, что облегчает обучение глубоких сетей из-за чего модели с residual connections достигают большей глубины (например, ResNet-152) без деградации точности.\n## Нарушение симметрии глубоких ИНС\n   В традиционных архитектурах преобразования между слоями часто симметричны, что ухудшает ландшафт функции потерь. Остаточные связи разрывают эту симметрию (так  как конкатенация не симметричная операция)\n## Сравнение с другими архитектурами\n1. **ResNet vs VGG**:\n   - ResNet глубже и требует меньше параметров.\n   - VGG строится на одинаковых блоках, что увеличивает сложность вычислений.\n2. **ResNet vs DenseNet**:\n   - DenseNet использует плотные соединения (соединяет каждый слой с каждым), что требует больше памяти.\n   - ResNet проще и более масштабируем.\n3. **ResNet vs AlexNet**:\n   - AlexNet меньше по глубине, хуже обобщает сложные признаки.\n   - ResNet эффективнее за счет использования residual connections.\n## Итог\nResidual connections стали ключевой концепцией для глубоких архитектур, позволяя моделям быть более глубокими, обучаемыми и устойчивыми. Они изменили подход к проектированию сетей, устранив многие проблемы традиционных архитектур. Данный подход применяется в трансформер блоках.\n"
    },
    "25. Типы задач машинного зрения, решаемые с помощью глубоких моделей. Архитектура VGG16, её преимущества и недостатки..md": {
        "markdown": "## Типы решаемых задач\n1. Классификация изображений\n2. Обнаружение объектов\n3. Сегментация изображений\n4. Распознавание лиц\n5. Детекция ключевых точек\n6. Генерация описаний изображений\n7. Стилизование изображений\n8. Улучшение качества изображений\n## VGG16\nАктуальность модели состоит в:\n- Применении маленьких свёрточных ядер (3 на 3) с большим количеством карт признаков\n- Большой глубине сети (16 слоёв, имеются более маленькие/большие версии сети)\nСама архитектура очень проста, содержит conv и pooling слои с dense(linear) на конце\nПлюсы:\n- Точность\n- Модульность (легко изменяется кол-во блоков)\n- Простота\nМинусы:\n- Большая размер (глубина) модели\n- Высокие вычислительные затраты и затраты по памяти"
    },
    "26. Архитектура UNet - общие принципы, описание архитектуры, использование residual connections и использование модели для решения задачи сегментации..md": {
        "markdown": "## Общие принципы\nUNet — это архитектура для задач сегментации изображений, которая используется для предсказания пиксельных меток. Она основана на симметричной структуре, состоящей из нисходящей (encoder) и восходящей (decoder) частей, а также Skip Connections между ними\n## Описание архитектуры\n1. **Encoder**:\n   - Состоит из нескольких уровней сверток, за которыми следуют операции пуллинга.\n   - Извлекает пространственные и контекстуальные признаки из входного изображения.\n2. **Decoder**:\n   - Восстанавливает исходное разрешение изображения, применяя транспонированные свертки (up-convolutions).\n   - Использует пропущенные связи (skip connections) для объединения характеристик из encoder.\n3. **Skip Connections**:\n   - Соединяют слои encoder и decoder для передачи информации о мелких деталях.\n   - Это помогает модели лучше справляться с задачами, где важны границы объектов.\n\nИтоговый результат имеет ту же размерность, что и входное изображение, но включает предсказания для каждого пикселя.\n![[Pasted image 20250107144128.png]]\n## Использование residual connections\nResidual connections можно внедрить в UNet для улучшения потоков градиентов. Для каждого уровня encoder и decoder добавляется остаточная связь:\n\n$$\nx_{\\text{out}} = F(x_{\\text{in}}) + x_{\\text{in}}\n$$\n\nгде F — преобразование, включающее свертки и активации. Это ускоряет обучение и стабилизирует процесс оптимизации.\n## Использование для сегментации\nUNet используется для сегментации медицинских изображений, дорожных сцен, спутниковых данных и других областей. Модель предсказывает метку для каждого пикселя, например, классифицирует области как здоровые или пораженные. Благодаря skip connections и симметричной архитектуре, она достигает высокой точности на задачах с ограниченным количеством данных.\nТакже эта модель используется для обратной диффузии, но сейчас всё чаще заменяется моделями на основе трансформеров."
    },
    "27. Подходы к использованию механизма внимания в глубоких моделях машинного зрения. Механизмы и логика использования метода Grad-CAM в глубоких моделях машинного зрения..md": {
        "markdown": "## **Подходы к использованию механизма внимания в глубоких моделях машинного зрения:**\n\n1. **Внимание в сверточных нейронных сетях (CNN):**\n   - Механизмы внимания интегрируются в CNN для выделения значимых областей изображения, что повышает точность задач, таких как обнаружение объектов и сегментация. \n   - Вычленение признаков происходит с помощью свёрточных ядер и пуллинга, а затем обработку полученной информации берут на себя attention блоки\n  Пример - Residual Attention Network:\n![[Pasted image 20250107160002.png]]\n2. **Трансформеры в компьютерном зрении:**\n   - Архитектуры, основанные на механизме внимания, такие как Vision Transformers (ViT), обрабатывают изображения, разбивая их на патчи и применяя механизм внимания для моделирования глобальных зависимостей между различными частями изображения.\n[[28. Применение модуля Transformer в компьютерном зрении. Архитектура SWIN.|Подробнее]]\n\n## **Механизмы и логика использования метода Grad-CAM (Gradient-weighted Class Activation Mapping) в глубоких моделях машинного зрения:**\n1. **Применение Grad-CAM:**\n   - **Интерпретация модели:** Grad-CAM помогает понять, на какие части изображения модель обращает внимание при классификации, что повышает доверие к её решениям.\n   - **Диагностика ошибок:** Анализ тепловых карт Grad-CAM позволяет выявлять случаи, когда модель фокусируется на нерелевантных областях, что может указывать на необходимость дообучения или изменения архитектуры.\n   - **Обнаружение смещения:** Grad-CAM может выявлять предвзятость модели, показывая, если она основывает свои решения на неподходящих признаках.\n2. **Логика работы Grad-CAM:**\n   - Метод вычисляет градиенты вероятности целевого класса по отношению к активациям выбранного сверточного слоя.\n   - Эти градиенты используются для взвешивания активаций, определяя вклад каждого нейрона в предсказание.\n   - Взвешенные активации суммируются и проходят через функцию ReLU, чтобы получить окончательную карту активации класса, которая затем накладывается на исходное изображение для визуализации.\n## Примеры работы:\n ![[Pasted image 20250107160739.png]]\n![[Pasted image 20250107160651.png]]"
    },
    "28. Применение модуля Transformer в компьютерном зрении. Архитектура SWIN..md": {
        "markdown": "## Применение Transformer в компьютерном зрении (классическая ViT архитектура)\n1. Изображение делится на патчи (стандартная архитектура ViT), путём разбиения исходного изображения на квадраты.\n   Например, в исходной статье для 224 x 224 использовали патчи 14 x 14 (их получилось 16 x 16 штук)\n2. Затем полученные патчи развёртываются в одномерный вектор, преобразуются в эмбеддинги через прохождение сквозь начальные линейные слои\n3. Также используются эмбеддинги патчей (то есть их позиционное кодирование), чтобы добавить информацию об месте патча на исходной картинке\n4. После всех этапов кодирования в обычные трансформер блоки подаются векторы размерности (batch size, number of patches, embedding dimension)\n![[Pasted image 20250107144318.png]]\n## Архитектура SWIN\n\nSWIN Transformer обрабатывает изображение через **иерархическую архитектуру**\n1. Изображение разбивается на патчи (в исходной статье это 4x4, что меньше чем в ViT, ось цвета (каналов), также развёртывается), пиксели преобразуются в эмбеддинги также как в ViT\n2. Полученные патчи разбиваются на группы (7 на 7 патчей в каждой, тогда в исходной архитектуре выйдет 64 окна)\n3. Используются только блоки локального внимания. То есть не взаимодействие всех патчей со всеми, а только внутри групп со второго шага\n   Есть два вида блоков локального внимания:\n\t1. Обычный\n\t2. Со сдвигом сетки разбиения патчей. Нужен для взаимодействия патчей друг с другом, но взаимодействие между группами НЕ происходит из-за маскирования\n4. Путём конкатенации групп патчей 2 x 2 в 1 патч, из-за чего размерность эмбеддингов увеличивается в 4 раза.\n5. Шаги 3 и 4 повторяются по глубине сети. С каждой глубиной патчи увеличиваются и несут в себе всё более верхнеуровневые представления.\n![[Pasted image 20250107144605.png]]\n## Разница\n![[Pasted image 20250107144649.png]]\nВ ViT разбиение на патчи происходить 1 раз, а в SWiN в шаге 4 они объединяются в патчи всё большего размера с увеличением глубины сети"
    },
    "29. Векторная интерпретация весов скрытого слоя многослойного перцептрона. Задача восстановления входного сигнала после сжатия в скрытом слое ИНС..md": {
        "markdown": "В многослойном перцептроне (MLP) веса скрытого слоя можно интерпретировать как векторы в пространстве входных признаков. \nКаждый нейрон скрытого слоя имеет свой вектор весов, определяющий направление в пространстве входных данных, на которое нейрон наиболее чувствителен. \nИными словами, веса нейрона определяют гиперплоскость, разделяющую входное пространство на области, которые нейрон активирует по-разному.\n## Задача восстановления входного сигнала после сжатия в скрытом слое ИНС\nДля этой цели используется архитектура, известная как автоэнкодер. \nАвтоэнкодер состоит из двух основных частей: энкодера и декодера.\n Энкодер сжимает входной сигнал в представление меньшей размерности в скрытом слое, а декодер восстанавливает исходный сигнал из этого сжатого представления. \n В процессе обучения автоэнкодер минимизирует разницу между входным и восстановленным сигналами, что позволяет ему эффективно кодировать и декодировать данные.\n\nВ процессе сжатия и последующего восстановления входного сигнала автоэнкодер обучается выделять наиболее значимые характеристики данных, отбрасывая избыточную информацию. Это позволяет использовать автоэнкодеры для задач уменьшения размерности, устранения шума и генерации новых данных, схожих с обучающими.\nВеса скрытого слоя в автоэнкодере определяют, какие аспекты входного сигнала сохраняются при сжатии, а какие отбрасываются, что напрямую влияет на качество восстановления сигнала."
    },
    "30. Автоэнкодеры. Линейный автоэнкодер и его аналог в статистических методах. Нелинейные и глубокие автоэнкодеры. Области значений латентного пространства..md": {
        "markdown": "Примеры интерполяции и экстраполяции на многообразиях области значений латентных пространств автоэкодеров\n\n## Автоэнкодеры\nАвтоэнкодеры — это нейронные сети, обучающиеся воспроизводить свои входные данные на выходе. Они состоят из двух основных компонентов: энкодера, который сжимает входные данные в латентное пространство меньшей размерности, и декодера, восстанавливающего данные из этого пространства.\n\n## **Линейный автоэнкодер и метод главных компонент (PCA) (аналог в статистических методах):**\nЛинейный автоэнкодер, использующий линейные функции активации и минимизирующий среднеквадратичную ошибку, по сути, выполняет задачу, аналогичную методу главных компонент (PCA). Оба метода стремятся найти линейное подпространство меньшей размерности, которое максимально сохраняет дисперсию исходных данных. Однако автоэнкодеры могут обучать неортогональные (перпендикулярные) базисы, в отличие от PCA, где главные компоненты ортогональны.\n![[Pasted image 20250107150050.png]]\nВидно, что PCA плохо работает с нелинейными функциями\n![[Pasted image 20250107150032.png]]\n## **Нелинейные и глубокие автоэнкодеры:**\nНелинейные автоэнкодеры используют нелинейные функции активации, что позволяет им моделировать сложные, нелинейные зависимости в данных. Глубокие автоэнкодеры состоят из нескольких слоев в энкодере и декодере, что увеличивает их способность захватывать сложные структуры данных и выявлять скрытые представления более высокого уровня.\n\n## **Латентное пространство:**\nЛатентное пространство — это пространство меньшей размерности, в которое энкодер преобразует входные данные. Оно содержит сжатые представления, сохраняющие наиболее существенные характеристики исходных данных. Структура латентного пространства отражает внутренние зависимости и структуры в данных (которые могут быть проанализированы человеком в малой размерности), что делает его полезным для задач визуализации, кластеризации и генерации новых данных.\n\n## **Интерполяция в латентном пространстве**:\nИнтерполяция в латентном пространстве позволяет создавать новые данные, плавно переходя от одного образца к другому. Например, в случае автоэнкодера, обученного на изображениях рукописных цифр, можно взять латентные представления двух разных цифр и линейно интерполировать между ними. Декодируя промежуточные точки, мы получим изображения, постепенно переходящие от одной цифры к другой, демонстрируя способность модели генерировать новые, осмысленные данные.\n## **Пример интерполяции**:\nРассмотрим автоэнкодер, обученный на наборе данных MNIST, содержащем изображения рукописных цифр от 0 до 9. Выберем два латентных вектора: один, соответствующий цифре \"2\", и другой — цифре \"0\". Выполнив линейную интерполяцию между этими векторами и декодируя полученные промежуточные векторы, мы можем наблюдать постепенное преобразование изображения \"2\" в \"0\". Это демонстрирует, как автоэнкодер может генерировать плавные переходы между различными классами данных.\n## **Экстраполяция в латентном пространстве**:\nЭкстраполяция предполагает выход за пределы известных данных в латентном пространстве. Однако, в отличие от интерполяции, экстраполяция может приводить к менее предсказуемым или даже бессмысленным результатам, поскольку модель не обучалась на таких данных. Поэтому экстраполяция в латентном пространстве автоэнкодеров используется реже и требует осторожности.\n## **Пример экстраполяции**:\nПродолжая предыдущий пример с цифрами \"2\" и \"0\", если мы будем экстраполировать за пределы этих латентных векторов, то есть выходить за диапазон значений, используемых при обучении, декодер может генерировать изображения, не соответствующие никаким реальным цифрам. Это подчеркивает ограниченность модели в генерации осмысленных данных при экстраполяции.\n\nПервый пример (Manifold interpolation), является примером интерполяции. Он показывает плавный переход от 2 к 0, где посреди перехода мы попали в векторное представление цифры 6\n\nВторой пример (Linear interpolation), можно считать примером экстраполяции так как взято среднее между векторами, которое не соответствует никакой цифре, из-за чего получившийся результат не является особо осмысленным.\n![[Pasted image 20250107150702.png]]"
    },
    "31. Задачи дискриминативных и генеративных моделей, сравнение моделей. Классификация генеративных моделей..md": {
        "markdown": "Прикладные задачи для генеративных моделей в области компьютерного зрения.\n## Задачи дискриминативных моделей\n1. Классификация данных.\n2. Прогнозирование меток $y$ на основе входных данных $x$.\n3. Пример: логистическая регрессия, SVM, ResNet.\n## Задачи генеративных моделей\n1. Изучение распределения $p(x)$ или $p(x, y)$.\n2. Генерация новых данных, похожих на реальные.\n3. Пример: VAE, GAN, PixelCNN, diffusion models\n## Сравнение моделей\n1. **Дискриминативные модели**:\n   - Предсказывают $p(y|x)$.\n   - Ориентированы на классификацию и регрессию.\n   - Архитектурно более просты, не моделируют данные полностью, используют их сжатые внутренние представления.\n2. **Генеративные модели**:\n   - Строят $p(x)$ или $p(x, y)$.\n   - Могут быть использованы для генерации новых изображений, заполнения пропусков.\n   - Архитектурно сложнее, но дают более богатое представление данных.\n## Классификация генеративных моделей\n1. **Латентные вероятностные модели**:\n   - **Вариационные Автоэнкодеры (VAE)**: Модели, которые обучаются представлять данные в латентном пространстве, позволяя генерировать новые образцы путем выборки из этого пространства.\n   - **Гауссовские Смеси (Gaussian Mixture Models, GMM)**: Модели, представляющие данные как смесь нескольких гауссовских распределений, что позволяет моделировать сложные распределения данных.\n2. **Модели с явным распределением**:\n   - **PixelCNN**: Авторегрессионная модель, предсказывающая вероятность каждого пикселя изображения на основе предыдущих, что позволяет генерировать изображения по одному пикселю за раз.\n   - **PixelRNN**: Аналогична PixelCNN, но использует рекуррентные нейронные сети для моделирования зависимости между пикселями.\n3. **Модели с неявным распределением**:\n   - **Генеративно-Состязательные Сети (GAN)**: Состоят из генератора и дискриминатора, обучающихся совместно; генератор создает данные, стремясь обмануть дискриминатор, который пытается отличить реальные данные от сгенерированных.\n4. **Авторегрессионные модели**:\n   - **Transformer**: Модель, основанная на механизме внимания, способная моделировать последовательности данных и генерировать новые последовательности, учитывая контекст предыдущих элементов.\n5. **Нормализующие потоки (Normalizing Flows)**:\n   - Модели, которые преобразуют простое распределение в сложное с помощью последовательности обратимых и дифференцируемых преобразований, позволяя точно вычислять вероятность и эффективно генерировать новые данные.\n6. **Диффузионные модели**:\n   - Модели, которые обучаются генерировать данные путем постепенного добавления и удаления шума, что позволяет получать высококачественные сэмплы, особенно в области генерации изображений.\n## Прикладные задачи для генеративных моделей в области компьютерного зрения\n**1. Генерация фотореалистичных изображений**\n- **Задача**: Создание новых изображений, неотличимых от реальных фотографий, для применения в искусстве, развлечениях и виртуальной реальности.\n- **Архитектура**: Генеративно-состязательные сети (GAN) и диффузионные модели.\n**2. Повышение разрешения изображений (Super-Resolution)**\n- **Задача**: Увеличение разрешения низкокачественных изображений для улучшения их детализации.\n- **Архитектура**: Super-Resolution GAN (SRGAN) .\n**3. Удаление шума с изображений (Denoising)**\n- **Задача**: Очистка изображений от шумов для повышения их качества.\n- **Архитектура**: Вариационные автокодировщики (VAE) и диффузионные модели.\n**4. Аугментация данных**\n- **Задача**: Генерация новых вариантов существующих данных для расширения обучающего набора и повышения устойчивости моделей.\n- **Архитектура**: Генеративно-состязательные сети (GAN) и автокодировщики (AE) .\n**5. Сегментация и аннотация изображений**\n- **Задача**: Разделение изображения на смысловые части и автоматическая аннотация для упрощения анализа.\n- **Архитектура**: U-Net и его вариации.\n**6. Генерация изображений по текстовым описаниям**\n- **Задача**: Создание изображений на основе текстовых описаний, что полезно в дизайне и рекламе.\n- **Архитектура**: диффузионные модели, их трансформерные вариации.\n**7. Восстановление изображений (Inpainting)**\n- **Задача**: Заполнение отсутствующих или поврежденных частей изображения для его восстановления.\n- **Архитектура**: Генеративно-состязательные сети (GAN) с соответствующими модификациями.\n**8. Стилистическая трансформация изображений (Style Transfer)**\n- **Задача**: Изменение стиля изображения при сохранении его содержимого, что используется в искусстве и дизайне.\n- **Архитектура**: Модели на основе сверточных нейронных сетей (CNN) и диффузионных моделей.\n**9. Создание 3D-моделей из 2D-изображений**\n- **Задача**: Генерация трехмерных моделей на основе двухмерных изображений для применения в робототехнике и дополненной реальности.\n- **Архитектура**: Комбинация сверточных нейронных сетей (CNN) и диффузионных моделей.\n"
    },
    "32. Архитектура GAN - описание общей архитектуры, модели обучения и архитектур глубоких моделей в GAN..md": {
        "markdown": "## Общая архитектура GAN\nGAN (Generative Adversarial Network) состоит из двух нейронных сетей:\n1. **Генератор (Generator)**:\n   - Генерирует новые данные из случайного шума.\n   - Цель: обучиться создавать данные, похожие на реальные.\n2. **Дискриминатор (Discriminator)**:\n   - Классифицирует входные данные как реальные или сгенерированные.\n   - Цель: уметь отличать реальные данные от сгенерированных.\n\nОбе сети соревнуются: генератор пытается обмануть дискриминатор, а дискриминатор стремится точнее различать данные.\n## Модель обучения\nGAN обучается с помощью минимакс-игры:\n$$\n\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log (1 - D(G(z)))]\n$$\nгде:\n- $D(x)$ — вероятность того, что $x$ реально.\n- $G(z)$ — данные, сгенерированные генератором из шума $z$.\n- $p_{data}$ — распределение реальных данных.\n- $p_z$ — распределение шума.\nАлгоритм обучения:\n1. Обновляем дискриминатор для повышения точности различения реальных и сгенерированных данных.\n2. Обновляем генератор для обмана дискриминатора.\n## Архитектуры глубоких моделей в GAN\n1. **Классический GAN**:\n   - Использует полносвязные и сверточные слои для генерации и дискриминации.\n2. **DCGAN (Deep Convolutional GAN)**:\n   - Заменяет полносвязные слои сверточными, улучшая качество генерации.\n   - Применяет BatchNorm и ReLU для стабильности.\n3. **WGAN (Wasserstein GAN)**:\n   - Использует расстояние Васерштейна для улучшения сходимости.\n   - Устраняет проблемы с коллапсом генератора.\n4. **Conditional GAN (cGAN)**:\n   - Генерация данных с учетом условий (например, меток классов).\n5. **StyleGAN**: \n- Использует многомерный латентный вектор для раздельного управления разными аспектами изображения (например, управления стилем).\n## Обучение на примере одномерной функции распределения\nРассмотрим задачу аппроксимации одномерного распределения данных, например, нормального распределения $p_{data} \\sim \\mathcal{N}(0, 1)$:\n1. **Инициализация**:\n   - Генератор принимает на вход шум $z$ из простого распределения (например, равномерного).\n   - Генератор преобразует шум $z$ в данные $x = G(z)$.\n   - Дискриминатор оценивает вероятность того, что данные являются реальными.\n2. **Целевая функция**:\n   Обучение идет по функции:\n   $$\n   \\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]\n   $$\n\n3. **Шаги обучения**:\n   - **Обновление дискриминатора**:\n     Оптимизируем $D$, чтобы увеличить вероятность правильной классификации реальных и сгенерированных данных.\n   - **Обновление генератора**:\n     Оптимизируем $G$, чтобы минимизировать способность дискриминатора отличать сгенерированные данные от реальных.\n4. **Постепенная сходимость**:\n   - Дискриминатор становится лучше в отличении данных, обучая генератор.\n   - Генератор начинает приближать распределение $p_{data}$."
    },
    "33. Модель вариационного автоэнкодера (VAE) - общие и специфические цели модели, общая архитектура модели и баейсовское моделирование..md": {
        "markdown": "Функция потерь VAE и специфика получаемых скрытых представлений.\n\n## Общие и специфические цели модели VAE\n1. **Общие цели**:\n   - Создание компактных скрытых представлений данных.\n   - Генерация новых данных, похожих на обучающие.\n2. **Специфические цели**:\n   - Явное моделирование вероятностного распределения данных.\n   - Регуляризация скрытого пространства для интерпретируемости и непрерывности.\n## Общая архитектура модели\n1. **Энкодер**:\n   - Преобразует входные данные $x$ в параметры распределения скрытого представления $z$: $\\mu(x)$ и $\\sigma^2(x)$.\n2. **Декодер**:\n   - Генерирует данные $\\hat{x}$ из выборки $z$, взятой из распределения, определяемого энкодером.\n3. **Скрытое пространство**:\n   - $z$ моделируется как латентное пространство, которое должно быть приближено к заранее заданному распределению (обычно $\\mathcal{N}(0, 1)$).\n## [[34. Модель вариационного автоэнкодера (VAE) - баейсовское моделирование|Баейсовское моделирование]]\n## Функция потерь VAE\nФункция потерь состоит из двух частей:\n1. **Реконструкция**:\n   - Сравнивает исходные данные $x$ с реконструированными $\\hat{x}$:\n     $$\n     \\mathbb{E}_{q(z|x)}[\\log p(x|z)]\n     $$\n2. **КЛ-дивергенция**:\n   - Минимизирует расхождение между $q(z|x)$ и $p(z)$:\n     $$\n     \\text{KL}(q(z|x) || p(z)) = \\int q(z|x) \\log \\frac{q(z|x)}{p(z)} dz\n     $$\nИтоговая функция потерь:\n$$\n\\mathcal{L}_{VAE} = - \\mathbb{E}_{q(z|x)}[\\log p(x|z)] + \\text{KL}(q(z|x) || p(z))\n$$\n## Специфика скрытых представлений\n1. **Непрерывность**:\n   - Близкие точки в скрытом пространстве $z$ соответствуют похожим данным.\n2. **Семантическая интерпретируемость**:\n   - Скрытые переменные обучаются на распределении, чтобы отражать важные факторы изменчивости данных, что и помогает хорошо генерировать новые данные.\n3. **Сглаженность**:\n   - Скрытое пространство приближает нормальное распределение, что делает генерацию стабильной."
    },
    "34. Модель вариационного автоэнкодера (VAE) - баейсовское моделирование.md": {
        "markdown": ", функция ошибки на основе метода максимального правдоподобия, причины построения ELBO и метод построения этой оценки.\n\n## Баейсовское моделирование в VAE\n$x_1, x_2, \\ldots, x_n$ — это наблюдаемые данные из обучающего набора.\n$z_i$ — это скрытые (или латентные) переменные, соответствующие каждому $x_i$.\nВариационные автоэнкодеры (VAE) предполагают, что данные $x$ и скрытые переменные $z$ связаны через совместное распределение:\n  $$\n  p(x, z) = p(x|z) p(z),\n  $$\n  где:\n  - $p(z)$: априорное распределение латентных переменных. Обычно это стандартное нормальное распределение $\\mathcal{N}(0, I)$.\n  - $p(x|z)$: вероятность наблюдения данных $x$, если латентные переменные $z$ заданы. Эта вероятность моделируется декодером.\nВ VAE цель — аппроксимировать апостериорное распределение $p(z|x)$ через вариационное приближение $q(z|x)$ и использовать его для генерации данных. Это основано на баейсовском подходе, где $p(x)$ выражается через интеграл:\n$$\np(x) = \\int p(x|z)p(z)dz\n$$\n## Функция ошибки на основе метода максимального правдоподобия\nОптимизация модели направлена на максимизацию логарифма правдоподобия данных:\n$$\n\\log p(x) = \\log \\int p(x|z)p(z)dz\n$$\nОднако прямой расчет этого выражения сложен из-за вычислительной трудности интеграла.\n## Причины построения ELBO\nELBO (Evidence Lower Bound) вводится как нижняя граница для аппроксимации $\\log p(x)$. Это позволяет оптимизировать модель, избегая прямого вычисления интеграла. ELBO упрощает задачу, разделяя её на две части: реконструкцию данных и регуляризацию скрытого пространства.\n\n## Метод построения ELBO\nИспользуется разложение $\\log p(x)$:\n$$\n\\log p(x) = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) || p(z))\n$$\n1. **Первая часть**:\n   - $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ — мера качества реконструкции данных.\n2. **Вторая часть**:\n   - $\\text{KL}(q(z|x) || p(z))$ — регуляризация, минимизирующая расхождение между $q(z|x)$ и $p(z)$.\n\nЦель — максимизация $\\mathcal{L}_{\\text{ELBO}}$, что приближает $\\log p(x)$.\n## Итог\nБаейсовское моделирование в VAE основано на использовании аппроксимации апостериорного распределения. ELBO упрощает оптимизацию функции правдоподобия, разделяя её на реконструкцию и регуляризацию. Это делает обучение модели вычислительно эффективным.\n\n"
    },
    "35. Denoising diffusion models - общий принцип работы, описание прямого процесса и основные принципы описания обратного процесса..md": {
        "markdown": "## Общий принцип работы\n\nDenoising diffusion models представляют собой классы моделей генерации данных, основанных на постепенном добавлении шума к данным (прямой процесс) и обучении обратного процесса для восстановления исходных данных из зашумленных.\n## Прямой процесс\n\nПрямой процесс заключается в последовательном добавлении гауссовского шума к данным. Он описывается уравнением:\n\n$$q(x_t \\mid x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{\\alpha_t} x_{t-1}, (1 - \\alpha_t)I),$$\n\nгде $x_t$ - состояние данных на шаге $t$, $\\alpha_t$ - коэффициенты, контролирующие величину добавленного шума.\n\nИтерации продолжаются до тех пор, пока данные не станут распределены как стандартное гауссовское распределение (то есть зашумлены).\nХорошим решением в этой сфере является использование “линейного планировщика”, для увеличения добавляемого шума с каждый шагом зашумления.\n\n## Обратный процесс\n\nОбратный процесс предполагает восстановление данных из полученных зашумленных версий. Он моделируется условным распределением:\n\n$$p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)),$$\n\nгде параметры $\\mu_\\theta$ и $\\Sigma_\\theta$ оцениваются с помощью нейронной сети, обученной минимизировать разницу между истинным распределением $q$ и модельным распределением $p_\\theta$.\n\nОсновной принцип обучения - минимизация вариации Кульбака-Лейблера между распределениями прямого и обратного процессов.\n![[Pasted image 20250106181049.png]]\n## Генерация изображений\n1. _Безусловная генерация изображений_ означает, что модель преобразует шум в любую “случайную репрезентативную выборку данных”. \n   Процесс генерации не контролируется и не управляется, и модель может генерировать изображение любого характера.\n2. _Условная генерация изображений_ - это когда модели предоставляется дополнительная информация с помощью текста (text2img) или меток классов (как в CGANs). \n   Это случай управляемой или управляемой генерации изображений. Предоставляя дополнительную информацию, мы ожидаем, что модель будет генерировать определенные наборы изображений. Например, вы можете обратиться к двум изображениям в начале текстовое описание того, что мы хотим получить.\n\n## Пример на архитектуре Stable Diffusion\n1. **Кодировщик текста**  \n   Преобразует текстовое приглашение в машиночитаемый вектор.\n2. **U-Net**  \n   Диффузионная модель для генерации изображений в уменьшенном пространстве (пошагово удаляет шум, как описано выше).\n3. **Вариационный автоэнкодер**  \n   - Кодер: уменьшает размер изображения перед обработкой U-Net.  \n   - Декодер: восстанавливает изображение до исходного размера после генерации.\n![[Pasted image 20250106181014.png]]"
    },
    "Гиперпараметры. Скорость обучения и размер батча..md": {
        "markdown": "## Гиперпараметры\nГиперпараметры — это параметры, которые задаются перед началом обучения модели и не изменяются в процессе. Они влияют на качество и скорость обучения. Примеры: скорость обучения, размер батча, количество слоев и нейронов.\n## Скорость обучения\nСкорость обучения (learning rate) определяет, насколько большие шаги делаются при обновлении параметров модели:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде η — скорость обучения.  \nОсобенности:\n- Слишком большая скорость обучения может привести к нестабильности и \"перелету\" через минимум функции потерь.\n- Слишком маленькая замедляет обучение и может застрять в локальном минимуме.\nСовременные подходы включают адаптивные методы (Adam, RMSProp) или использование планов изменения скорости (learning rate schedule), таких как уменьшение скорости при отсутствии улучшения метрик.\n## Размер батча\nРазмер батча определяет количество примеров из обучающей выборки, которые используются для одного шага обновления.  \nОсобенности:\n- **Малый размер батча**: обеспечивает более точные обновления, лучше подходит для шумных данных, но увеличивает время обучения.\n- **Большой размер батча**: ускоряет вычисления, но может привести к застреванию в локальных минимумах.\nБаланс между точностью и скоростью обучения достигается выбором оптимального размера батча, обычно 32, 64 или 128 (лучше использовать батчи кратные 2, так как современные GPU и библиотеки, такие как cuBLAS, оптимизированы для работы с матрицами размером, кратным 2. Это обеспечивает более эффективное использование памяти, шины данных и вычислительных ресурсов, ускоряя операции свертки и линейной алгебры)\n[[9. Стохастический градиентный спуск. Батчи обучающей выборки.|Подробнее]]\nПри большом размере батча можно понизить $\\beta_1$ в оптимизаторе Adam для более быстрого учёта изменений, но всё равно все подобные изменения требует экспериментального подтверждения\n## Связь между скоростью обучения и размером батча\nЕдиного ответа нет, в разных источниках предлагается при увеличении размера батча в n раз увеличить скорость в обучения тоже в n так, так и в **корень из n** раз, так и не изменять вовсе при незначительном увеличении."
    },
    "Линейное отображение. Векторно-матричное дифференцирование..md": {
        "markdown": "## Линейное отображение\nЛинейное отображение — это отображение между векторными пространствами, которое сохраняет операции сложения и умножения на скаляр. Формально, если A — это линейное отображение, то для любых векторов v, w и скаляров alpha, beta выполняются следующие свойства:\n\n$$ A(\\alpha \\mathbf{v} + \\beta \\mathbf{w}) = \\alpha A(\\mathbf{v}) + \\beta A(\\mathbf{w}) $$\n\n## Векторно-матричное дифференцирование\n\nВекторно-матричное дифференцирование используется для нахождения производных векторных и матричных функций. Например, если функция y = A * x + b, где A — матрица, a,b — векторы, то производная функции по вектору x будет:\n\n$$ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = A $$\n\nЭтот метод широко применяется для вычисления градиентов в задачах оптимизации.\n\n## Пример\n\n^fafd8c\n\n### Прямой проход (Forward Pass)\n1. **Входной вектор:** $\\mathbf{x}$ (размерности $n_{\\text{in}} \\times 1$).\n2. **Выход на скрытом слое, $\\mathbf{z} = \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b}$:\n   где:\n   - $\\mathbf{W}$ — матрица весов (размерности $n_{\\text{hidden}} \\times n_{\\text{in}}$),\n   - $\\mathbf{b}$ — вектор смещений (размерности $n_{\\text{hidden}} \\times 1$).\n3. **Применение функции активации ReLU, $\\mathbf{a} = \\text{ReLU}(\\mathbf{z})$:\n   где:\n   $\\text{ReLU}(\\mathbf{z}) = \\max(0, \\mathbf{z})$\n4. **Выход сети, $y_{\\text{pred}} = \\mathbf{a}^T \\cdot \\mathbf{w}_{\\text{out}} + b_{\\text{out}}$:\n   где:\n   - $\\mathbf{w}_{\\text{out}}$ — вектор весов выходного слоя (размерности $n_{\\text{hidden}} \\times 1$),\n   - $b_{\\text{out}}$ — смещение выходного слоя (скаляр).\n5. **Функция потерь (MSE), $L = \\frac{1}{2} \\left(y_{\\text{pred}} - y_{\\text{true}}\\right)^2$:\n   где $y_{\\text{true}}$ — истинное значение.\n### Обратное распространение ошибки (Backward Pass)\n#### 1. Градиент ошибки по выходу сети ($y_{\\text{pred}}$):\n$\\frac{\\partial L}{\\partial y_{\\text{pred}}} = y_{\\text{pred}} - y_{\\text{true}}$\n#### 2. Градиент ошибки по активации ($\\mathbf{a}$):\nГрадиент передаётся через выходной слой:\n$\\frac{\\partial L}{\\partial \\mathbf{a}} = \\frac{\\partial L}{\\partial y_{\\text{pred}}} \\cdot \\frac{\\partial y_{\\text{pred}}}{\\partial \\mathbf{a}}$\n\nгде:\n$\\frac{\\partial y_{\\text{pred}}}{\\partial \\mathbf{a}} = \\mathbf{w}_{\\text{out}}$\nИтог:\n$\\frac{\\partial L}{\\partial \\mathbf{a}} = \\left(y_{\\text{pred}} - y_{\\text{true}}\\right) \\cdot \\mathbf{w}_{\\text{out}}$\n#### 3. Градиент ошибки по $\\mathbf{z}$:\nДля ReLU функция активации имеет производную:\n\n$$\n\n\\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{z}} = \\begin{cases}\n\n1, & \\text{если } \\mathbf{z} > 0, \\\\\n\n0, & \\text{если } \\mathbf{z} \\leq 0.\n\n\\end{cases}\n\n$$\nСоответственно, градиент по $\\mathbf{z}$ вычисляется как:\n$\\frac{\\partial L}{\\partial \\mathbf{z}} = \\frac{\\partial L}{\\partial \\mathbf{a}} \\cdot \\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{z}}$\n#### 4. Градиент ошибки по весам $\\mathbf{W}$:\nДля вычисления градиента по весам скрытого слоя используем правило цепочки:\n$\\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}}$\nПоскольку:\n$\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} = \\mathbf{x}^T$\nто:\n$\\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\mathbf{x}^T$\n### Итоговая процедура обновления весов\nПосле вычисления градиентов параметры обновляются с использованием шага обучения $\\alpha$, например:\n1. Обновление весов выходного слоя:\n   $\\mathbf{w}_{\\text{out}} \\leftarrow \\mathbf{w}_{\\text{out}} - \\alpha \\cdot \\frac{\\partial L}{\\partial \\mathbf{w}_{\\text{out}}}$\n2. Обновление смещения выходного слоя:\n   $b_{\\text{out}} \\leftarrow b_{\\text{out}} - \\alpha \\cdot \\frac{\\partial L}{\\partial b_{\\text{out}}}$"
    }
}

questions_numerated = {
    i: {j: v for j, (k, v) in enumerate(v.items())}
    for i, (k, v) in enumerate(questions.items())
}

# themes_numerated = {
#     i: {
#         j: {k: v for k, (k_name, v) in enumerate(q.items())}
#         for j, (q_name, q) in enumerate(v.items())
#     }
#     for i, (theme_name, v) in enumerate(themes.items())
# }

# themes_all_numerated = {
#     i: {j: v for j, (k, v) in enumerate(v.items())}
#     for i, (k, v) in enumerate(themes_all.items())
# }

def get(i=None, j=None, silent: bool = False):
    if i is None:
        info_string = ''
        for i, (question, codes) in enumerate(questions.items()):
            info_string += f'{i} {question.strip("1234567890 .")}\n'
            if len(codes.keys()) > 1:
                for j, code in enumerate(codes.keys()):
                    info_string += f'{"-"*2} {i}.{j} {code}\n'
        if silent:
            pyperclip.copy(info_string)
        else:
            print(info_string)
    else:
        if j is None:
            return_string = ''
            for k, v in questions_numerated[i].items():
                # if k == 'markdown':
                #     return_string += '#' + '#'.join(v.split('\n'))
                # else:
                return_string += v

            pyperclip.copy(return_string.strip())
        else:
            pyperclip.copy(questions_numerated[i][j].strip())

# def get(i=None, j=None, k=None, silent: bool = False):
#     if i is None or j is None:
#         info_string = ''
#         for i, (theme, questions) in enumerate(themes.items()):
#             info_string += f"{i} {theme}\n"
#             for j, (question, codes) in enumerate(questions.items()):
#                 info_string += f'{"-"*2} {i}.{j} {question}\n'
#                 for k, code in enumerate(codes.keys()):
#                     info_string += f'{"-"*4} {i}.{j}.{k} {code}\n'
#         if silent:
#             pyperclip.copy(info_string)
#         else:
#             print(info_string)
#     else:
#         if k is None:
#             pyperclip.copy(themes_all_numerated[i][j].strip())
#         else:
#             pyperclip.copy(themes_numerated[i][j][k].strip())
