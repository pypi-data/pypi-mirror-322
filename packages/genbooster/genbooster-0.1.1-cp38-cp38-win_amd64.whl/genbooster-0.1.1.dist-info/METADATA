Metadata-Version: 2.4
Name: genbooster
Version: 0.1.1
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Rust
Classifier: License :: OSI Approved :: BSD License
Classifier: Operating System :: OS Independent
Requires-Dist: nnetsauce
Requires-Dist: numpy >=1.20.0
Requires-Dist: pandas
Requires-Dist: scikit-learn >=1.0.0
License-File: LICENSE
Summary: A fast boosting implementation using Rust and Python
Author-email: "T. Moudiki" <thierry.moudiki@gmail.com>
Requires-Python: >=3.7
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
Project-URL: Repository, https://github.com/yourusername/genbooster

# Genbooster

A fast gradient boosting implementation using Rust and Python. Any base learner can be used.

## 1 - Installation

```bash
pip install genbooster
```

## 2 - Usage

### 2.1 - Regression

```python
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.utils.discovery import all_estimators
from sklearn.datasets import load_diabetes
from sklearn.linear_model import Ridge, RidgeCV
from sklearn.tree import ExtraTreeRegressor
from sklearn.model_selection import train_test_split
from genbooster.genbooster import BoosterRegressor
from sklearn.metrics import mean_squared_error
from tqdm import tqdm

# Load diabetes dataset
X, y = load_diabetes(return_X_y=True)
y = y.astype(np.float64)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=42)

results = []

for estimator in tqdm(all_estimators(type_filter='regressor')):
    try:
        regr = BoosterRegressor(base_estimator=estimator[1]())
        regr.fit(X_train, y_train)
        print(estimator[0])
        results.append((estimator[0], np.sqrt(mean_squared_error(y_test, regr.predict(X_test)))))
    except Exception as e:
        print(e)
        continue

results = pd.DataFrame(results, columns=['Estimator', 'RMSE']).sort_values(by='RMSE')
print(results)
```

### 2.2 - Classification

```python
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.utils.discovery import all_estimators
from sklearn.datasets import load_iris, load_breast_cancer, load_wine
from sklearn.linear_model import Ridge, RidgeCV
from sklearn.tree import ExtraTreeRegressor
from sklearn.model_selection import train_test_split
from genbooster.genbooster import BoosterClassifier
from sklearn.metrics import mean_squared_error
from tqdm import tqdm
from sklearn.utils.discovery import all_estimators


X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
clf = BoosterClassifier(base_estimator=ExtraTreeRegressor(), 
                        n_hidden_features=10)
clf.fit(X_train, y_train)
preds = clf.predict(X_test)
print(np.mean(preds == y_test))
```


