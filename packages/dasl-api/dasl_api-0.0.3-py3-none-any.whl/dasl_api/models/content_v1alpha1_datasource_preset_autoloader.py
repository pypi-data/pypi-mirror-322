# coding: utf-8

"""
    Antimatter Security Lakehouse Public API

    Interact with the Antimatter ASL API

    The version of the OpenAPI document: 0.0.3
    Contact: support@antimatter.io
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from dasl_api.models.core_v1alpha1_data_source_autoloader_spec_cloud_files import CoreV1alpha1DataSourceAutoloaderSpecCloudFiles
from typing import Optional, Set
from typing_extensions import Self

class ContentV1alpha1DatasourcePresetAutoloader(BaseModel):
    """
    The databricks autoloader configuration for this preset. This configuration will be used to load data from the source  during the bronze stage of the data pipeline. The fields available mirror those found in the DataSourceSpec except for the location field which is not available here. 
    """ # noqa: E501
    format: StrictStr = Field(description="json | parquet | csv | kafka | txt | cloudFiles")
    schema_file: Optional[StrictStr] = Field(default=None, description="An optional file containing the schema of the data source", alias="schemaFile")
    cloud_files: Optional[CoreV1alpha1DataSourceAutoloaderSpecCloudFiles] = Field(default=None, alias="cloudFiles")
    __properties: ClassVar[List[str]] = ["format", "schemaFile", "cloudFiles"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ContentV1alpha1DatasourcePresetAutoloader from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of cloud_files
        if self.cloud_files:
            _dict['cloudFiles'] = self.cloud_files.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ContentV1alpha1DatasourcePresetAutoloader from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "format": obj.get("format"),
            "schemaFile": obj.get("schemaFile"),
            "cloudFiles": CoreV1alpha1DataSourceAutoloaderSpecCloudFiles.from_dict(obj["cloudFiles"]) if obj.get("cloudFiles") is not None else None
        })
        return _obj


