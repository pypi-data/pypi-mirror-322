from _typeshed import Incomplete
from ydata.connectors.base_connector import BaseConnector
from ydata.dataset.dataset import Dataset
from ydata.dataset.engines import VALID_ENGINES as VALID_ENGINES

class BigQueryConnector(BaseConnector):
    STORAGE_TYPE: Incomplete
    credentials: Incomplete
    def __init__(self, project_id: Incomplete | None = None, gcs_credentials: Incomplete | None = None, key_path: Incomplete | None = None, keyfile_dict: Incomplete | None = None, scopes: Incomplete | None = None) -> None: ...
    @property
    def project_id(self): ...
    @property
    def client(self): ...
    def set_client(self) -> None: ...
    def set_env_vars(self) -> None: ...
    def dataset_exist(self, dataset: str) -> bool: ...
    def table_exist(self, table: str, dataset: str) -> bool: ...
    @property
    def datasets(self) -> list[str]: ...
    def set_datasets(self) -> None: ...
    def list_tables(self, dataset: str) -> list[str]: ...
    def get_or_create_dataset(self, dataset: str): ...
    def delete_table_if_exists(self, dataset: str, table: str): ...
    def delete_dataset_if_exists(self, dataset: str): ...
    def table_schema(self, dataset: str, table: str): ...
    def query(self, query, n_sample: int | None = None): ...
    def query_sample(self, query: str, n_sample=...): ...
    def write_query_to_gcs(self, query: str, path: str, tmp_dataset: str = 'ydata_tmp', tmp_table: str = 'tmp_query_table', clean_tmp: bool = True): ...
    def export_table_to_gcs(self, dataset: str, table: str, bucket: str, filename: str, compression=..., destination_format=...): ...
    def write_table_from_data(self, data: Dataset | VALID_ENGINES, database: str, table: str): ...
    def write_table_from_query(self, query: str, dataset: str, table: str, write_disposition: Incomplete | None = None): ...
    def test(self) -> None: ...
