import dask
from dask.dataframe import DataFrame as ddDataframe, Series as ddSeries
from dask.dataframe.core import Scalar as ddScalar
from dask.delayed import Delayed as Delayed
from numpy import ndarray as ndarray
from pandas import DataFrame as pdDataframe, Series as pdSeries
from typing import Literal
from ydata.dataset.engines import VALID_ENGINES
from ydata.dataset.schemas import DatasetSchema as Schema
from ydata.utils.data_types import VariableType

class Dataset:
    def __init__(self, df: VALID_ENGINES, schema: dict[str, Schema] | None = None, sample: float = 0.2, index: str | dask.dataframe.core.Index | None = None, divisions: list | tuple | None = None) -> None: ...
    def copy(self) -> Dataset: ...
    @property
    def ncols(self) -> int: ...
    @property
    def nrows(self) -> int: ...
    @property
    def columns(self) -> list[str | int]: ...
    @property
    def index(self) -> str | None: ...
    @property
    def loc(self): ...
    @property
    def schema(self) -> dict: ...
    @schema.setter
    def schema(self, new_value: dict[str, VariableType | str]): ...
    def apply(self, function: callable, axis: int | str = 1, raw: bool = False, args: tuple | None = None, meta: dict | list[tuple] | tuple | Dataset | None | str = '__no_default__') -> Dataset: ...
    def shape(self, lazy_eval: bool = True, delayed: bool = False) -> tuple[int | Delayed | None, int]: ...
    @property
    def memory_usage(self) -> ddSeries: ...
    def missings(self, compute: bool = False) -> ddSeries | pdSeries: ...
    @property
    def nmissings(self) -> int: ...
    def infer_dtypes(self, schema: dict | None = None): ...
    def select_dtypes(self, include: str | list | None = None, exclude: str | list | None = None) -> Dataset: ...
    def astype(self, column: str, vartype: VariableType | str, format: str | None = None): ...
    def update_types(self, dtypes: list): ...
    def to_pandas(self) -> pdDataframe: ...
    def to_numpy(self) -> ndarray: ...
    def to_dask(self) -> ddDataframe: ...
    def value_counts(self, col: str, compute: bool = True) -> ddSeries | pdSeries: ...
    def uniques(self, col: str, approx: bool = True, delayed: bool = False) -> int | ddScalar: ...
    def drop_columns(self, columns: str | list, inplace: bool = False) -> Dataset | None: ...
    def select_columns(self, columns: str | list, copy: bool = True) -> Dataset: ...
    def query(self, query: str) -> Dataset: ...
    def sample(self, size: float | int, strategy: Literal['random', 'stratified'] = 'random', **strategy_params) -> Dataset: ...
    def reorder_columns(self, columns: list[str]) -> Dataset: ...
    def divisions(self) -> tuple: ...
    def sort_values(self, by: list[str], ignore_index: bool = True, inplace: bool = False) -> Dataset | None: ...
    def sorted_index(self, by: list[str]) -> pdSeries: ...
    @property
    def known_divisions(self) -> bool: ...
    def head(self, n: int = 5) -> pdDataframe: ...
    def tail(self, n: int = 5) -> pdDataframe: ...
    def __len__(self) -> int: ...
    def __contains__(self, key) -> bool: ...
    def __getitem__(self, key) -> Dataset: ...
