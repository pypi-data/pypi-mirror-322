from _typeshed import Incomplete
from dask.distributed import Future
from dataclasses import dataclass
from pandas import DataFrame as pdDataframe
from ydata.characteristics import ColumnCharacteristic
from ydata.dataset import Dataset, DatasetType
from ydata.metadata.builder import MetadataConfigurationBuilder
from ydata.metadata.column import Column
from ydata.metadata.compute import ComputeConfig

logger: Incomplete
DEFAULT_PARTITION_SIZE: int

def assign_correlation(data: Future | pdDataframe, m: Metadata): ...
def assign_characteristics(data: Future | tuple, m: Metadata, schema, columns: dict | None = None): ...

@dataclass
class DatasetAttr:
    sortbykey: list[str] = ...
    entities: list[str] = ...
    @staticmethod
    def fields(): ...
    def empty(self): ...
    def __init__(self, sortbykey=..., entities=...) -> None: ...

def istype(d: dict, inputtype=...): ...
def valid_input_col(d: dict): ...

class Metadata:
    DATASET_WARNINGS: list[str]
    MIN_ROWS_FOR_SAMPLING: int
    MAX_CORR_CARDINALITY: int
    status: Incomplete
    def __init__(self, dataset: Dataset | None = None, dataset_attrs: dict | None = None, columns: dict | None = None, dataset_type: DatasetType | str = ..., infer_characteristics: bool = False, characteristics: dict | None = None, pairwise_metrics: bool = True, partition_size: int = ..., intercolumns_warnings: bool = True, compute_config: ComputeConfig | dict | None = None, configuration_builder: MetadataConfigurationBuilder | None = None) -> None: ...
    def __call__(self, dataset: Dataset, dataset_attrs: dict | DatasetAttr | None = None, columns: dict | None = None, dataset_type: DatasetType | str = ...) -> Metadata: ...
    def set_dataset_type(self, dataset_type: DatasetType | str, dataset_attrs: dict | None = None): ...
    def set_dataset_attrs(self, sortby: str | list[str], entities: str | list[str] | None = None): ...
    def clean_characteristics(self, matched_dictionary: dict, threshold: float, confidence_level: float) -> dict: ...
    def compute_characteristics(self, dataset: Dataset, columns: dict | None = None, deferred: bool = False) -> dict | Future: ...
    def compute_correlation(self, dataset: Dataset, columns: dict | None = None, deferred: bool = False) -> pdDataframe | Future: ...
    def add_characteristics(self, characteristics: dict[str, list[ColumnCharacteristic | str] | ColumnCharacteristic | str]): ...
    def add_characteristic(self, column: str, characteristic: ColumnCharacteristic | str): ...
    def remove_characteristics(self, characteristics: dict[str, list[ColumnCharacteristic | str] | ColumnCharacteristic | str]): ...
    def remove_characteristic(self, column: str, characteristic: ColumnCharacteristic | str): ...
    def get_characteristics(self) -> dict[str, list[ColumnCharacteristic]]: ...
    def set_characteristics(self, characteristics: dict[str, list[ColumnCharacteristic | str]]): ...
    def get_possible_targets(self): ...
    @property
    def columns(self) -> dict | None: ...
    def update_datatypes(self, value: dict, dataset: Dataset | None = None): ...
    @property
    def cardinality(self) -> dict: ...
    @property
    def isconstant(self) -> list: ...
    @property
    def warnings(self) -> dict: ...
    @property
    def summary(self): ...
    @property
    def shape(self) -> tuple: ...
    @property
    def ncols(self): ...
    @property
    def target(self): ...
    @target.setter
    def target(self, value: str | Column): ...
    def get_numerical_columns(self): ...
    @property
    def numerical_vars(self): ...
    @property
    def date_vars(self): ...
    @property
    def categorical_vars(self): ...
    @property
    def id_vars(self): ...
    @property
    def longtext_vars(self): ...
    @property
    def string_vars(self): ...
    @property
    def dataset_attrs(self): ...
    @dataset_attrs.setter
    def dataset_attrs(self, attrs: dict): ...
    def save(self, path: str): ...
    @staticmethod
    def load(path: str) -> Metadata: ...
    def __getitem__(self, key): ...
    def combine(self, other: Metadata): ...
