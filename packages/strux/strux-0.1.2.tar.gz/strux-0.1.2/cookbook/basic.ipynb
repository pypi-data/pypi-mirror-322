{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install strux\n",
    "# !pip install strux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from strux import PostgresDataSource, RegressionConfig, Sequential, exact_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strux\n",
    "Strux is a Python framework for structured outputs model versioning. It helps you:\n",
    "\n",
    "- Track changes in your model outputs over time\n",
    "- Detect regressions in model behavior\n",
    "- Compare model outputs against baselines\n",
    "- Validate outputs against schema definitions\n",
    "\n",
    "This notebook demonstrates the basic usage of Strux using a simple sentiment analysis example.\n",
    "\n",
    "In this example, we will:\n",
    "\n",
    "1. Define input/output schemas\n",
    "2. Define an inference function\n",
    "3. Connect to a database\n",
    "4. Run inference on a dataset\n",
    "5. Compare the results to a baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define connection parameters in a dictionary and pass it to the `PostgresDataSource` constructor. The `PostgresDataSource` will be used to connect to the database and fetch the data.\n",
    "\n",
    "It is recommended to use environment variables to store connection parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Connection Parameters\n",
    "connection_params = {\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"POSTGRES_HOST\"),\n",
    "    \"port\": os.getenv(\"POSTGRES_PORT\"),\n",
    "    \"database\": os.getenv(\"POSTGRES_DATABASE\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input/output schemas\n",
    "Strux supports Pydantic models as input/output schemas. \n",
    "\n",
    "The `InputSchema` is a Pydantic model that we will coerce the read output from the database into. In this scenario, each row from the database has a `chat_history` column that contains a list of `ChatMessage` objects stored as JSONB.\n",
    "\n",
    "The `OutputSchema` is a Pydantic model that we will coerce the output of our inference function into. In this scenario, we will return a `sentiment` field that is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input/output schemas\n",
    "class ChatMessage(BaseModel):\n",
    "    role: Literal[\"user\", \"assistant\"]\n",
    "    content: str\n",
    "\n",
    "class InputSchema(BaseModel):\n",
    "    chat_history: List[ChatMessage]\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a `PostgresDataSource` that will fetch the data from the database and coerce it into the `InputSchema`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = PostgresDataSource(\n",
    "    query=\"SELECT * FROM matador_s_idx LIMIT 1\",\n",
    "    connection_params=connection_params,\n",
    "    schema=InputSchema,\n",
    "    json_columns={\"chat_history\": List[ChatMessage]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define inference function\n",
    "Strux builds pipelines from steps. A \"Step\" is the smallest unit of work in Strux. It is a function that takes an input and returns an output where the input and output are both Pydantic models. \n",
    "\n",
    "For simplicity, we will define a single step that takes the input schema and returns the output schema. For generative AI models that produce structured outputs like OpenAI's API, this is the most common case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input: InputSchema) -> OutputSchema:\n",
    "    return OutputSchema(sentiment=\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a pipeline\n",
    "In Strux, a pipeline is a sequence of steps. We can define a pipeline by calling the `from_steps` method on the `Sequential` class. This method takes a list of steps and returns a pipeline.\n",
    "\n",
    "In this scenario, we will define a pipeline that takes the input schema, runs inference on it, and returns the output schema.\n",
    "\n",
    "We will also define a `RegressionConfig` that will be used to configure the pipeline. The `RegressionConfig` is a configuration object that we will use to configure the inference function. We will use the `exact_match` strategy to compare the output of our inference function to the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RegressionConfig(\n",
    "    target_schema=OutputSchema,\n",
    "    strict_fields=[\"sentiment\"],\n",
    ")\n",
    "\n",
    "config.configure_field(\"sentiment\", strategy=exact_match())\n",
    "\n",
    "pipeline = Sequential.from_steps(\n",
    "    data_source=source,\n",
    "    steps=[(\"sentiment\", inference, OutputSchema)],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(connection_params: dict) -> Sequential:\n",
    "    source = PostgresDataSource(\n",
    "        query=\"SELECT * FROM matador_s_idx LIMIT 1\",\n",
    "        connection_params=connection_params,\n",
    "        schema=InputSchema,\n",
    "        json_columns={\"chat_history\": List[ChatMessage]}\n",
    "    )\n",
    "\n",
    "    config = RegressionConfig(\n",
    "        target_schema=OutputSchema,\n",
    "        strict_fields=[\"sentiment\"],\n",
    "    )\n",
    "\n",
    "    config.configure_field(\"sentiment\", strategy=exact_match())\n",
    "\n",
    "    return Sequential.from_steps(\n",
    "        data_source=source,\n",
    "        steps=[(\"sentiment\", inference, OutputSchema)],\n",
    "        config=config\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = setup_pipeline(connection_params)\n",
    "\n",
    "# First run - create baseline\n",
    "results = pipeline.run(\n",
    "    baseline_path=\"baselines/sentiment_baseline.json\"\n",
    ")\n",
    "\n",
    "# Check if this is first run (no baseline)\n",
    "is_first_run = all(\n",
    "    \"is_first_run\" in step.metadata and step.metadata[\"is_first_run\"]\n",
    "    for step in results.step_validations\n",
    ")\n",
    "\n",
    "if is_first_run:\n",
    "    print(\"\\nFirst run completed. Would you like to save as baseline? (y/n)\")\n",
    "    if input().lower() == 'y':\n",
    "        results.save_as_baseline(\"baselines/sentiment_baseline.json\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Make changes to your model\")\n",
    "        print(\"2. Run regression test against baseline:\")\n",
    "        print(\"   pipeline.run(baseline_path='baselines/sentiment_baseline.json')\")\n",
    "else:\n",
    "    if results.passed:\n",
    "        print(\"\\nRegression test passed. No changes needed.\")\n",
    "    else:\n",
    "        print(\"\\nRegression test failed. Please make changes to your model.\")\n",
    "        for step in results.get_failed_steps():\n",
    "            print(f\"\\n{step.format_summary()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second run - compare to baseline\n",
    "Suppose we make some changes to our model and want to run the pipeline again. We can do this by calling the `run` method on the pipeline again and passing in the baseline path. We can change the inference function directly in the pipeline definition or we can define a new inference function and pass it to the `run` method.\n",
    "\n",
    "In this scenario, we will change the inference function directly in the pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input: InputSchema) -> OutputSchema:\n",
    "    return OutputSchema(sentiment=\"negative\")\n",
    "\n",
    "pipeline = pipeline.from_steps(\n",
    "    data_source=source,\n",
    "    steps=[(\"sentiment\", inference, OutputSchema)],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "results = pipeline.run(\n",
    "    baseline_path=\"baselines/sentiment_baseline.json\"\n",
    ")\n",
    "\n",
    "if results.passed:\n",
    "    print(\"\\nRegression test passed. No changes needed.\")\n",
    "else:\n",
    "    print(\"\\nRegression test failed. Please make changes to your model.\")\n",
    "    for step in results.get_failed_steps():\n",
    "        print(f\"\\n{step.format_summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
