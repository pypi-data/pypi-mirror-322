# easy_rag_llm

## CAUTION
- easy-rag-llm==1.0.* version is testing version. These versions are usually invalid.

## ğŸ‡°ğŸ‡· ì†Œê°œ
- easy_rag_llmëŠ” OpenAI ë° DeepSeek ëª¨ë¸ì„ ì§€ì›í•˜ëŠ” ê°„ë‹¨í•œ RAG(ì •ë³´ ê²€ìƒ‰ ë° ìƒì„±) ê¸°ë°˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ RAG LLMì„ ì„œë¹„ìŠ¤ì— í†µí•©ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.
- (2025.01.16 ê¸°ì¤€/ v1.1.0) í•™ìŠµê°€ëŠ¥í•œ ìë£Œ í¬ë§·ì€ PDFì…ë‹ˆë‹¤.

## ğŸ‡ºğŸ‡¸ Introduction
- easy_rag_llm is a lightweight RAG-based service that supports both OpenAI and DeepSeek models.
It is designed to seamlessly integrate RAG-based LLM functionalities into your service.
- As of 2025-01-15 (v1.1.0), the supported resource format for training is PDF.

## Usage
#### Install (https://pypi.org/project/easy-rag-llm/)
```bash
pip install easy_rag_llm
```

#### How to integrate to your service?
```python
from easy_rag import RagService

rs = RagService(
    embedding_model="text-embedding-3-small", #Fixed to OpenAI model
    response_model="deepseek-chat",  # Options: "openai" or "deepseek-chat"
    open_api_key="your_openai_api_key_here",
    deepseek_api_key="your_deepseek_api_key_here",
    deepseek_base_url="https://api.deepseek.com",
)

rs2 = RagService( # this is example for openai chat model
    embedding_model="text-embedding-3-small",
    response_model="gpt-3.5-turbo",
    open_api_key="your_openai_api_key_here",
)

# Learn from all files under ./rscFiles
resource = rs.rsc("./rscFiles", force_update=False, max_workers=5, embed_workers=10) # default workers are 10.

query = "Explain what is taught in the third week's lecture."
response, top_evidence = rs.generate_response(resource, query, evidence_num=5) # default evidence_num is 3.

print(response)
```

### ğŸ‡°ğŸ‡· ì•ˆë‚´.
- pdf ì œëª©ì„ ëª…í™•í•˜ê²Œ ì ì–´ì£¼ì„¸ìš”. ë©”íƒ€ë°ì´í„°ì—ëŠ” pdfì œëª©ì´ ì¶”ì¶œë˜ì–´ ë“¤ì–´ê°€ë©°, ë‹µë³€ ê·¼ê±°ë¥¼ ì¶œë ¥í• ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `rs.rsc("./folder")` ì‘ë™ì‹œ `faiss_index.bin`ê³¼ `metadata.json`ì´ ìƒì„±ë©ë‹ˆë‹¤. ì´í›„ì—” ì´ë¯¸ ë§Œë“¤ì–´ì§„ .binê³¼ .jsonìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ë§Œì•½ í´ë”ì— ìƒˆë¡œìš´ íŒŒì¼ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•˜ì—¬ ë³€ê²½í•˜ê³  ì‹¶ë‹¤ë©´ `force_update=True`ë¡œ ì„¤ì •í•˜ì—¬ ê°•ì œì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- max_workerëŠ” pdf ë¶„í•  ë³‘ë ¬ì²˜ë¦¬ë¥¼ ìœ„í•œ ë™ì‹œì‘ì—… ê°œìˆ˜ì´ê³ , embed_workerëŠ” ì„ë² ë”© ì‘ì—… ë³‘ë ¬ì²˜ë¦¬ë¥¼ ìœ„í•œ ë™ì‹œì‘ì—… ê°œìˆ˜ì…ë‹ˆë‹¤. ë‘˜ë‹¤ ê¸°ë³¸ê°’ 10ìœ¼ë¡œ ê°ê° CPU ì½”ì–´ê°œìˆ˜ì™€ api ratelimitì— ì˜í–¥ì„ ë°›ìœ¼ë¯€ë¡œ ì ì ˆíˆ ì¡°ì ˆí•´ì•¼í•©ë‹ˆë‹¤.

### ğŸ‡ºğŸ‡¸ Note.
- Ensure that your PDFs have clear titles. Extracted titles from the PDF metadata are used during training and for generating evidence-based responses.
- Running `rs.rsc("./folder")` generates `faiss_index.bin` and `metadata.json` files. Subsequently, the system uses the existing .bin and .json files to generate responses. If you want to reflect changes by adding or removing files in the folder, you can enable forced updates by setting `force_update=True`.

### release version.
- 1.0.12 : Supported. However, the embedding model and chat model are fixed to OpenAI's text-embedding-3-small and deepseek-chat, respectively. Fixed at threadpool worker=10, which may cause errors in certain environments.
- 1.1.0 : LTS version.

### TODO
- í´ë”ê¸°ë°˜ ì •ë¦¬ ì§€ì›. ./rscFiles ì…ë ¥í–ˆìœ¼ë©´ rscFilesIndex ìƒì„±í•˜ê³ 
ê·¸ ì•„ë˜ë¡œ ì¸ë±ìŠ¤ ì •ë¦¬.
index/ì•„ë˜ì— ìƒì„±ëœ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ê·¸ê±° ì“°ë„ë¡ í•¨.
- Replace threadPool to asyncio (v1.2.* ~)
- L2 ê¸°ë°˜ ë²¡í„°ê²€ìƒ‰ì™¸ HNSW ì§€ì›. (ì²´ê°ì„±ëŠ¥ ë¹„êµ) (v1.3.0~)
- ì…ë ¥í¬ë§· ë‹¤ì–‘í™”. pdfì™¸ ì§€ì›. (v1.4.* ~)


### What can you do with this?
https://github.com/Aiden-Kwak/ClimateJudgeLLM



### Author Information
- ê³½ë³‘í˜ (https://github.com/Aiden-Kwak)
