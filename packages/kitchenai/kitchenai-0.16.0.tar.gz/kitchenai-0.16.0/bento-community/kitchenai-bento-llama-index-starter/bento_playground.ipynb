{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bento Playground\n",
    "This notebook integrates with kitchenai bento magic commands so you can experiment and serve a lightweight bento to integrate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-llms-openai\n",
      "  Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.8 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from llama-index-llms-openai)\n",
      "  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (6.0.2)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.2.15)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.2.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.10.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.17.0)\n",
      "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.6-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (4.7.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->llama-index-llms-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->llama-index-llms-openai)\n",
      "  Using cached jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.3.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: certifi in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/epuerta/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Downloading llama_index-0.12.8-py3-none-any.whl (6.8 kB)\n",
      "Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.8-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Using cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Using cached llama_cloud-0.1.6-py3-none-any.whl (195 kB)\n",
      "Using cached llama_parse-0.5.18-py3-none-any.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Using cached SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, typing-inspect, tenacity, pypdf, propcache, networkx, multidict, joblib, jiter, greenlet, fsspec, frozenlist, distro, aiohappyeyeballs, yarl, tiktoken, SQLAlchemy, nltk, dataclasses-json, aiosignal, openai, llama-cloud, aiohttp, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 dataclasses-json-0.6.7 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 frozenlist-1.5.0 fsspec-2024.12.0 greenlet-3.1.1 jiter-0.8.2 joblib-1.4.2 llama-cloud-0.1.6 llama-index-0.12.8 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.8 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.12 llama-index-multi-modal-llms-openai-0.4.1 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.18 multidict-6.1.0 networkx-3.4.2 nltk-3.9.1 openai-1.58.1 propcache-0.2.1 pypdf-5.1.0 striprtf-0.0.26 tenacity-9.0.0 tiktoken-0.8.0 typing-inspect-0.9.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "SynchronousOnlyOperation",
     "evalue": "You cannot call this from an async context - use a thread or sync_to_async.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall llama-index llama-index-llms-openai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkitchenai.contrib.notebooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkitchenai_set_project\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkitchenai-bento-llama-index-starter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/IPython/core/extensions.py:62\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/IPython/core/extensions.py:77\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 77\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/projects/kitchenai/kitchenai/contrib/notebooks/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotebookMagics\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_ipython_extension\u001b[39m(ipython):\n\u001b[1;32m      3\u001b[0m     ipython\u001b[38;5;241m.\u001b[39mregister_magics(NotebookMagics)\n",
      "File \u001b[0;32m~/projects/kitchenai/kitchenai/contrib/notebooks/notebooks.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Setup Django and nest_asyncio\u001b[39;00m\n\u001b[1;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDJANGO_SETTINGS_MODULE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkitchenai.settings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mdjango\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkitchenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeFunction,Notebook, CodeImport, CodeSetup\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/__init__.py:24\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(set_prefix)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_prefix:\n\u001b[1;32m     21\u001b[0m     set_script_prefix(\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mFORCE_SCRIPT_NAME \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mFORCE_SCRIPT_NAME\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mapps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINSTALLED_APPS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/apps/registry.py:124\u001b[0m, in \u001b[0;36mApps.populate\u001b[0;34m(self, installed_apps)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Phase 3: run ready() methods of app configs.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m app_config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_app_configs():\n\u001b[0;32m--> 124\u001b[0m     \u001b[43mapp_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready_event\u001b[38;5;241m.\u001b[39mset()\n",
      "File \u001b[0;32m~/projects/kitchenai/kitchenai/plugins/apps.py:16\u001b[0m, in \u001b[0;36mPluginsConfig.ready\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m loaded_plugins \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mKITCHENAI\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplugins\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# First delete plugins that are no longer loaded\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mPlugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname__in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_plugins\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Then create any new plugins that are loaded but not in DB\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plugin_name \u001b[38;5;129;01min\u001b[39;00m loaded_plugins:\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/db/models/query.py:1188\u001b[0m, in \u001b[0;36mQuerySet.delete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1186\u001b[0m collector \u001b[38;5;241m=\u001b[39m Collector(using\u001b[38;5;241m=\u001b[39mdel_query\u001b[38;5;241m.\u001b[39mdb, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1187\u001b[0m collector\u001b[38;5;241m.\u001b[39mcollect(del_query)\n\u001b[0;32m-> 1188\u001b[0m num_deleted, num_deleted_per_model \u001b[38;5;241m=\u001b[39m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# Clear the result cache, in case this QuerySet gets reused.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/db/models/deletion.py:455\u001b[0m, in \u001b[0;36mCollector.delete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(instance, model\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mpk\u001b[38;5;241m.\u001b[39mattname, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m count, {model\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mlabel: count}\n\u001b[0;32m--> 455\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic\u001b[49m\u001b[43m(\u001b[49m\u001b[43musing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavepoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# send pre_delete signals\u001b[39;49;00m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstances_with_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_created\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/db/transaction.py:198\u001b[0m, in \u001b[0;36mAtomic.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit_on_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    197\u001b[0m connection\u001b[38;5;241m.\u001b[39mneeds_rollback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_autocommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# Pretend we're already in an atomic block to bypass the code\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# that disables autocommit to enter a transaction, and make a\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# note to deal with this case in __exit__.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     connection\u001b[38;5;241m.\u001b[39min_atomic_block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     connection\u001b[38;5;241m.\u001b[39mcommit_on_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/db/backends/base/base.py:454\u001b[0m, in \u001b[0;36mBaseDatabaseWrapper.get_autocommit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_autocommit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the autocommit state.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit\n",
      "File \u001b[0;32m~/.local/share/hatch/env/pip-compile/llama-index-starter-bento/UrwETRuf/dev/lib/python3.11/site-packages/django/utils/asyncio.py:24\u001b[0m, in \u001b[0;36masync_unsafe.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDJANGO_ALLOW_ASYNC_UNSAFE\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SynchronousOnlyOperation(message)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Pass onward.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mSynchronousOnlyOperation\u001b[0m: You cannot call this from an async context - use a thread or sync_to_async."
     ]
    }
   ],
   "source": [
    "%pip install llama-index llama-index-llms-openai\n",
    "%load_ext kitchenai.contrib.notebooks\n",
    "%kitchenai_set_project kitchenai-bento-llama-index-starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Register your imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kitchenai_import kitchenai-bento-llama-index-starter-imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kitchenai_setup kitchenai-bento-llama-index-starter-setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These storage variables are the input for the storage function. Use it in your storage logic cell.\n",
    "dir = \"./data/\" #dir is the directory where the temporary file for processing will be placed.\n",
    "metadata = {} #metadata is the metadata for the storage function.\n",
    "kwargs = {} #kwargs is the keyword arguments for the storage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kitchenai_register storage kitchenai-bento-llama-index-starter\n",
    "\"\"\"\n",
    "Storage logic cell\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitchenai.contrib.kitchenai_sdk.api import QuerySchema\n",
    "\n",
    "#Query Schema is the input for the query function. Use it in your query logic cell.\n",
    "data =  QuerySchema(query=\"summarize llama2\", metadata={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kitchenai_register query kitchenai-bento-llama-index-starter\n",
    "\"\"\"\n",
    "Query logic cell\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitchenai.contrib.kitchenai_sdk.api import EmbedSchema\n",
    "\n",
    "embeddings = EmbedSchema(text=\"this is my first text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kitchenai_register embed kitchenai-bento-llama-index-starter\n",
    "\"\"\"\n",
    "Embedding logic cell\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a KitchenAI Module \n",
    "\n",
    "This transforms your registered functions into a module that can be served directly. To create it, run the %kitchenai_create_module magic command.\n",
    "\n",
    "make sure this is the last cell in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%kitchenai_create_module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
