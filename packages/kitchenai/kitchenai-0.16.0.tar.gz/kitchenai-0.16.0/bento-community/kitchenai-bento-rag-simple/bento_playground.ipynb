{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KitchenAI Simple RAG Bento\n",
    "\n",
    "This is a simple rag that should get developers up and running as quickly as possible and provide all the necessary RAG for their application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext kitchenai.contrib.notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:38:18.943021Z",
     "iopub.status.busy": "2024-12-26T18:38:18.942350Z",
     "iopub.status.idle": "2024-12-26T18:38:20.096035Z",
     "shell.execute_reply": "2024-12-26T18:38:20.095525Z",
     "shell.execute_reply.started": "2024-12-26T18:38:18.942991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Project name set to 'kitchenai-bento-simple-rag'.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%kitchenai_set_project kitchenai-bento-simple-rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitchenai_llama.storage.llama_parser import Parser\n",
    "from llama_index.llms.litellm import LiteLLM\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os \n",
    "import chromadb\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    QuestionsAnsweredExtractor)\n",
    "from llama_index.core import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: Registered new CodeImport with hash 13b980c4893f2e5a1d6a010f18c2276ec9427a5cfbc5ac60e4f6dd591a68ebb0.\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_import_previous_cell kitchenai-bento-rag-simple-imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup globals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LiteLLM(\"gpt-4o\")\n",
    "chroma_client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"quickstart\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: setup 'kitchenai-bento-simple-rag' is already registered with the same code.\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_setup_previous_cell kitchenai-bento-simple-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitchenai.contrib.kitchenai_sdk.schema import StorageSchema\n",
    "\n",
    "\n",
    "storage_data = StorageSchema(\n",
    "dir=\"./data\",\n",
    "metadata={\"source\": \"notebook\", \"category\": \"mock\"},\n",
    "extension=\".pdf\"\n",
    ")\n",
    "\n",
    "def simple_storage(data: StorageSchema, **kwargs):\n",
    "    \"\"\"\n",
    "    Parse a directory of documents and store them in a vector database. This is run in a background task.\n",
    "    Args:\n",
    "        data: StorageSchema\n",
    "    \"\"\"\n",
    "    parser = Parser(api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\", None))\n",
    "    response = parser.load(data.dir, metadata=data.metadata, **kwargs)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    VectorStoreIndex.from_documents(\n",
    "        response[\"documents\"], storage_context=storage_context, show_progress=True,\n",
    "            transformations=[TokenTextSplitter(), TitleExtractor(),QuestionsAnsweredExtractor()]\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: Registered new function 'kitchenai-bento-simple-rag' of type 'storage' with hash e344d1c9f726de475f8d4ee6971fe560aa7552e193783ff1428352effb6947b9.\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_register_previous_cell storage kitchenai-bento-simple-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a4bacc148f4f01963dfcac8e597560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  5%|▌         | 1/20 [00:01<00:24,  1.27s/it]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 2/20 [00:01<00:11,  1.55it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 25%|██▌       | 5/20 [00:02<00:06,  2.31it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 6/20 [00:02<00:05,  2.54it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 45%|████▌     | 9/20 [00:03<00:04,  2.73it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 10/20 [00:04<00:03,  2.81it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 12/20 [00:04<00:02,  3.48it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 65%|██████▌   | 13/20 [00:05<00:02,  2.47it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 16/20 [00:06<00:01,  2.88it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 85%|████████▌ | 17/20 [00:06<00:01,  2.79it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 18/20 [00:06<00:00,  3.26it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c41761efc04b59a4783dece4bde965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = simple_storage(storage_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitchenai.contrib.kitchenai_sdk.schema import QuerySchema, QueryBaseResponseSchema\n",
    "import asyncio\n",
    "\n",
    "query_data = QuerySchema(\n",
    "    query=\"Summarize the rfp\",\n",
    "    stream=False,\n",
    "    metadata={\"topic\": \"healthcare\", \"keyword\": \"AI\"}\n",
    ")\n",
    "\n",
    "async def kitchenai_bento_simple_rag_vjnk(data: QuerySchema):\n",
    "    \"\"\"\n",
    "    Query the vector database with a chat interface\n",
    "    class QuerySchema(Schema):\n",
    "        query: str\n",
    "        stream: bool = False\n",
    "        metadata: dict[str, str] | None = None\n",
    "    Args:\n",
    "        data: QuerySchema\n",
    "    \n",
    "    Response:\n",
    "        QueryBaseResponseSchema:\n",
    "            input: str | None = None\n",
    "            output: str | None = None\n",
    "            retrieval_context: list[str] | None = None\n",
    "            generator: Callable | None = None\n",
    "            metadata: dict[str, str] | None = None\n",
    "    \"\"\"\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store,\n",
    "    )\n",
    "    query_engine = index.as_query_engine(chat_mode=\"best\", llm=llm, verbose=True)\n",
    "    response = await query_engine.aquery(data.query)\n",
    "    print(\"metadata:\", response.metadata)\n",
    "    print(\"response:\", response.source_nodes)\n",
    "    return QueryBaseResponseSchema(output=response.response)\n",
    "\n",
    "async def run_query():\n",
    "    response = await kitchenai_bento_simple_rag_vjnk(query_data)\n",
    "    print(\"output:\", response.output)\n",
    "    # print(\"retrieval_context:\", response.retrieval_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: Registered new function 'kitchenai-bento-simple-rag' of type 'query' with hash d082441dee5a8ce4d42c7ea8cb09d078fb59f74f03bdd36374c6875a9c0c175e.\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_register_previous_cell query kitchenai-bento-simple-rag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m22:11:06 - LiteLLM:INFO\u001b[0m: utils.py:2699 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'8b9e88a0-5b3a-4f9a-8e44-c1707adbf159': {'page_label': '6', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock', 'document_title': 'Procurement Guidelines and Terms for Request for Proposal (RFP) Submission', 'questions_this_excerpt_can_answer': '1. What is the duration of prices for the proposal submitted in response to this RFP?\\n2. What law governs this RFP and any resulting contract?\\n3. Can the City reject proposals and waive technical defects at its sole discretion?\\n4. Are proposal expenses the responsibility of the City or the respondent?\\n5. How does the City handle confidentiality of proposals and what is the process for designating material as confidential?'}, 'dd37669a-77e4-46b5-81ec-4d8f0ee40b85': {'page_label': '5', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock', 'document_title': 'Proposal Submission Requirements and Price Proposal for City of Takoma Park', 'questions_this_excerpt_can_answer': '1. What is the contact information for Kristen Boone in case a confirmation of proposal submission is not received?\\n2. What specific components should be included in the Design, Methodology, and Approach section of the proposal submission?\\n3. How many references are required to be provided in the proposal submission, and what information should be included for each reference?\\n4. What is the required format for the Price Proposal section of the submission, including details on labor costs and non-labor costs?\\n5. What certification is required to be completed as part of the proposal submission process?'}}\n",
      "response: [NodeWithScore(node=TextNode(id_='8b9e88a0-5b3a-4f9a-8e44-c1707adbf159', embedding=None, metadata={'page_label': '6', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock', 'document_title': 'Procurement Guidelines and Terms for Request for Proposal (RFP) Submission', 'questions_this_excerpt_can_answer': '1. What is the duration of prices for the proposal submitted in response to this RFP?\\n2. What law governs this RFP and any resulting contract?\\n3. Can the City reject proposals and waive technical defects at its sole discretion?\\n4. Are proposal expenses the responsibility of the City or the respondent?\\n5. How does the City handle confidentiality of proposals and what is the process for designating material as confidential?'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='555be212-e662-4146-a580-1037141301d6', node_type='4', metadata={'page_label': '6', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock'}, hash='144d8d1f899730f0f685146b0a792b7cedf2931e4e0b6ec5f7fa6776bf91bbbe')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2. A completed Certification of Non-Involvement in the Nuclear Weapons IndustryD. GENERAL1. Confidentiality: Proposals will be available for public inspection after the awardannouncement, except as totheextent that arespondent designatestradesecretsorotherproprietary data to be confidential. Material designated as confidential must be readilyseparable from the remainder of the proposal to facilitate public inspection of thenon-confidential portion of the proposal. A respondent’s designation of material asconfidential will not necessarily be conclusive, and the respondent may be required toprovide justification why such material should not be disclosed, on request, under theMaryland Public Information Act (“PIA”), Title 4 of theGeneral Provisions Article(“GP”) oftheAnnotated Code of Maryland.\\n2. Proposal Expenses: The City is not responsible for expenses incurred in preparing andsubmitting proposals.\\n3. Rejectionof Proposals: TheCityreserves theright,initssolediscretion,torejectanyandallproposals, in part or as a whole, to waive technical defects, and to select theproposal(s)deemed most advantageous to the City, and to elect not to proceed withtheprocess setforth in this RFP.\\n4. Durationof Prices: Thepriceproposal submittedis irrevocablefor aperiodof 90daysfromthe proposal due date.\\n5. Acceptance of Terms and Conditions: By submitting a proposal, a respondent accepts theterms and conditions set forth in this RFP.\\n6. Procurement Law: This RFP and any contract entered into as a result of this RFP aregoverned byTakoma Park Code, Title 7, Division 1(Purchasing), as amended.\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=1597, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.726409817726505), NodeWithScore(node=TextNode(id_='dd37669a-77e4-46b5-81ec-4d8f0ee40b85', embedding=None, metadata={'page_label': '5', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock', 'document_title': 'Proposal Submission Requirements and Price Proposal for City of Takoma Park', 'questions_this_excerpt_can_answer': '1. What is the contact information for Kristen Boone in case a confirmation of proposal submission is not received?\\n2. What specific components should be included in the Design, Methodology, and Approach section of the proposal submission?\\n3. How many references are required to be provided in the proposal submission, and what information should be included for each reference?\\n4. What is the required format for the Price Proposal section of the submission, including details on labor costs and non-labor costs?\\n5. What certification is required to be completed as part of the proposal submission process?'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f864d944-7f28-44ed-ad4f-6719ca92bcf7', node_type='4', metadata={'page_label': '5', 'file_name': 'mock-rfp.pdf', 'source': 'notebook', 'category': 'mock'}, hash='1b6fc013e2b13c7de9795dceb5c83cff9321334c7c525cad4fc083dea928c1e3')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='the receipt of a proposal email. If no confirmation is received within that time frame or before the RFPproposal submission deadline date and time, pleasecontact Kristen Boone at 301-891-7282 to confirmthat the proposal was received.\\nA. TECHNICAL FORMAT\\n1. General: Titlepage/coverletterontherespondent’sbusinessstationary.Thepurposeofthis letter is to provide a record of the transmittal of the proposal and anacknowledgement of anyamendments, addendums, andchanges totheRFP. Thelettershould be signed by an individual who is authorized tocommit therespondent totheservices andrequirementsstatedinthisRFP.TheattachedQualificationandCertificationStatement must be completed and included with theproposal.\\n2. Design, Methodology, and Approach: The respondent shall submit a narrativehighlighting key components of theproposal. This project narrativeshouldidentifytheapproach and methodology to be used to accomplish the objectives of theproject, inaccordance with the project description and proposed schedule, and demonstrate anunderstanding of the project work.\\n3. Qualifications and Experience: A company profile, including number of years inbusiness, type of operation, and number of employees, including a list of all personswhowillbedirectlyorindirectlyinvolvedinprovidingservicestotheCityofTakomaParkunder this proposal andabriefresumeorqualificationssummaryforeachsuchperson.Provide a listing of past projects of similar sizeand scope.\\n4. References: Provide at least three references, including the government entity ororganization name, contact person’s title andcontact information(address, telephone,and e-mail), name of project, location and project description, major personnel of therespondent who will be involved in the project work, contract value, and completiondate.\\nB. PRICE PROPOSAL\\n1. An annual lump sumtotal cost proposal for completing the Scope of Services for theproject describedinthisRFPforthecurrentyearandfortwosubsequentyears.Thecostproposal shouldclearlyreflect theamount of timeandpersonnelneededtoaccomplishall tasks.\\n2. Anestimateof thehours andhourlyratesofindividualsassignedtotheprojectthatwillberequiredtocompletetheScopeof Services describedinthisRFPforthecurrentyearand for two subsequent years.\\n3. All non-labor costs, suchas fordeliveries,transportation,sitevisits,andotherexpenses,for the current year and for two subsequent years aretobeincludedwithinthelumpsum total cost proposal.\\nC. REQUIRED CERTIFICATIONS1. A completed Living Wage Requirements Certification\\n5', mimetype='text/plain', start_char_idx=0, end_char_idx=2509, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.6897037174826506)]\n",
      "output: The Request for Proposal (RFP) outlines the requirements for submitting proposals to the City of Takoma Park. It includes guidelines on confidentiality, stating that proposals will be publicly accessible after the award announcement, except for parts designated as confidential by the respondent. The City is not liable for any expenses incurred in preparing and submitting proposals. It reserves the right to reject any proposals at its discretion and to waive technical defects. Price proposals must remain valid for 90 days from the due date. The RFP and any resulting contracts are governed by the Takoma Park Code. Proposals must include a completed Certification of Non-Involvement in the Nuclear Weapons Industry and a Living Wage Requirements Certification. The submission should also contain a narrative on the design, methodology, and approach, a company profile, and at least three references. The price proposal should include a lump sum total cost for the current and two subsequent years, detailing labor and non-labor costs.\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(run_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming Query\n",
    "\n",
    "async def kitchenai_bento_simple_rag_stream_vjnk(data: QuerySchema):\n",
    "    \"\"\"\n",
    "    Query the vector database with a chat interface\n",
    "    class QuerySchema(Schema):\n",
    "        query: str\n",
    "        stream: bool = False\n",
    "        metadata: dict[str, str] | None = None\n",
    "    Args:\n",
    "        data: QuerySchema\n",
    "    \n",
    "    Response:\n",
    "        QueryBaseResponseSchema:\n",
    "            input: str | None = None\n",
    "            output: str | None = None\n",
    "            retrieval_context: list[str] | None = None\n",
    "            generator: Callable | None = None\n",
    "            metadata: dict[str, str] | None = None\n",
    "    \"\"\"\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store,\n",
    "    )\n",
    "    query_engine = index.as_query_engine(chat_mode=\"best\", llm=llm, streaming=True)\n",
    "    \n",
    "    streaming_response = await query_engine.aquery(data.query)\n",
    "\n",
    "\n",
    "    return QueryBaseResponseSchema(stream_gen=streaming_response.response_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The\n",
      " Request\n",
      " for\n",
      " Proposal\n",
      " (\n",
      "R\n",
      "FP\n",
      ")\n",
      " outlines\n",
      " guidelines\n",
      " and\n",
      " terms\n",
      " for\n",
      " submitting\n",
      " proposals\n",
      ",\n",
      " including\n",
      " provisions\n",
      " on\n",
      " confidentiality\n",
      ",\n",
      " proposal\n",
      " expenses\n",
      ",\n",
      " rejection\n",
      " of\n",
      " proposals\n",
      ",\n",
      " duration\n",
      " of\n",
      " prices\n",
      ",\n",
      " acceptance\n",
      " of\n",
      " terms\n",
      " and\n",
      " conditions\n",
      ",\n",
      " and\n",
      " the\n",
      " governing\n",
      " procurement\n",
      " law\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def run_query_stream():\n",
    "    response = await kitchenai_bento_simple_rag_stream_vjnk(query_data)\n",
    "    async for chunk in response.stream_gen:\n",
    "        print(chunk)\n",
    "    # print(\"retrieval_context:\", response.retrieval_context)\n",
    "\n",
    "\n",
    "asyncio.run(run_query_stream())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca766fe2a54548de96e1f80bada51b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b745ea67d7624b86b13da8023f6ae968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from kitchenai.contrib.kitchenai_sdk.schema import EmbedSchema\n",
    "\n",
    "\n",
    "embed_data = EmbedSchema(\n",
    "    text=\"Some text to embed.\",\n",
    "    metadata={\"type\": \"embeddings\", \"keyword\": \"AI\"}\n",
    ")\n",
    "\n",
    "def simple_rag_bento_vagh(data: EmbedSchema):\n",
    "    \"\"\"\n",
    "    Embed a text into a vector database. This is run in a background task.\n",
    "    class EmbedSchema(Schema):\n",
    "        text: str\n",
    "        metadata: dict[str, str] | None = None\n",
    "    Args:\n",
    "        data: EmbedSchema\n",
    "\n",
    "    Response:\n",
    "        dict:\n",
    "           Any\n",
    "    \"\"\"\n",
    "\n",
    "    documents = [Document(text=data.text)]\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "            \n",
    "    VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context, show_progress=True,\n",
    "            transformations=[TokenTextSplitter(), TitleExtractor(),QuestionsAnsweredExtractor()]\n",
    "    )\n",
    "\n",
    "\n",
    "result = simple_rag_bento_vagh(embed_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: Registered new function 'kitchenai-bento-simple-rag' of type 'embedding' with hash 15b94838b492d68ae75047b98efa41975c7dc1da44cdc5e290ef03d27641930d.\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_register_previous_cell embedding kitchenai-bento-simple-rag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a KitchenAI Module \n",
    "\n",
    "This transforms your registered functions into a module that can be served directly. To create it, run the %kitchenai_create_module magic command.\n",
    "\n",
    "make sure this is the last cell in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchenai_result: Created app.py\n"
     ]
    }
   ],
   "source": [
    "%kitchenai_create_module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
