# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import numpy
import numpy.typing
import typing
from enum import Enum, auto

class EvaluationResult:
    objective: float
    constraints: dict[str, Violation]
    penalties: dict[str, Violation]
    def __new__(cls,objective = ...,constraints = ...,penalties = ...): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...


class MeasuringTime:
    def __new__(cls,solving_time:typing.Optional[SolvingTime], system_time:typing.Optional[SystemTime]): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def total(self) -> float:
        r"""
        Returns the total time measurred, across both `SolvingTime` and `SystemTime`.
        """
        ...

    def view_solving_time(self) -> SolvingTime:
        r"""
        Returns a readonly view of the internal `SolvingTime` field.
        """
        ...

    def view_system_time(self) -> SystemTime:
        r"""
        Returns a readonly view of the internal `SystemTime` field.
        """
        ...


class Sample:
    r"""
    A Sample representing an individual solution found by running the mathematical optimization model.
    
    Variables in `var_values` are stored in instances of `SparseVarValues`. This uses a dictionary
    style, retaining only non-zero elements. For example, if the values for a two-dimensional
    decision variable are `x = [[0, 1, 2], [1, 0, 0]]`, they will be stored as
    `{(0,1): 1, (0,2): 2, (1,0): 1}`. To retrieve this, use `sample.var_values["x"].values`.
    If you want a dense array of decision variables, you can use the `to_dense()` method.
    
    `run_id` is a unique identifier of the run in which this sample was found.
    Note that this is not the same as a unique identifier of the Sample.
    """
    run_id: str
    num_occurrences: int
    run_info: dict[str, None | str | int | float | list | dict]
    var_values: dict[str, SparseVarValues]
    eval: EvaluationResult
    def __new__(cls,num_occurrences = ...,run_id = ...,run_info = ...,var_values = ...,eval = ...): ...
    @staticmethod
    def from_dense_arrays(dict,num_occurrences = ...,var_types = ...,run_id = ...,meta_info = ...) -> Sample:
        ...

    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def __eq__(self, other:typing.Any) -> bool:
        ...

    def is_feasible(self, epsilon = ...) -> bool:
        ...

    def to_dense(self) -> dict[str, numpy.typing.NDArray[numpy.float64]]:
        ...

    @staticmethod
    def from_dict(dict:dict) -> Sample:
        r"""
        Converts a python dictionary into a SampleSet.
        
        This is intended to be used primarily with dictionaries generated by
        the `to_dict()` method. As such sparse value maps must be represented as
        association lists.
        """
        ...

    def to_dict(self) -> typing.Any:
        r"""
        Converts this SampleSet into a regular python dictionary.
        
        Note that this dictionary has a slightly different structure to better support JSON
        serialization of the output dictionary: sparse values are stored differently. Any mapping
        with tuples as keys is transformed into an association list of key-value pairs,
        that is, `[(k1, v1), (k2, v2), ...]`.
        """
        ...


class SampleIter:
    def __iter__(self) -> SampleIter:
        ...

    def __next__(self) -> Sample:
        ...


class SampleSet:
    data: list[Sample]
    set_id: str
    set_info: dict[str, None | str | int | float | list | dict]
    run_info: dict[str, None | str | int | float | list | dict]
    measuring_time: MeasuringTime
    run_times: dict[str, MeasuringTime]
    def __new__(cls,data = ...,*,set_id = ...,set_info = ...,run_info = ...,measuring_time = ...,run_times = ...): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def __eq__(self, other:typing.Any) -> bool:
        ...

    def __len__(self) -> int:
        ...

    def __getitem__(self, idx:int) -> Sample:
        ...

    def __iter__(self) -> SampleIter:
        ...

    @staticmethod
    def from_array(samples:typing.Sequence[typing.Mapping[str, numpy.typing.NDArray[numpy.float64] | list]]) -> SampleSet:
        r"""
        Builds a SampleSet from a list of dictionaries, where each entry is interpreted as a sample.
        
        Args
        -----
        - `samples`(`list[dict[str, list | numpy.ndarray]]`)
        """
        ...

    @staticmethod
    def concat(family:typing.Sequence[SampleSet]) -> SampleSet:
        r"""
        Creates a single SampleSet by concatenating a list of multiple SampleSets.
        
        Args
        -----
        - `family` (`list[SampleSet]`)
        """
        ...

    @staticmethod
    def from_dict(dict:dict) -> SampleSet:
        r"""
        Converts a python dictionary into a SampleSet.
        
        This is intended to be used primarily with dictionaries generated by
        the `to_dict()` method. As such sparse value maps must be represented as
        association lists.
        """
        ...

    def to_dict(self) -> typing.Any:
        r"""
        Converts this SampleSet into a regular python dictionary.
        
        Note that this dictionary has a slightly different structure to better support JSON
        serialization of the output dictionary: sparse values are stored differently. Any mapping
        with tuples as keys is transformed into an association list of key-value pairs,
        that is, `[(k1, v1), (k2, v2), ...]`.
        """
        ...

    def feasibles(self, epsilon = ...) -> SampleSet:
        r"""
        Returns a SampleSet containing only the feasible samples.
        
        Args
        -----
        - `epsilon` (`float`, optional): Tolerance threshold for constraint violations. Defaults to $1e-8$.
        
        Returns
        --------
        - `SampleSet`: a feasible subset of the current set.
        """
        ...

    def separate(self) -> dict[str, SampleSet]:
        r"""
        Splits this `SampleSet` based on the `run_id` of the samples.
        
        In other words, for each distinct `run_id` among the `Sample`s contained in this instance, a
        new `SampleSet` is created to store all `Sample`s with that ID.
        
        Returns
        -----
        - `sets` (dict[str, SampleSet]): The separated SampleSets. Keys are the run IDs.
        """
        ...

    def lowest(self, epsilon = ...) -> list[Sample]:
        r"""
        Returns a list of the feasible samples which have the lowest objective value.
        If there are no feasible solutions, this returns an empty list.
        
        Args
        -----
        - `epsilon` (`float`, optional): Tolerance threshold. Objective values within this tolerance are included, even if not exactly the minimum value. Defaults to $1e-8$.
        
        Returns
        -----
        `lowest_samples`: A list of Sample objects with the lowest ojective value in this SampleSet.
        """
        ...


class SolvingTime:
    compiling_time: float
    transpiling_time: float
    preprocess_time: float
    solving_time: float
    decoding_time: float
    postprocess_time: float
    def __new__(cls,compiling_time = ...,transpiling_time = ...,preprocess_time = ...,solving_time = ...,decoding_time = ...,postprocess_time = ...): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    def total(self) -> float:
        ...


class SparseVarValues:
    name: str
    values: dict[typing.Tuple[int, ...], float]
    var_type: VarType
    shape: tuple
    def __new__(cls,name,values,shape,var_type = ...): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...

    @staticmethod
    def from_array(name,array,var_type = ...) -> SparseVarValues:
        ...

    def to_dense(self) -> numpy.typing.NDArray[numpy.float64]:
        ...


class SystemTime:
    posting_time: typing.Optional[float]
    request_queuing_time: typing.Optional[float]
    fetching_problem_time: typing.Optional[float]
    fetching_result_time: typing.Optional[float]
    deserialize_time: typing.Optional[float]
    def __new__(cls,posting_time = ...,request_queuing_time = ...,fetching_problem_time = ...,fetching_result_time = ...,deserialize_time = ...): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...


class Violation:
    name: str
    total_violation: float
    expr_values: dict[typing.Tuple[int, ...], float]
    def __new__(cls,name:str, total_violation:float, expr_values:typing.Mapping[typing.Tuple[int, ...], float]): ...
    def __str__(self) -> str:
        ...

    def __repr__(self) -> str:
        ...


class VarType(Enum):
    CONTINUOUS = auto()
    INTEGER = auto()
    BINARY = auto()

def from_old_sampleset(sampleset:typing.Any) -> SampleSet:
    ...

