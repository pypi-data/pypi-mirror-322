# Plan for Improving `ArchitectCoder`

You and I often collaborate on projects. You defer to my leadership, but you also trust your own judgment and challenge my decisions when you think that's important. We both believe strongly in this tenet of agile: use the simplest approach that might work.

We are collaborating to enhance our Python project as described below. We want to work efficiently in an organized way. For the portions of the code that we must change to meet our functionality goals, we want to move toward beautiful, idiomatic Python code. We also want to move toward more testable code with simple unit tests that cover the most important paths.

This document contains three kinds of material:

- requirements
- specific plans for meeting those requirements
- our findings as we analyze our code along the way

We only intend for this plan to cover straightforward next steps to our next demonstrable milestone. We'll extend it as we go.

We write down our findings as we go, to build up context for later tasks. When a task requires analysis, we use the section header as the task and write down our findings as that section's content.

For relatively complex tasks that benefit from a prose description of our approach, we use the section header as the task and write down our approach as that section's content. We nest these sections as appropriate.

For simpler tasks that can be naturally specified in a single sentence, we move to bullet points.

We use simple, textual checkboxes at each level of task, both for tasks represented by section headers and for tasks represented by bullets. Like this:

```
### ( ) Complex Task.

- (✅) Subtask
  - (✅) Subsubtask
- ( ) Another subtask
```

## Requirements

We want a smoother flow between the architect model's work and the edit model. 

### Retain the messages generated by the architect model in our chat history.

Right now, we clear the chat history when we change models. This makes sense for some transitions between coders, such as between those using "diff" and "whole" edit formats. These coders produce code modifications that should be automatically applied. Because they format these code modifications differently, and because the model may emulate formatting from the chat history regardless of how it is instructed, the chat history must be cleared on that transition. But coders using the "ask" and "architect" edit formats are different: they don't produce code blocks at all, so they are compatible with any other coder.

Let's add a class attribute `produces_code_edits` to the `Coder` base class that defaults to `True`. Let's set this to `False` in the `AskCoder` and `ArchitectCoder` classes. Let's only clear the chat history when we change coders if `produces_code_edits` is `True` for both the old and new coders. When we do clear the chat history, let's announce in the UI that we did.

### Interact appropriately with the user after the architect model replies.

Let's explicitly tell the architect model that it can choose to reply in any of the following ways:

- It can continue the conversation by asking a follow-up question or by making a suggestion.
- It can ask to see additional files.
- It can propose to edit source files.

After the architect model generates its reply, let's use `llm-multiple-choice` to construct a follow-up inquiry to the architect model to find out which way the architect model replied, and thus what the UI should do next.

- If the architect model replied in a way that just continued the conversation, then `ArchitectCoder` should stop and let the user speak.

- If the architect model asked to see additional files, then `ArchitectCoder` should prompt the user to decide whether it is ok to add those files to the chat.

- If the architect model proposed to edit source files, then `ArchitectCoder` should prompt the user to decide whether it is ok to proceed with the edits.

### Example chat that we'd like the architect coder to handle smoothly, but where it is currently jarring.

architect> !poetry run pytest

============================= test session starts ==============================
platform darwin -- Python 3.12.4, pytest-8.3.3, pluggy-1.5.0
rootdir: /Users/deansher/projects/llm-multiple-choice-py
configfile: pyproject.toml
plugins: anyio-4.6.0
collected 0 items / 1 error

==================================== ERRORS ====================================
________________ ERROR collecting tests/test_choice_manager.py _________________
ImportError while importing test module '/Users/deansher/projects/llm-multiple-choice-py/tests/test_choice_manager.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/opt/homebrew/Cellar/python@3.12/3.12.4/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_choice_manager.py:3: in <module>
    from llm_multiple_choice import (
E   ModuleNotFoundError: No module named 'llm_multiple_choice'
=========================== short test summary info ============================
ERROR tests/test_choice_manager.py
!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
=============================== 1 error in 0.06s ===============================

Add the output to the chat?
(Y)es/(n)o/message with instructions:

This error indicates that Python can't find the llm_multiple_choice module when running the tests. This typically happens when the package isn't installed in
development mode or isn't in the Python path.

Let me see your pyproject.toml file to help diagnose and fix this. Could you please share it?

The solution will likely involve either:

 1 Making sure the package is properly configured in pyproject.toml
 2 Installing the package in development mode with poetry install
 3 Or adjusting the Python path configuration

Could you please share your pyproject.toml file so I can help diagnose the specific issue?


Tokens: 5.8k sent, 132 received.
Cost: $0.02 message, $0.08 session. Use --no-stream for accurate caching costs.
Should I edit files now? (Respond "No" to continue the conversation instead.) (Y)es/(N)o [Yes]: N
Add pyproject.toml to the chat? (Y)es/(N)o/(D)on't ask again [Yes]:
I see the pyproject.toml file now, and it looks correctly configured. The issue is likely that the package needs to be installed in development mode. Please
try running:


 poetry install


This will install your package in development mode along with all its dependencies. After that, try running the tests again with:


 poetry run pytest


Let me know if you still encounter any issues.


Tokens: 6.3k sent, 90 received.
Cost: $0.02 message, $0.10 session. Use --no-stream for accurate caching costs.
Should I edit files now? (Respond "No" to continue the conversation instead.) (Y)es/(N)o [Yes]: N
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
llm_multiple_choice/choice_manager.py (read only)
pyproject.toml
tests/test_choice_manager.py
architect> poetry install

I see you ran poetry install, but I don't see the output. Could you try running the tests again with poetry run pytest and share the results? This will help us
determine if the installation resolved the module import issue or if we need to try something else.


Tokens: 6.4k sent, 58 received.
Cost: $0.02 message, $0.12 session. Use --no-stream for accurate caching costs.
Should I edit files now? (Respond "No" to continue the conversation instead.) (Y)es/(N)o [Yes]: N
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
llm_multiple_choice/choice_manager.py (read only)
pyproject.toml
tests/test_choice_manager.py
architect> !poetry install

Installing dependencies from lock file

Package operations: 3 installs, 2 updates, 0 removals

  - Installing mypy-extensions (1.0.0)
  - Updating virtualenv (20.26.5 -> 20.26.6)
  - Installing black (23.12.1)
  - Installing mypy (1.11.2)
  - Downgrading pytest (8.3.3 -> 7.4.4)

Installing the current project: llm-multiple-choice (0.1.0)

Add the output to the chat?
(Y)es/(n)o/message with instructions:

Great, the package has been installed in development mode. Now please try running the tests again with:


 poetry run pytest


This should resolve the module import error we saw earlier. Let me know what output you get.


Tokens: 9.3k sent, 49 received.
Cost: $0.03 message, $0.15 session. Use --no-stream for accurate caching costs.
Should I edit files now? (Respond "No" to continue the conversation instead.) (Y)es/(N)o [Yes]: N
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
llm_multiple_choice/choice_manager.py (read only)
pyproject.toml
tests/test_choice_manager.py
architect>

## ( ) Retain the messages generated by the architect model in our chat history.

  - (✅) implement
  - ( ) verify

## ( ) Fix our Langfuse integration

```
Failed to configure Langfuse: LangfuseDecorator.configure() got an unexpected keyword argument 'error_handler'
```

## (✅) Disable automatic pip-upgrade prompt

```
Newer aider version v0.61.0 is available.

python3.12 -m pip install --upgrade --upgrade-strategy only-if-needed aider-chat
Run pip install? (Y)es/(N)o [Yes]:
```

## (✅) Explicitly tell the architect model the ways in which it can reply.

## ( ) Use `llm-multiple-choice` to find out how the architect model replied.

### (✅) Add a function to `sendchat.py` that uses `llm-multiple-choice` to analyze the current chat situation.

```
def analyze_chat_situation(
    choice_manager,
    model_name,
    messages,
    functions,
    stream,
    temperature=0,
    extra_params=None,
):
```

This is analogous to `send_completion`, and should delegate to that function.
It should return a `ChoiceCodeSet`.

### (✅) Add a test for `analyze_chat_situation`.

### ( ) Use `analyze_chat_situation` to determine how the architect model replied.

## ( ) Interact with the user appropriately to how the architect model replied.

## ( ) Fix all broken tests.

## ( ) Eliminate automatic GitHub issue raising

```
Please consider reporting this bug to help improve aider!
Open a GitHub Issue pre-filled with the above error in your browser? (Y/n) n
```