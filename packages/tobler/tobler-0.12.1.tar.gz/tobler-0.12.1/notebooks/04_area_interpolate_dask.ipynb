{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f2586a-5b6a-4d46-b6e8-1991ae3bec6f",
   "metadata": {},
   "source": [
    "# (Distributed) areal interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f875bd-2714-4551-b10c-1ef3f514478d",
   "metadata": {},
   "source": [
    "In this notebook, we compare the single-core version in `tobler.area_weighted.area_interpolate` with the distributed version in `tobler.area_weighted.area_interpolate_dask`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4084f715-3989-4424-943a-2a4066a8bcf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '1'\n",
    "\n",
    "import pandas\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "import tobler\n",
    "from libpysal.examples import load_example\n",
    "import numpy as np\n",
    "\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2e15-866b-407d-b65d-54a675aefbd7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080369e7-f3d4-41c6-a629-12ed458eb743",
   "metadata": {},
   "source": [
    "Load example data from `pysal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb395dc5-67f2-462e-a1cf-919c8e6d0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = load_example('Charleston1')\n",
    "c2 = load_example('Charleston2')\n",
    "\n",
    "crs = 6569  # https://epsg.io/6569\n",
    "\n",
    "tracts = geopandas.read_file(c1.get_path('sc_final_census2.shp')).to_crs(crs)\n",
    "zip_codes = geopandas.read_file(c2.get_path('CharlestonMSA2.shp')).to_crs(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11c1d7-6435-40cb-a4d4-851f63eccf01",
   "metadata": {},
   "source": [
    "We make up a categorical variable with four classes distributed randomly across the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3543702f-5e8a-4336-a14d-19a4eeb77b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "tracts['rando'] = pandas.Series(\n",
    "    rng.integers(0, 4, len(tracts)), dtype='category'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2546bb7-abcb-4cad-8db8-c569ea9289ae",
   "metadata": {},
   "source": [
    "We will set up a local Dask cluster so you can follow the computations on the dashboard (`http://localhost:8787` by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ac8ec-51e2-4d2d-abb2-96a7519ed749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(LocalCluster(n_workers=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c32c7d-0ca8-4945-a1f8-edfbc8917880",
   "metadata": {},
   "source": [
    "Finally, for Dask, we need to provide `dask_geopandas.GeoDataFrame` objects with spatial partitions and categorical variables properly set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31a1a91-4071-40e2-a21f-7e035d734976",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtracts = (\n",
    "    dask_geopandas.from_geopandas(tracts[['geometry', 'rando']], npartitions=16)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "dzips = (\n",
    "    dask_geopandas.from_geopandas(zip_codes[['ZIP', 'geometry']], npartitions=16)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f986ec-ea46-479e-aed8-5edeeaf16fda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**IMPORTANT** - At this point, only *categorical* variables are implemented, so those are what we will test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783aabc-8221-40f6-a0d5-bf21dd75e2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dafb11-ec94-43c2-baec-2a5e2a0b380d",
   "metadata": {},
   "source": [
    "- Single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4cde6d-73c1-4197-86ed-131724e21296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts, zip_codes, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982d8dc-c1e9-4927-8643-9900b1b09890",
   "metadata": {},
   "source": [
    "- Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c7896f-9004-4a07-b3ba-75301f8120e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts, dzips, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19b8dd-505f-4dc1-ba85-9fd825e59b43",
   "metadata": {},
   "source": [
    "And we can compare both results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81de5e35-f3b6-4567-86b1-36d98583dca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rando_0    4.188295e-08\n",
       "rando_1    5.328575e-08\n",
       "rando_2    5.396667e-08\n",
       "rando_3    2.935173e-08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (\n",
    "    cat_dk\n",
    "    .set_index('ZIP')\n",
    "    .reindex(zip_codes['ZIP'].values)\n",
    "    .drop(columns='geometry')\n",
    ")\n",
    "\n",
    "b = (\n",
    "    cat_sc\n",
    "    .drop(columns='geometry')\n",
    "    [['rando_0', 'rando_1', 'rando_2', 'rando_3']]\n",
    ")\n",
    "b.index = a.index\n",
    "\n",
    "(a - b).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e04df1-3331-449c-b74c-e910239c3067",
   "metadata": {},
   "source": [
    "The differences in the estimates for the proportions of each area start at the 8th decimal, and thus likely rounding errors derived from the different approaches used to compute the interpolation (the single core does it in one-shot, while Dask computes parts and brings them together later with a sum)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debbdf4-892f-4fda-834a-0403595794ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE** - Timings below do _not_ include computation time required for spatial shuffling and partitioning (which can be substantial with large datasets), or converting from `geopandas`. These are \"sunk costs\" that'll only make this approach preferable with large datasets, although they can be computed once and the result stored in disk efficiently (e.g., as Parquet files). Having said that, when \"larger\" is large enough is not very large in modern terms: from a handful of thousand observations the gains will be substantial if several cores/workers are available.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5242c13-c4cd-46e2-9131-ec1734bcc142",
   "metadata": {},
   "source": [
    "We can now time the example above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902e494b-65ba-4fa2-99e6-eb3a513769f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 ms ± 1.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts, zip_codes, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfc44d9-f79a-4b8e-9caa-975ea64d5f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 s ± 51.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts, dzips, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124ee86-c527-4386-be8d-2dc833270fd9",
   "metadata": {},
   "source": [
    "This is notably slower (about 5x!). For such a small dataset, the overhead in distributing computations and collecting them overcomes any gains in parallelism.\n",
    "\n",
    "Now we can artificially increase the size of the datasets by concatenating them several times and re-computing (this time we only time one execution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f56d579-0022-45c2-845c-f351bf96ed01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40x increase | N. tracts: 4680 | N. ZIPs: 1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 30.18 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 30.18 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sizeup = 40\n",
    "tracts_lrg = pandas.concat([tracts] * sizeup)\n",
    "zips_lrg = pandas.concat([zip_codes] * sizeup)\n",
    "print(\n",
    "    f'{sizeup}x increase | N. tracts: {len(tracts_lrg)} | N. ZIPs: {len(zips_lrg)}'\n",
    ")\n",
    "\n",
    "dtracts_lrg = (\n",
    "    dask_geopandas.from_geopandas(tracts_lrg[['geometry', 'rando']], chunksize=500)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")\n",
    "\n",
    "dzips_lrg = (\n",
    "    dask_geopandas.from_geopandas(zips_lrg[['ZIP', 'geometry']], chunksize=500)\n",
    "    .spatial_shuffle(by='hilbert', shuffle=\"tasks\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5187109-ba95-4b5f-b373-2ec4745d0289",
   "metadata": {},
   "source": [
    "And re-compute the timings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da372a-f791-47fb-ade0-317a1cf6ff9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620cf9ab-7b9e-4458-809c-c7a73d13f26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 10x\n",
      "CPU times: user 7.21 s, sys: 11.3 ms, total: 7.23 s\n",
      "Wall time: 6.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c615b27a-e004-429b-a0c5-e4b237516f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 10x\n",
      "CPU times: user 548 ms, sys: 18 ms, total: 566 ms\n",
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc13af25-e97e-4b34-bb1f-bb946c15748e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 20x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbb40d4-4b3b-446d-9d1b-99462a122d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 20x\n",
      "CPU times: user 28.6 s, sys: 26.1 ms, total: 28.7 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ca1394-5f8d-428f-a61c-87beb8778322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 20x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 16.77 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 65.3 ms, total: 1.38 s\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b34b4-9fea-48a6-b38b-8b1a5d755ca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 30x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1598ce3f-d21e-4a60-9619-ee5b1eb4932f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 30x\n",
      "CPU times: user 1min 4s, sys: 176 ms, total: 1min 4s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224ffbca-7690-4b20-bad2-efbf042623a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 30x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 25.14 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 58.8 ms, total: 1.97 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004834f-c5ce-4f92-be9a-364a07c7996b",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### 40x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b9d06a-9034-4c39-b3a9-92fc6408d5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 40x\n",
      "CPU times: user 2min 2s, sys: 1.71 s, total: 2min 3s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_sc = tobler.area_weighted.area_interpolate(\n",
    "    tracts_lrg, zips_lrg, categorical_variables=['rando']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a68e5fe-ee41-48cc-9222-6554a7651c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for a sizeup of 40x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tobler/lib/python3.11/site-packages/distributed/client.py:3161: UserWarning: Sending large graph of size 33.52 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 512 ms, total: 7.5 s\n",
      "Wall time: 30.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Computing for a sizeup of {sizeup}x')\n",
    "cat_dk = tobler.area_weighted.area_interpolate_dask(\n",
    "    dtracts_lrg, dzips_lrg, 'ZIP', categorical_variables=['rando']\n",
    ").compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobler",
   "language": "python",
   "name": "tobler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
